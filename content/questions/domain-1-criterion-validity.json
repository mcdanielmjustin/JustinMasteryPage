{
  "domain": "Domain 1: Psychometrics & Research Methods",
  "domainId": 1,
  "subdomain": "Predicting Outcomes \u2014 Criterion-Related Validity",
  "asppbDomain": 5,
  "questionCount": 26,
  "questions": [
    {
      "type": "single_choice",
      "id": "d1-cv-sc-001",
      "stem": "A researcher correlates SAT scores with first-year college GPA to determine whether SAT scores predict academic success. This correlation coefficient represents:",
      "options": [
        {"id": "a", "text": "Concurrent validity coefficient", "isCorrect": false},
        {"id": "b", "text": "Predictive validity coefficient", "isCorrect": true},
        {"id": "c", "text": "Content validity coefficient", "isCorrect": false},
        {"id": "d", "text": "Construct validity coefficient", "isCorrect": false}
      ],
      "explanation": "Predictive validity examines whether a test predicts future performance on a criterion measured at a later time. SAT (predictor) → future GPA (criterion) demonstrates predictive validity. The time gap between predictor and criterion is the defining feature.",
      "difficulty": "hard",
      "tags": ["predictive validity", "criterion-related", "SAT"]
    },
    {
      "type": "single_choice",
      "id": "d1-cv-sc-002",
      "stem": "A clinician wants to determine whether a brief depression screening tool accurately identifies currently depressed patients. The screening scores are correlated with diagnoses from structured clinical interviews conducted at the same time. This establishes:",
      "options": [
        {"id": "a", "text": "Predictive validity", "isCorrect": false},
        {"id": "b", "text": "Concurrent validity", "isCorrect": true},
        {"id": "c", "text": "Incremental validity", "isCorrect": false},
        {"id": "d", "text": "Face validity", "isCorrect": false}
      ],
      "explanation": "Concurrent validity examines the relationship between a test and a criterion measured at approximately the same time. The screening tool (predictor) and clinical interview (criterion) are administered simultaneously to assess whether the brief tool captures current depression status.",
      "difficulty": "hard",
      "tags": ["concurrent validity", "screening", "simultaneous measurement"]
    },
    {
      "type": "single_choice",
      "id": "d1-cv-sc-003",
      "stem": "An employment test has a validity coefficient of r = .35 for predicting job performance. Squaring this coefficient (r² = .12) indicates that the test explains:",
      "options": [
        {"id": "a", "text": "35% of variance in job performance", "isCorrect": false},
        {"id": "b", "text": "12% of variance in job performance", "isCorrect": true},
        {"id": "c", "text": "88% of variance in job performance", "isCorrect": false},
        {"id": "d", "text": "65% of error variance", "isCorrect": false}
      ],
      "explanation": "r² (coefficient of determination) represents the proportion of criterion variance explained by the predictor. With r = .35, r² = .12, meaning 12% of job performance variance is predicted by the test. While seemingly small, r = .35 is considered useful for selection in psychology.",
      "difficulty": "hard",
      "tags": ["validity coefficient", "r-squared", "explained variance"]
    },
    {
      "type": "single_choice",
      "id": "d1-cv-sc-004",
      "stem": "A researcher finds that adding a personality measure to cognitive ability testing improves prediction of job performance beyond what cognitive ability alone predicts. This demonstrates:",
      "options": [
        {"id": "a", "text": "Concurrent validity", "isCorrect": false},
        {"id": "b", "text": "Content validity", "isCorrect": false},
        {"id": "c", "text": "Incremental validity", "isCorrect": true},
        {"id": "d", "text": "Face validity", "isCorrect": false}
      ],
      "explanation": "Incremental validity refers to the improvement in prediction when a new predictor is added to existing predictors. The personality measure has incremental validity because it adds predictive power beyond cognitive ability alone. This is assessed via hierarchical regression.",
      "difficulty": "hard",
      "tags": ["incremental validity", "prediction improvement", "multiple predictors"]
    },
    {
      "type": "single_choice",
      "id": "d1-cv-sc-005",
      "stem": "A selection test has sensitivity = .85 and specificity = .70 for identifying successful employees. Sensitivity represents:",
      "options": [
        {"id": "a", "text": "Proportion of unsuccessful employees correctly rejected", "isCorrect": false},
        {"id": "b", "text": "Proportion of successful employees correctly identified", "isCorrect": true},
        {"id": "c", "text": "Overall accuracy rate", "isCorrect": false},
        {"id": "d", "text": "Positive predictive value", "isCorrect": false}
      ],
      "explanation": "Sensitivity (true positive rate) = proportion of actual positives correctly identified (successful employees correctly selected). Specificity (true negative rate) = proportion of actual negatives correctly rejected (unsuccessful correctly screened out). Both are aspects of criterion-related validity for classification decisions.",
      "difficulty": "hard",
      "tags": ["sensitivity", "specificity", "classification accuracy"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-cv-mc-001",
      "stem": "Which factors can ATTENUATE (reduce) a validity coefficient? Select all that apply.",
      "options": [
        {"id": "a", "text": "Unreliability in the predictor measure", "isCorrect": true},
        {"id": "b", "text": "Unreliability in the criterion measure", "isCorrect": true},
        {"id": "c", "text": "Range restriction in predictor or criterion scores", "isCorrect": true},
        {"id": "d", "text": "Very large sample size", "isCorrect": false},
        {"id": "e", "text": "Criterion contamination", "isCorrect": false}
      ],
      "explanation": "Validity is attenuated by: unreliable predictor, unreliable criterion, and range restriction (reduced variance). Large samples don't affect coefficient magnitude (affect significance). Criterion contamination actually inflates validity artificially.",
      "difficulty": "hard",
      "tags": ["attenuation", "validity reduction", "range restriction"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-cv-mc-002",
      "stem": "Which statements about the base rate's effect on selection testing are TRUE? Select all that apply.",
      "options": [
        {"id": "a", "text": "Base rate is the proportion of applicants who would succeed without selection", "isCorrect": true},
        {"id": "b", "text": "When base rate is .50, selection tests have maximum utility", "isCorrect": true},
        {"id": "c", "text": "When base rate is very high (.95), selection tests add little value", "isCorrect": true},
        {"id": "d", "text": "When base rate is very low (.05), most selected applicants will succeed", "isCorrect": false},
        {"id": "e", "text": "Base rate interacts with selection ratio to determine utility", "isCorrect": true}
      ],
      "explanation": "Base rate = natural success rate. Tests are most useful when base rate ≈ .50 (maximum uncertainty). Very high base rates (almost everyone succeeds) or very low (almost everyone fails) mean selection adds little. Low base rate means most people selected may still fail. Base rate × selection ratio = utility.",
      "difficulty": "hard",
      "tags": ["base rate", "selection utility", "Taylor-Russell tables"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-cv-mc-003",
      "stem": "When using a test for selection purposes, which decision outcomes represent selection errors? Select all that apply.",
      "options": [
        {"id": "a", "text": "False positives (selecting someone who fails)", "isCorrect": true},
        {"id": "b", "text": "False negatives (rejecting someone who would have succeeded)", "isCorrect": true},
        {"id": "c", "text": "True positives (selecting someone who succeeds)", "isCorrect": false},
        {"id": "d", "text": "True negatives (rejecting someone who would have failed)", "isCorrect": false},
        {"id": "e", "text": "Hits (correct decisions of any type)", "isCorrect": false}
      ],
      "explanation": "Selection errors: false positives (selected but fail—wasted resources) and false negatives (rejected but would have succeeded—lost talent). True positives and true negatives are correct decisions. The costs of each error type differ by situation (clinical vs. employment).",
      "difficulty": "hard",
      "tags": ["selection errors", "false positives", "false negatives"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-cv-mc-004",
      "stem": "Which are appropriate criteria for evaluating a test's predictive validity for employment selection? Select all that apply.",
      "options": [
        {"id": "a", "text": "Objective job performance measures", "isCorrect": true},
        {"id": "b", "text": "Supervisor ratings", "isCorrect": true},
        {"id": "c", "text": "Tenure/turnover", "isCorrect": true},
        {"id": "d", "text": "Sales or productivity metrics", "isCorrect": true},
        {"id": "e", "text": "Physical attractiveness ratings", "isCorrect": false}
      ],
      "explanation": "Valid job criteria: objective performance (sales, errors), supervisor ratings (performance appraisals), tenure/turnover (staying on job), productivity metrics. Attractiveness is not a legitimate job performance criterion (legally and ethically problematic).",
      "difficulty": "hard",
      "tags": ["criterion measures", "job performance", "employment testing"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-cv-mc-005",
      "stem": "Criterion contamination occurs in which situations? Select all that apply.",
      "options": [
        {"id": "a", "text": "Supervisor knows employee's test scores when rating performance", "isCorrect": true},
        {"id": "b", "text": "Criterion measure is systematically biased by irrelevant factors", "isCorrect": true},
        {"id": "c", "text": "Predictor and criterion are measured at the same time", "isCorrect": false},
        {"id": "d", "text": "Criterion ratings are influenced by factors other than true performance", "isCorrect": true},
        {"id": "e", "text": "The validity coefficient is very low", "isCorrect": false}
      ],
      "explanation": "Criterion contamination: criterion is influenced by knowledge of predictor scores (biases ratings toward test results) or by irrelevant factors (halo effect, likeability). This artificially inflates validity coefficients. Concurrent measurement timing doesn't itself cause contamination.",
      "difficulty": "hard",
      "tags": ["criterion contamination", "biased criteria"]
    },
    {
      "type": "matrix_single",
      "id": "d1-cv-ms-001",
      "stem": "Match each validity type with the timing of predictor and criterion measurement.",
      "rows": [
        {"id": "r1", "text": "Predictive validity"},
        {"id": "r2", "text": "Concurrent validity"},
        {"id": "r3", "text": "Postdictive validity"},
        {"id": "r4", "text": "Incremental validity"}
      ],
      "columns": [
        {"id": "c1", "text": "Predictor now, criterion later"},
        {"id": "c2", "text": "Predictor and criterion at same time"},
        {"id": "c3", "text": "Criterion first, predictor later (reconstruct past)"},
        {"id": "c4", "text": "New predictor adds to existing predictors"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c2"},
        {"rowId": "r3", "columnId": "c3"},
        {"rowId": "r4", "columnId": "c4"}
      ],
      "explanation": "Predictive: predictor predicts future criterion. Concurrent: same-time measurement. Postdictive: criterion preceded predictor (reconstruct/diagnose past events). Incremental: improvement from adding predictor to existing battery (timing varies).",
      "difficulty": "hard",
      "tags": ["validity timing", "criterion-related types"]
    },
    {
      "type": "matrix_single",
      "id": "d1-cv-ms-002",
      "stem": "Match each classification outcome with its definition.",
      "rows": [
        {"id": "r1", "text": "Sensitivity"},
        {"id": "r2", "text": "Specificity"},
        {"id": "r3", "text": "Positive predictive value (PPV)"},
        {"id": "r4", "text": "Negative predictive value (NPV)"}
      ],
      "columns": [
        {"id": "c1", "text": "True positives ÷ All actual positives"},
        {"id": "c2", "text": "True negatives ÷ All actual negatives"},
        {"id": "c3", "text": "True positives ÷ All predicted positives"},
        {"id": "c4", "text": "True negatives ÷ All predicted negatives"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c2"},
        {"rowId": "r3", "columnId": "c3"},
        {"rowId": "r4", "columnId": "c4"}
      ],
      "explanation": "Sensitivity: of actual positives, how many detected (TP/actual+). Specificity: of actual negatives, how many correctly ruled out (TN/actual-). PPV: of positive predictions, how many correct. NPV: of negative predictions, how many correct. PPV/NPV depend on base rate.",
      "difficulty": "hard",
      "tags": ["classification metrics", "sensitivity", "specificity", "PPV", "NPV"]
    },
    {
      "type": "matrix_multiple",
      "id": "d1-cv-mm-001",
      "stem": "For each scenario, select ALL factors that would affect selection utility.",
      "rows": [
        {"id": "r1", "text": "Raising the cutoff score"},
        {"id": "r2", "text": "Lower base rate of success"},
        {"id": "r3", "text": "Higher validity coefficient"},
        {"id": "r4", "text": "Lower selection ratio (more selective)"}
      ],
      "columns": [
        {"id": "c1", "text": "Increases proportion of successes among selected"},
        {"id": "c2", "text": "Decreases number of people selected"},
        {"id": "c3", "text": "Increases false negatives"},
        {"id": "c4", "text": "Decreases false positives"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r1", "columnId": "c2"},
        {"rowId": "r1", "columnId": "c3"},
        {"rowId": "r1", "columnId": "c4"},
        {"rowId": "r3", "columnId": "c1"},
        {"rowId": "r4", "columnId": "c1"},
        {"rowId": "r4", "columnId": "c2"},
        {"rowId": "r4", "columnId": "c3"}
      ],
      "explanation": "Higher cutoff: selects fewer, increases success proportion, but misses qualified people (false negatives increase) while reducing unqualified hires (false positives decrease). Better validity increases correct decisions. Lower selection ratio = more selective = same tradeoffs as higher cutoff.",
      "difficulty": "hard",
      "tags": ["selection utility", "cutoff effects", "selection ratio"]
    },
    {
      "type": "matrix_multiple",
      "id": "d1-cv-mm-002",
      "stem": "Select ALL statements that are TRUE for each validity coefficient interpretation.",
      "rows": [
        {"id": "r1", "text": "r = .40 for employment test"},
        {"id": "r2", "text": "r = .70 for clinical diagnosis"},
        {"id": "r3", "text": "r = .25 for personality predicting job performance"},
        {"id": "r4", "text": "r = .15 for interview predicting success"}
      ],
      "columns": [
        {"id": "c1", "text": "Considered useful/acceptable in context"},
        {"id": "c2", "text": "Explains substantial criterion variance"},
        {"id": "c3", "text": "Should not be used alone for decisions"},
        {"id": "c4", "text": "Typical for this type of prediction"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r1", "columnId": "c4"},
        {"rowId": "r2", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c2"},
        {"rowId": "r3", "columnId": "c1"},
        {"rowId": "r3", "columnId": "c4"},
        {"rowId": "r4", "columnId": "c3"},
        {"rowId": "r4", "columnId": "c4"}
      ],
      "explanation": "Context matters: r=.40 is good for employment; r=.70 is strong for diagnosis and explains substantial variance (49%); r=.25 is typical for personality-job prediction and useful as part of battery; r=.15 is typical but weak for interviews—shouldn't rely on alone.",
      "difficulty": "hard",
      "tags": ["validity coefficient interpretation", "context-specific standards"]
    },
    {
      "type": "cloze_dropdown",
      "id": "d1-cv-cd-001",
      "stem": "Criterion-related validity is evaluated by correlating test scores with a {{blank1}}. When the criterion is measured at the same time as the predictor, this is called {{blank2}} validity. When the criterion is measured later, this is called {{blank3}} validity. The validity coefficient can be corrected for {{blank4}} to estimate true validity.",
      "blanks": [
        {
          "id": "blank1",
          "options": [
            {"id": "a", "text": "criterion measure", "isCorrect": true},
            {"id": "b", "text": "reliability coefficient", "isCorrect": false},
            {"id": "c", "text": "content domain", "isCorrect": false},
            {"id": "d", "text": "factor structure", "isCorrect": false}
          ]
        },
        {
          "id": "blank2",
          "options": [
            {"id": "a", "text": "predictive", "isCorrect": false},
            {"id": "b", "text": "concurrent", "isCorrect": true},
            {"id": "c", "text": "construct", "isCorrect": false},
            {"id": "d", "text": "content", "isCorrect": false}
          ]
        },
        {
          "id": "blank3",
          "options": [
            {"id": "a", "text": "concurrent", "isCorrect": false},
            {"id": "b", "text": "predictive", "isCorrect": true},
            {"id": "c", "text": "incremental", "isCorrect": false},
            {"id": "d", "text": "face", "isCorrect": false}
          ]
        },
        {
          "id": "blank4",
          "options": [
            {"id": "a", "text": "range restriction and unreliability", "isCorrect": true},
            {"id": "b", "text": "sample size", "isCorrect": false},
            {"id": "c", "text": "base rate", "isCorrect": false},
            {"id": "d", "text": "criterion contamination", "isCorrect": false}
          ]
        }
      ],
      "explanation": "Criterion-related validity: correlate predictor with criterion. Concurrent = same time; Predictive = criterion later. Validity coefficients are attenuated by unreliability and range restriction—corrections estimate what validity would be without these artifacts.",
      "difficulty": "hard",
      "tags": ["criterion-related validity", "attenuation correction"]
    },
    {
      "type": "cloze_dropdown",
      "id": "d1-cv-cd-002",
      "stem": "In selection, the {{blank1}} is the proportion of applicants who are hired. The {{blank2}} is the proportion who would succeed without any selection. According to the Taylor-Russell tables, selection utility is greatest when the selection ratio is {{blank3}} and the base rate is around {{blank4}}.",
      "blanks": [
        {
          "id": "blank1",
          "options": [
            {"id": "a", "text": "selection ratio", "isCorrect": true},
            {"id": "b", "text": "base rate", "isCorrect": false},
            {"id": "c", "text": "validity coefficient", "isCorrect": false},
            {"id": "d", "text": "cutoff score", "isCorrect": false}
          ]
        },
        {
          "id": "blank2",
          "options": [
            {"id": "a", "text": "selection ratio", "isCorrect": false},
            {"id": "b", "text": "base rate", "isCorrect": true},
            {"id": "c", "text": "hit rate", "isCorrect": false},
            {"id": "d", "text": "success rate", "isCorrect": false}
          ]
        },
        {
          "id": "blank3",
          "options": [
            {"id": "a", "text": "low (very selective)", "isCorrect": true},
            {"id": "b", "text": "high (select most)", "isCorrect": false},
            {"id": "c", "text": "at .50", "isCorrect": false},
            {"id": "d", "text": "equal to validity", "isCorrect": false}
          ]
        },
        {
          "id": "blank4",
          "options": [
            {"id": "a", "text": ".50", "isCorrect": true},
            {"id": "b", "text": ".10", "isCorrect": false},
            {"id": "c", "text": ".90", "isCorrect": false},
            {"id": "d", "text": "1.00", "isCorrect": false}
          ]
        }
      ],
      "explanation": "Selection ratio = hired/applied. Base rate = natural success rate. Taylor-Russell tables show utility increases with: lower selection ratio (more selective), moderate base rate (~.50, maximum uncertainty), and higher validity. Extreme base rates limit utility regardless of validity.",
      "difficulty": "hard",
      "tags": ["Taylor-Russell", "selection ratio", "base rate"]
    },
    {
      "type": "bowtie",
      "id": "d1-cv-bt-001",
      "stem": "A company develops a new selection test and validates it on current employees (incumbent sample). The validity coefficient is r = .45. When applied to job applicants, the coefficient drops to r = .28.",
      "config": {
        "actionsLabel": "Possible Explanations",
        "conditionLabel": "Core Problem",
        "parametersLabel": "Solutions"
      },
      "options": [
        {"id": "a1", "text": "Incumbent sample has range restriction (low performers already left)", "category": "action", "isCorrect": true},
        {"id": "a2", "text": "Criterion contamination in incumbent study", "category": "action", "isCorrect": true},
        {"id": "a3", "text": "Applicant sample is too large", "category": "action", "isCorrect": false},
        {"id": "a4", "text": "Different criterion measures used", "category": "action", "isCorrect": true},
        {"id": "c1", "text": "Validity shrinkage from development to application sample", "category": "condition", "isCorrect": true},
        {"id": "c2", "text": "The test lacks reliability", "category": "condition", "isCorrect": false},
        {"id": "c3", "text": "Applicants are more motivated", "category": "condition", "isCorrect": false},
        {"id": "p1", "text": "Validate on applicant sample from the start", "category": "parameter", "isCorrect": true},
        {"id": "p2", "text": "Use cross-validation procedures", "category": "parameter", "isCorrect": true},
        {"id": "p3", "text": "Correct for range restriction in incumbent studies", "category": "parameter", "isCorrect": true},
        {"id": "p4", "text": "Use the incumbent validity coefficient for all decisions", "category": "parameter", "isCorrect": false}
      ],
      "explanation": "Incumbent validation inflates validity: range restriction (poor performers gone), possible criterion contamination (supervisors know employees). Validity shrinks when applied to applicants (full range). Solution: validate on applicants, cross-validate, or correct for restriction statistically.",
      "difficulty": "hard",
      "tags": ["incumbent validation", "validity shrinkage", "range restriction"]
    },
    {
      "type": "bowtie",
      "id": "d1-cv-bt-002",
      "stem": "A screening test for depression has sensitivity = .90 and specificity = .60. In a community sample where the base rate of depression is 10%, the test is being considered for universal screening.",
      "config": {
        "actionsLabel": "Test Performance Implications",
        "conditionLabel": "Clinical Reality",
        "parametersLabel": "Recommendations"
      },
      "options": [
        {"id": "a1", "text": "High sensitivity means few depressed individuals will be missed", "category": "action", "isCorrect": true},
        {"id": "a2", "text": "Low specificity means many false positives", "category": "action", "isCorrect": true},
        {"id": "a3", "text": "With 10% base rate, positive predictive value will be low", "category": "action", "isCorrect": true},
        {"id": "a4", "text": "All positive screens will have depression", "category": "action", "isCorrect": false},
        {"id": "c1", "text": "Low base rate + low specificity = many false positive screens", "category": "condition", "isCorrect": true},
        {"id": "c2", "text": "The test is perfect for screening", "category": "condition", "isCorrect": false},
        {"id": "c3", "text": "High sensitivity guarantees high PPV", "category": "condition", "isCorrect": false},
        {"id": "p1", "text": "Use test as first-stage screen followed by diagnostic interview", "category": "parameter", "isCorrect": true},
        {"id": "p2", "text": "Calculate positive predictive value for this base rate", "category": "parameter", "isCorrect": true},
        {"id": "p3", "text": "Consider costs of false positives vs. false negatives", "category": "parameter", "isCorrect": true},
        {"id": "p4", "text": "Diagnose all positive screens without further evaluation", "category": "parameter", "isCorrect": false}
      ],
      "explanation": "With low base rate (10%) and low specificity (60%), most positive screens will be false positives. PPV calculation: Of 1000 people, 100 depressed, 90 detected (TP); 900 non-depressed, 360 false positives. PPV = 90/450 = 20%. Screen should be followed by confirmation, not diagnosis.",
      "difficulty": "hard",
      "tags": ["screening", "base rate effects", "PPV", "false positives"]
    },
    {
      "type": "highlight",
      "id": "d1-cv-hl-001",
      "stem": "Highlight ALL statements that correctly describe predictive validity.",
      "passage": "Predictive validity is a key concept in test validation. [Predictive validity assesses whether a test predicts future performance on a criterion]. [It requires that the predictor and criterion be measured at the same time]. [The validity coefficient represents the correlation between predictor and criterion]. [Higher validity coefficients always indicate a more useful test]. [Predictive validity studies are prospective—they follow examinees over time]. [A test with r = .30 has no practical utility].",
      "highlightableSegments": [
        {"id": "h1", "text": "Predictive validity assesses whether a test predicts future performance on a criterion", "isCorrect": true},
        {"id": "h2", "text": "It requires that the predictor and criterion be measured at the same time", "isCorrect": false},
        {"id": "h3", "text": "The validity coefficient represents the correlation between predictor and criterion", "isCorrect": true},
        {"id": "h4", "text": "Higher validity coefficients always indicate a more useful test", "isCorrect": false},
        {"id": "h5", "text": "Predictive validity studies are prospective—they follow examinees over time", "isCorrect": true},
        {"id": "h6", "text": "A test with r = .30 has no practical utility", "isCorrect": false}
      ],
      "explanation": "True: predictive = future criterion, validity = predictor-criterion correlation, prospective design. False: same-time = concurrent; higher validity isn't always more useful (depends on context, costs); r = .30 has practical utility in selection when combined with low selection ratio.",
      "difficulty": "hard",
      "tags": ["predictive validity", "misconceptions"]
    },
    {
      "type": "highlight",
      "id": "d1-cv-hl-002",
      "stem": "Highlight ALL factors that INCREASE selection utility according to the Taylor-Russell model.",
      "passage": "The Taylor-Russell tables help determine when selection testing adds value. [Higher validity coefficients increase utility]. [Lower selection ratios (being more selective) increase utility]. [Very high base rates (95%) maximize utility]. [Moderate base rates around 50% allow maximum improvement]. [Larger applicant pools allow more selective hiring]. [Low validity tests are never useful regardless of other factors].",
      "highlightableSegments": [
        {"id": "h1", "text": "Higher validity coefficients increase utility", "isCorrect": true},
        {"id": "h2", "text": "Lower selection ratios (being more selective) increase utility", "isCorrect": true},
        {"id": "h3", "text": "Very high base rates (95%) maximize utility", "isCorrect": false},
        {"id": "h4", "text": "Moderate base rates around 50% allow maximum improvement", "isCorrect": true},
        {"id": "h5", "text": "Larger applicant pools allow more selective hiring", "isCorrect": true},
        {"id": "h6", "text": "Low validity tests are never useful regardless of other factors", "isCorrect": false}
      ],
      "explanation": "Utility increases with: higher validity, lower selection ratio, moderate base rate, larger applicant pools. High base rates (95%) mean almost everyone succeeds anyway—no room for improvement. Even low validity tests can be useful with very low selection ratios.",
      "difficulty": "hard",
      "tags": ["Taylor-Russell", "selection utility factors"]
    },
    {
      "type": "drag_drop_ordered",
      "id": "d1-cv-do-001",
      "stem": "Arrange the steps for conducting a predictive validity study in the correct sequence.",
      "items": [
        {"id": "i1", "text": "Administer predictor test to all applicants", "correctPosition": 1},
        {"id": "i2", "text": "Make selection decisions WITHOUT using test scores", "correctPosition": 2},
        {"id": "i3", "text": "Allow time to pass for job performance to occur", "correctPosition": 3},
        {"id": "i4", "text": "Collect criterion data (job performance measures)", "correctPosition": 4},
        {"id": "i5", "text": "Correlate predictor scores with criterion scores", "correctPosition": 5},
        {"id": "i6", "text": "Evaluate magnitude and significance of validity coefficient", "correctPosition": 6}
      ],
      "explanation": "Proper predictive validity: test all applicants → hire without using scores (prevents range restriction) → wait for performance → collect criterion → correlate → evaluate. If scores are used for selection, range restriction attenuates observed validity.",
      "difficulty": "hard",
      "tags": ["predictive validity procedure", "research design"]
    },
    {
      "type": "drag_drop_ordered",
      "id": "d1-cv-do-002",
      "stem": "Arrange these validity coefficient values from SMALLEST to LARGEST explained variance (r²).",
      "items": [
        {"id": "i1", "text": "r = .20 (explains 4% variance)", "correctPosition": 1},
        {"id": "i2", "text": "r = .35 (explains 12% variance)", "correctPosition": 2},
        {"id": "i3", "text": "r = .50 (explains 25% variance)", "correctPosition": 3},
        {"id": "i4", "text": "r = .60 (explains 36% variance)", "correctPosition": 4},
        {"id": "i5", "text": "r = .80 (explains 64% variance)", "correctPosition": 5}
      ],
      "explanation": "Explained variance = r². The relationship is non-linear: r = .20 → 4%, r = .35 → 12%, r = .50 → 25%, r = .60 → 36%, r = .80 → 64%. Note how doubling r more than doubles r² at lower values. Most psychological predictions explain 10-25% variance.",
      "difficulty": "hard",
      "tags": ["r-squared", "explained variance", "validity interpretation"]
    },
    {
      "type": "trend",
      "id": "d1-cv-tr-001",
      "stem": "A researcher examines how validity changes across different selection ratios using Taylor-Russell tables (base rate = .50, validity = .40).",
      "data": {
        "timePoints": ["SR = .90", "SR = .70", "SR = .50", "SR = .30", "SR = .10"],
        "measurements": [
          {"label": "% Success Among Selected", "values": [54, 60, 67, 76, 88]}
        ]
      },
      "question": "What do these data demonstrate about selection utility?",
      "options": [
        {"id": "a", "text": "Selection ratio has no effect on utility", "isCorrect": false},
        {"id": "b", "text": "Lower selection ratios dramatically increase the proportion of successful hires", "isCorrect": true},
        {"id": "c", "text": "Higher selection ratios are always better", "isCorrect": false},
        {"id": "d", "text": "The test is invalid", "isCorrect": false}
      ],
      "explanation": "With same validity (.40) and base rate (.50), lower selection ratios dramatically improve success rates: SR=.90 yields 54% success, SR=.10 yields 88% success. Being more selective (hiring top scorers only) maximizes test utility—but requires large applicant pools.",
      "difficulty": "hard",
      "tags": ["selection ratio effects", "Taylor-Russell", "utility"]
    },
    {
      "type": "trend",
      "id": "d1-cv-tr-002",
      "stem": "A test developer examines how positive predictive value (PPV) changes with base rate for a screening test with sensitivity = .85 and specificity = .80.",
      "data": {
        "timePoints": ["Base Rate 1%", "Base Rate 5%", "Base Rate 10%", "Base Rate 25%", "Base Rate 50%"],
        "measurements": [
          {"label": "Positive Predictive Value (%)", "values": [4, 18, 32, 59, 81]}
        ]
      },
      "question": "What is the key clinical implication of this pattern?",
      "options": [
        {"id": "a", "text": "The test is equally useful at all base rates", "isCorrect": false},
        {"id": "b", "text": "At low base rates, most positive screens are false positives", "isCorrect": true},
        {"id": "c", "text": "Sensitivity and specificity change with base rate", "isCorrect": false},
        {"id": "d", "text": "The test should only be used when base rate is 1%", "isCorrect": false}
      ],
      "explanation": "PPV is dramatically affected by base rate. At 1% base rate, only 4% of positive screens are true positives (96% false positives!). At 50% base rate, 81% are true positives. Screening tests in low-prevalence populations generate many false positives—always follow with confirmatory testing.",
      "difficulty": "hard",
      "tags": ["base rate effects", "PPV", "screening implications"]
    },
    {
      "type": "drag_drop_categorize",
      "id": "d1-cv-dc-001",
      "stem": "Categorize each example as CONCURRENT validity or PREDICTIVE validity.",
      "categories": [
        {"id": "cat1", "name": "Concurrent Validity"},
        {"id": "cat2", "name": "Predictive Validity"}
      ],
      "items": [
        {"id": "i1", "text": "SAT scores correlated with college GPA 4 years later", "correctCategory": "cat2"},
        {"id": "i2", "text": "Depression screening correlated with diagnosis from same-day interview", "correctCategory": "cat1"},
        {"id": "i3", "text": "Cognitive ability test correlated with current job performance ratings", "correctCategory": "cat1"},
        {"id": "i4", "text": "Personality test at hiring correlated with turnover after 2 years", "correctCategory": "cat2"},
        {"id": "i5", "text": "New anxiety scale correlated with established anxiety scale at same session", "correctCategory": "cat1"},
        {"id": "i6", "text": "Risk assessment at intake predicting violence over 6 months", "correctCategory": "cat2"}
      ],
      "explanation": "Concurrent: same-time measurement (screening-interview, current performance, same-session scales). Predictive: time gap between predictor and criterion (SAT-future GPA, hiring test-later turnover, risk assessment-future violence).",
      "difficulty": "hard",
      "tags": ["concurrent vs predictive", "timing"]
    },
    {
      "type": "drag_drop_categorize",
      "id": "d1-cv-dc-002",
      "stem": "Categorize each factor as something that would INCREASE or DECREASE the observed validity coefficient.",
      "categories": [
        {"id": "cat1", "name": "Increases Observed Validity"},
        {"id": "cat2", "name": "Decreases Observed Validity"}
      ],
      "items": [
        {"id": "i1", "text": "Higher reliability of the predictor", "correctCategory": "cat1"},
        {"id": "i2", "text": "Range restriction in predictor scores", "correctCategory": "cat2"},
        {"id": "i3", "text": "Criterion contamination (raters know test scores)", "correctCategory": "cat1"},
        {"id": "i4", "text": "Unreliable criterion measure", "correctCategory": "cat2"},
        {"id": "i5", "text": "Homogeneous sample with little score variability", "correctCategory": "cat2"},
        {"id": "i6", "text": "Using multiple criterion measures", "correctCategory": "cat1"}
      ],
      "explanation": "Increases validity (some artificially): better predictor reliability, criterion contamination (inflates artificially), multiple criteria (composite more reliable). Decreases validity: range restriction, unreliable criterion, homogeneous samples. Distinguish true validity from artifacts.",
      "difficulty": "hard",
      "tags": ["factors affecting validity", "attenuation", "inflation"]
    }
  ]
}
