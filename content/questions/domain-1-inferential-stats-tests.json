{
  "domain": "Domain 1: Psychometrics & Research Methods",
  "domainId": 1,
  "subdomain": "From Samples to Populations \u2014 Inferential Statistics",
  "asppbDomain": 7,
  "questionCount": 26,
  "questions": [
    {
      "type": "single_choice",
      "id": "d1-ist-sc-001",
      "stem": "A researcher compares therapy outcomes across four treatment conditions using a one-way ANOVA and obtains F(3, 76) = 4.82, p = .004. Which conclusion is MOST appropriate?",
      "options": [
        {"id": "a", "text": "All four groups differ significantly from each other", "isCorrect": false},
        {"id": "b", "text": "At least one group mean differs significantly from at least one other", "isCorrect": true},
        {"id": "c", "text": "The first group is significantly different from the fourth group", "isCorrect": false},
        {"id": "d", "text": "The effect size is large", "isCorrect": false}
      ],
      "explanation": "A significant omnibus F-test indicates at least one significant difference exists somewhere among the group means, but doesn't specify which groups differ. Post-hoc tests (e.g., Tukey, Bonferroni) are needed to identify specific pairwise differences. The F-test alone doesn't indicate effect size.",
      "difficulty": "hard",
      "tags": ["ANOVA", "omnibus test", "post-hoc tests"]
    },
    {
      "type": "single_choice",
      "id": "d1-ist-sc-002",
      "stem": "A clinical researcher wants to compare pre-treatment and post-treatment anxiety scores for the SAME participants. Which statistical test is MOST appropriate?",
      "options": [
        {"id": "a", "text": "Independent samples t-test", "isCorrect": false},
        {"id": "b", "text": "Paired samples (dependent) t-test", "isCorrect": true},
        {"id": "c", "text": "One-way ANOVA", "isCorrect": false},
        {"id": "d", "text": "Chi-square test of independence", "isCorrect": false}
      ],
      "explanation": "When the same participants are measured twice (repeated measures/within-subjects design), scores are correlated—the paired t-test accounts for this dependency. Independent samples t-test assumes different participants in each group. ANOVA is for 3+ groups. Chi-square is for categorical data.",
      "difficulty": "hard",
      "tags": ["paired t-test", "repeated measures", "test selection"]
    },
    {
      "type": "single_choice",
      "id": "d1-ist-sc-003",
      "stem": "A researcher reports η² = .14 for a significant ANOVA effect. According to Cohen's guidelines, this represents:",
      "options": [
        {"id": "a", "text": "A small effect size", "isCorrect": false},
        {"id": "b", "text": "A medium effect size", "isCorrect": false},
        {"id": "c", "text": "A large effect size", "isCorrect": true},
        {"id": "d", "text": "Effect size cannot be determined from η²", "isCorrect": false}
      ],
      "explanation": "Cohen's conventions for η² (eta-squared): small = .01, medium = .06, large = .14. An η² of .14 indicates 14% of variance in the DV is explained by group membership—a large effect. This differs from Cohen's d conventions for mean differences.",
      "difficulty": "hard",
      "tags": ["effect size", "eta-squared", "Cohen's guidelines", "ANOVA"]
    },
    {
      "type": "single_choice",
      "id": "d1-ist-sc-004",
      "stem": "In a 2×3 factorial ANOVA, the researcher finds a significant interaction effect. This means:",
      "options": [
        {"id": "a", "text": "Both main effects must also be significant", "isCorrect": false},
        {"id": "b", "text": "The effect of one independent variable depends on the level of the other", "isCorrect": true},
        {"id": "c", "text": "The two independent variables are correlated", "isCorrect": false},
        {"id": "d", "text": "More participants are needed to interpret the results", "isCorrect": false}
      ],
      "explanation": "An interaction means the effect of one IV differs across levels of the other IV—the variables don't have independent, additive effects. Main effects may or may not be significant when an interaction is present. Interactions require examining simple effects or graphing cell means for interpretation.",
      "difficulty": "hard",
      "tags": ["factorial ANOVA", "interaction effect", "simple effects"]
    },
    {
      "type": "single_choice",
      "id": "d1-ist-sc-005",
      "stem": "A researcher conducts 20 independent t-tests, each at α = .05, without correction. The probability of making at least one Type I error across all tests is approximately:",
      "options": [
        {"id": "a", "text": "5%", "isCorrect": false},
        {"id": "b", "text": "64%", "isCorrect": true},
        {"id": "c", "text": "100%", "isCorrect": false},
        {"id": "d", "text": "20%", "isCorrect": false}
      ],
      "explanation": "Family-wise error rate: 1 - (1 - α)^k where k = number of tests. With 20 tests at α = .05: 1 - (0.95)^20 = 1 - 0.36 = 0.64 or 64%. This is why corrections (Bonferroni, Holm, FDR) are needed for multiple comparisons.",
      "difficulty": "hard",
      "tags": ["Type I error", "family-wise error", "multiple comparisons"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-ist-mc-001",
      "stem": "Which assumptions must be met for a valid independent samples t-test? Select all that apply.",
      "options": [
        {"id": "a", "text": "The dependent variable is measured on an interval or ratio scale", "isCorrect": true},
        {"id": "b", "text": "Observations are independent of one another", "isCorrect": true},
        {"id": "c", "text": "The populations from which samples are drawn are normally distributed (or n is large)", "isCorrect": true},
        {"id": "d", "text": "The two groups have equal sample sizes", "isCorrect": false},
        {"id": "e", "text": "The variances of the two populations are equal (homogeneity of variance)", "isCorrect": true}
      ],
      "explanation": "T-test assumptions: interval/ratio DV, independence, normality (relaxed with large n via CLT), homogeneity of variance. Equal sample sizes are NOT required (though unequal n with unequal variances is problematic). Welch's t-test addresses variance heterogeneity.",
      "difficulty": "hard",
      "tags": ["t-test assumptions", "homogeneity of variance", "normality"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-ist-mc-002",
      "stem": "Which statements about statistical power are TRUE? Select all that apply.",
      "options": [
        {"id": "a", "text": "Power is the probability of correctly rejecting a false null hypothesis", "isCorrect": true},
        {"id": "b", "text": "Power increases as sample size increases", "isCorrect": true},
        {"id": "c", "text": "Power increases as effect size increases", "isCorrect": true},
        {"id": "d", "text": "Power increases as alpha level becomes more stringent (e.g., .05 to .01)", "isCorrect": false},
        {"id": "e", "text": "Power is 1 minus the probability of Type II error", "isCorrect": true}
      ],
      "explanation": "Power = 1 - β (probability of detecting true effect). Power increases with larger samples, larger effects, and less stringent (larger) alpha. Making alpha more stringent (.05→.01) DECREASES power by requiring stronger evidence to reject H₀.",
      "difficulty": "hard",
      "tags": ["statistical power", "Type II error", "factors affecting power"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-ist-mc-003",
      "stem": "A researcher uses chi-square test of independence. Which statements about this test are TRUE? Select all that apply.",
      "options": [
        {"id": "a", "text": "Both variables must be categorical (nominal or ordinal)", "isCorrect": true},
        {"id": "b", "text": "Expected cell frequencies should generally be at least 5", "isCorrect": true},
        {"id": "c", "text": "The test evaluates whether the two variables are associated", "isCorrect": true},
        {"id": "d", "text": "A significant result indicates the direction of the relationship", "isCorrect": false},
        {"id": "e", "text": "Cramér's V can be used to measure effect size", "isCorrect": true}
      ],
      "explanation": "Chi-square requirements: categorical variables, adequate expected frequencies (≥5 rule of thumb), independence. It tests association existence but doesn't indicate direction or pattern—examine the contingency table. Cramér's V is the standard effect size measure.",
      "difficulty": "hard",
      "tags": ["chi-square", "categorical data", "Cramér's V"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-ist-mc-004",
      "stem": "When would a non-parametric test be preferred over its parametric equivalent? Select all that apply.",
      "options": [
        {"id": "a", "text": "The dependent variable is measured on an ordinal scale", "isCorrect": true},
        {"id": "b", "text": "The sample size is very small and normality cannot be assumed", "isCorrect": true},
        {"id": "c", "text": "The data contain significant outliers that cannot be removed", "isCorrect": true},
        {"id": "d", "text": "The research design uses random assignment", "isCorrect": false},
        {"id": "e", "text": "Variance homogeneity assumption is severely violated", "isCorrect": true}
      ],
      "explanation": "Non-parametric tests (Mann-Whitney, Kruskal-Wallis, Wilcoxon) are appropriate for: ordinal data, small samples where normality is questionable, outlier-prone data, and variance heterogeneity. Random assignment doesn't determine parametric vs. non-parametric choice.",
      "difficulty": "hard",
      "tags": ["non-parametric tests", "assumptions", "test selection"]
    },
    {
      "type": "multiple_choice",
      "id": "d1-ist-mc-005",
      "stem": "Which procedures appropriately control for family-wise error rate in multiple comparisons? Select all that apply.",
      "options": [
        {"id": "a", "text": "Bonferroni correction (α/k)", "isCorrect": true},
        {"id": "b", "text": "Tukey's HSD for post-hoc pairwise comparisons", "isCorrect": true},
        {"id": "c", "text": "Holm-Bonferroni sequential procedure", "isCorrect": true},
        {"id": "d", "text": "Using a larger sample size", "isCorrect": false},
        {"id": "e", "text": "Planned orthogonal contrasts with limited number of comparisons", "isCorrect": true}
      ],
      "explanation": "Family-wise error control: Bonferroni (conservative), Tukey HSD (all pairwise), Holm (sequential, less conservative than Bonferroni), orthogonal contrasts (limit comparisons to k-1). Larger samples increase power but don't control Type I error inflation.",
      "difficulty": "hard",
      "tags": ["multiple comparisons", "Bonferroni", "Tukey", "family-wise error"]
    },
    {
      "type": "matrix_single",
      "id": "d1-ist-ms-001",
      "stem": "Match each research scenario with the MOST appropriate statistical test.",
      "rows": [
        {"id": "r1", "text": "Comparing mean depression scores between two independent treatment groups"},
        {"id": "r2", "text": "Comparing anxiety scores before and after treatment in the same participants"},
        {"id": "r3", "text": "Comparing mean IQ across four ethnic groups"},
        {"id": "r4", "text": "Testing if diagnosis category (yes/no) is related to gender (male/female)"}
      ],
      "columns": [
        {"id": "c1", "text": "Independent samples t-test"},
        {"id": "c2", "text": "Paired samples t-test"},
        {"id": "c3", "text": "One-way ANOVA"},
        {"id": "c4", "text": "Chi-square test"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c2"},
        {"rowId": "r3", "columnId": "c3"},
        {"rowId": "r4", "columnId": "c4"}
      ],
      "explanation": "Independent t-test: two independent groups, continuous DV. Paired t-test: same participants, two time points. One-way ANOVA: 3+ independent groups, continuous DV. Chi-square: both variables categorical, testing association.",
      "difficulty": "hard",
      "tags": ["test selection", "research design"]
    },
    {
      "type": "matrix_single",
      "id": "d1-ist-ms-002",
      "stem": "Match each statistical term with its correct definition.",
      "rows": [
        {"id": "r1", "text": "Type I error"},
        {"id": "r2", "text": "Type II error"},
        {"id": "r3", "text": "Statistical power"},
        {"id": "r4", "text": "Effect size"}
      ],
      "columns": [
        {"id": "c1", "text": "Rejecting a true null hypothesis (false positive)"},
        {"id": "c2", "text": "Failing to reject a false null hypothesis (false negative)"},
        {"id": "c3", "text": "Probability of correctly rejecting false null"},
        {"id": "c4", "text": "Magnitude of the phenomenon being studied"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c2"},
        {"rowId": "r3", "columnId": "c3"},
        {"rowId": "r4", "columnId": "c4"}
      ],
      "explanation": "Type I (α): false positive, conclude effect exists when it doesn't. Type II (β): false negative, miss real effect. Power (1-β): probability of detecting true effect. Effect size: standardized measure of magnitude independent of sample size.",
      "difficulty": "hard",
      "tags": ["Type I error", "Type II error", "power", "effect size definitions"]
    },
    {
      "type": "matrix_multiple",
      "id": "d1-ist-mm-001",
      "stem": "For each statistical test, select ALL assumptions that apply.",
      "rows": [
        {"id": "r1", "text": "Independent samples t-test"},
        {"id": "r2", "text": "One-way ANOVA"},
        {"id": "r3", "text": "Chi-square test of independence"},
        {"id": "r4", "text": "Pearson correlation"}
      ],
      "columns": [
        {"id": "c1", "text": "Normality"},
        {"id": "c2", "text": "Homogeneity of variance"},
        {"id": "c3", "text": "Independence of observations"},
        {"id": "c4", "text": "Continuous DV"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r1", "columnId": "c2"},
        {"rowId": "r1", "columnId": "c3"},
        {"rowId": "r1", "columnId": "c4"},
        {"rowId": "r2", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c2"},
        {"rowId": "r2", "columnId": "c3"},
        {"rowId": "r2", "columnId": "c4"},
        {"rowId": "r3", "columnId": "c3"},
        {"rowId": "r4", "columnId": "c1"},
        {"rowId": "r4", "columnId": "c3"},
        {"rowId": "r4", "columnId": "c4"}
      ],
      "explanation": "T-test and ANOVA share assumptions: normality, homogeneity of variance, independence, continuous DV. Chi-square requires only independence (and adequate expected frequencies)—no normality or variance assumptions for categorical data. Correlation assumes normality, independence, and continuous/interval data.",
      "difficulty": "hard",
      "tags": ["assumptions", "test comparison"]
    },
    {
      "type": "matrix_multiple",
      "id": "d1-ist-mm-002",
      "stem": "Select ALL factors that increase statistical power.",
      "rows": [
        {"id": "r1", "text": "Increasing sample size"},
        {"id": "r2", "text": "Using a more lenient alpha level (e.g., .10 instead of .05)"},
        {"id": "r3", "text": "Using a one-tailed instead of two-tailed test"},
        {"id": "r4", "text": "Reducing measurement error (increasing reliability)"}
      ],
      "columns": [
        {"id": "c1", "text": "Increases power"},
        {"id": "c2", "text": "Decreases power"},
        {"id": "c3", "text": "Increases Type I error risk"},
        {"id": "c4", "text": "Appropriate when direction is predicted"}
      ],
      "correctAnswers": [
        {"rowId": "r1", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c1"},
        {"rowId": "r2", "columnId": "c3"},
        {"rowId": "r3", "columnId": "c1"},
        {"rowId": "r3", "columnId": "c3"},
        {"rowId": "r3", "columnId": "c4"},
        {"rowId": "r4", "columnId": "c1"}
      ],
      "explanation": "All four increase power. BUT: lenient alpha and one-tailed tests also increase Type I error risk—they're not 'free' power increases. One-tailed tests are only appropriate when direction is firmly predicted. Larger n and better reliability increase power without inflating Type I error.",
      "difficulty": "hard",
      "tags": ["power", "Type I error tradeoff", "sample size"]
    },
    {
      "type": "cloze_dropdown",
      "id": "d1-ist-cd-001",
      "stem": "The F-ratio in ANOVA is calculated as {{blank1}} divided by {{blank2}}. A larger F-ratio indicates that {{blank3}}. The F-ratio is always {{blank4}}.",
      "blanks": [
        {
          "id": "blank1",
          "options": [
            {"id": "a", "text": "between-groups variance (MSB)", "isCorrect": true},
            {"id": "b", "text": "within-groups variance (MSW)", "isCorrect": false},
            {"id": "c", "text": "total variance", "isCorrect": false},
            {"id": "d", "text": "error variance", "isCorrect": false}
          ]
        },
        {
          "id": "blank2",
          "options": [
            {"id": "a", "text": "between-groups variance (MSB)", "isCorrect": false},
            {"id": "b", "text": "within-groups variance/error (MSW)", "isCorrect": true},
            {"id": "c", "text": "total sample size", "isCorrect": false},
            {"id": "d", "text": "number of groups", "isCorrect": false}
          ]
        },
        {
          "id": "blank3",
          "options": [
            {"id": "a", "text": "group means differ more than expected by chance", "isCorrect": true},
            {"id": "b", "text": "within-group variability is high", "isCorrect": false},
            {"id": "c", "text": "the null hypothesis is true", "isCorrect": false},
            {"id": "d", "text": "sample sizes are unequal", "isCorrect": false}
          ]
        },
        {
          "id": "blank4",
          "options": [
            {"id": "a", "text": "positive or zero (never negative)", "isCorrect": true},
            {"id": "b", "text": "between -1 and +1", "isCorrect": false},
            {"id": "c", "text": "negative when groups differ", "isCorrect": false},
            {"id": "d", "text": "equal to the t-statistic squared", "isCorrect": false}
          ]
        }
      ],
      "explanation": "F = MSB/MSW (between-groups variance ÷ within-groups variance). Large F means groups differ more than chance variation would produce. Since variances are always positive, F is always ≥ 0. F near 1 indicates null hypothesis plausibility; F >> 1 suggests group differences.",
      "difficulty": "hard",
      "tags": ["F-ratio", "ANOVA components", "variance"]
    },
    {
      "type": "cloze_dropdown",
      "id": "d1-ist-cd-002",
      "stem": "When a t-test yields t(48) = 2.45, p = .018, the \"48\" refers to {{blank1}}. The p-value of .018 means {{blank2}}. If the researcher set α = .05, the result is {{blank3}}. To determine practical importance, the researcher should also calculate {{blank4}}.",
      "blanks": [
        {
          "id": "blank1",
          "options": [
            {"id": "a", "text": "degrees of freedom", "isCorrect": true},
            {"id": "b", "text": "sample size", "isCorrect": false},
            {"id": "c", "text": "the number of groups", "isCorrect": false},
            {"id": "d", "text": "effect size", "isCorrect": false}
          ]
        },
        {
          "id": "blank2",
          "options": [
            {"id": "a", "text": "there is a 1.8% probability the null hypothesis is true", "isCorrect": false},
            {"id": "b", "text": "if H₀ is true, there's a 1.8% chance of getting results this extreme", "isCorrect": true},
            {"id": "c", "text": "the effect explains 1.8% of variance", "isCorrect": false},
            {"id": "d", "text": "the probability of a Type II error is 1.8%", "isCorrect": false}
          ]
        },
        {
          "id": "blank3",
          "options": [
            {"id": "a", "text": "statistically significant (reject H₀)", "isCorrect": true},
            {"id": "b", "text": "not statistically significant (retain H₀)", "isCorrect": false},
            {"id": "c", "text": "inconclusive", "isCorrect": false},
            {"id": "d", "text": "practically significant", "isCorrect": false}
          ]
        },
        {
          "id": "blank4",
          "options": [
            {"id": "a", "text": "additional p-values", "isCorrect": false},
            {"id": "b", "text": "effect size (e.g., Cohen's d)", "isCorrect": true},
            {"id": "c", "text": "sample size", "isCorrect": false},
            {"id": "d", "text": "the mean", "isCorrect": false}
          ]
        }
      ],
      "explanation": "df = 48 (for independent t-test, df = n₁ + n₂ - 2). P-value is probability of data given H₀ true—NOT probability H₀ is true. p < α means significant. Effect size (Cohen's d) indicates practical importance beyond statistical significance.",
      "difficulty": "hard",
      "tags": ["p-value interpretation", "degrees of freedom", "effect size", "significance"]
    },
    {
      "type": "bowtie",
      "id": "d1-ist-bt-001",
      "stem": "A researcher compares three therapy approaches with n=15 per group. ANOVA yields F(2, 42) = 3.15, p = .053. The researcher concludes there are no differences between treatments and abandons the research line.",
      "config": {
        "actionsLabel": "Problems with Conclusion",
        "conditionLabel": "Statistical Issue",
        "parametersLabel": "Better Approaches"
      },
      "options": [
        {"id": "a1", "text": "Study may be underpowered to detect meaningful effects", "category": "action", "isCorrect": true},
        {"id": "a2", "text": "p = .053 is marginally significant and shouldn't be dismissed entirely", "category": "action", "isCorrect": true},
        {"id": "a3", "text": "Effect size should be examined regardless of p-value", "category": "action", "isCorrect": true},
        {"id": "a4", "text": "The ANOVA assumptions were likely violated", "category": "action", "isCorrect": false},
        {"id": "c1", "text": "Confusing non-significant with 'no effect' (accepting null)", "category": "condition", "isCorrect": true},
        {"id": "c2", "text": "Too many comparisons inflated Type I error", "category": "condition", "isCorrect": false},
        {"id": "c3", "text": "The F-ratio was calculated incorrectly", "category": "condition", "isCorrect": false},
        {"id": "p1", "text": "Conduct power analysis and consider replication with larger n", "category": "parameter", "isCorrect": true},
        {"id": "p2", "text": "Report and interpret effect sizes", "category": "parameter", "isCorrect": true},
        {"id": "p3", "text": "Use a more stringent alpha level", "category": "parameter", "isCorrect": false},
        {"id": "p4", "text": "Consider confidence intervals for treatment differences", "category": "parameter", "isCorrect": true}
      ],
      "explanation": "The researcher made the classic error of accepting the null hypothesis from a non-significant result. With small samples (n=15/group), the study may lack power. Effect sizes should be examined; p = .053 is very close to α. Non-significant ≠ no effect—absence of evidence isn't evidence of absence.",
      "difficulty": "hard",
      "tags": ["null hypothesis interpretation", "power", "effect size", "p-value"]
    },
    {
      "type": "bowtie",
      "id": "d1-ist-bt-002",
      "stem": "A researcher finds that a new treatment produces statistically significant improvement over control: t(398) = 2.10, p = .036, Cohen's d = 0.21. The researcher claims this proves the treatment is highly effective.",
      "config": {
        "actionsLabel": "Interpretation Problems",
        "conditionLabel": "Statistical Reality",
        "parametersLabel": "Appropriate Conclusions"
      },
      "options": [
        {"id": "a1", "text": "Cohen's d = 0.21 represents only a small effect size", "category": "action", "isCorrect": true},
        {"id": "a2", "text": "Large sample size made a trivial difference significant", "category": "action", "isCorrect": true},
        {"id": "a3", "text": "Statistical significance doesn't equal clinical/practical significance", "category": "action", "isCorrect": true},
        {"id": "a4", "text": "The p-value is too large to be meaningful", "category": "action", "isCorrect": false},
        {"id": "c1", "text": "High power detected a real but small effect", "category": "condition", "isCorrect": true},
        {"id": "c2", "text": "Type I error is likely", "category": "condition", "isCorrect": false},
        {"id": "c3", "text": "The statistics were computed incorrectly", "category": "condition", "isCorrect": false},
        {"id": "p1", "text": "The treatment produces a statistically reliable but small improvement", "category": "parameter", "isCorrect": true},
        {"id": "p2", "text": "Clinical significance and cost-benefit should be evaluated", "category": "parameter", "isCorrect": true},
        {"id": "p3", "text": "The treatment is highly effective", "category": "parameter", "isCorrect": false},
        {"id": "p4", "text": "Results should be replicated before implementation", "category": "parameter", "isCorrect": true}
      ],
      "explanation": "This illustrates the distinction between statistical and practical significance. With n=400, even small effects become statistically significant. Cohen's d = 0.21 is a small effect. The treatment works (reliably different from control) but the effect may not be clinically meaningful.",
      "difficulty": "hard",
      "tags": ["statistical vs practical significance", "effect size interpretation", "large samples"]
    },
    {
      "type": "highlight",
      "id": "d1-ist-hl-001",
      "stem": "Highlight ALL correct statements about statistical significance testing.",
      "passage": "[A p-value of .03 means there is a 3% probability that the null hypothesis is true]. [If p < α, we reject the null hypothesis]. Statistical significance depends on both effect size and sample size. [A statistically significant result is always practically important]. [The alpha level should be set before data collection]. [With large enough samples, even trivial effects become statistically significant]. [A non-significant result proves the null hypothesis is true].",
      "highlightableSegments": [
        {"id": "h1", "text": "A p-value of .03 means there is a 3% probability that the null hypothesis is true", "isCorrect": false},
        {"id": "h2", "text": "If p < α, we reject the null hypothesis", "isCorrect": true},
        {"id": "h3", "text": "A statistically significant result is always practically important", "isCorrect": false},
        {"id": "h4", "text": "The alpha level should be set before data collection", "isCorrect": true},
        {"id": "h5", "text": "With large enough samples, even trivial effects become statistically significant", "isCorrect": true},
        {"id": "h6", "text": "A non-significant result proves the null hypothesis is true", "isCorrect": false}
      ],
      "explanation": "Correct: p < α → reject H₀; set α a priori; large n detects tiny effects. Incorrect: p-value is NOT probability H₀ is true (common misconception); significant ≠ important; non-significant doesn't prove H₀ (fails to reject ≠ accept).",
      "difficulty": "hard",
      "tags": ["p-value misconceptions", "significance testing"]
    },
    {
      "type": "highlight",
      "id": "d1-ist-hl-002",
      "stem": "Highlight ALL statements that correctly describe when to use non-parametric tests.",
      "passage": "Non-parametric tests are alternatives to parametric tests that make fewer distributional assumptions. [Use non-parametric tests when the dependent variable is ordinal rather than interval/ratio]. [Non-parametric tests should be used whenever sample sizes are very large]. [Use non-parametric tests when the normality assumption is severely violated and sample size is small]. [The Mann-Whitney U test is the non-parametric alternative to the independent samples t-test]. [Non-parametric tests are always more powerful than parametric tests]. [Use non-parametric tests when data contain extreme outliers that cannot be addressed].",
      "highlightableSegments": [
        {"id": "h1", "text": "Use non-parametric tests when the dependent variable is ordinal rather than interval/ratio", "isCorrect": true},
        {"id": "h2", "text": "Non-parametric tests should be used whenever sample sizes are very large", "isCorrect": false},
        {"id": "h3", "text": "Use non-parametric tests when the normality assumption is severely violated and sample size is small", "isCorrect": true},
        {"id": "h4", "text": "The Mann-Whitney U test is the non-parametric alternative to the independent samples t-test", "isCorrect": true},
        {"id": "h5", "text": "Non-parametric tests are always more powerful than parametric tests", "isCorrect": false},
        {"id": "h6", "text": "Use non-parametric tests when data contain extreme outliers that cannot be addressed", "isCorrect": true}
      ],
      "explanation": "Appropriate: ordinal data, violated normality with small n, outliers, and Mann-Whitney as t-test alternative. Incorrect: large samples don't require non-parametric (CLT helps); parametric tests are typically MORE powerful when assumptions are met.",
      "difficulty": "hard",
      "tags": ["non-parametric tests", "test selection", "assumptions"]
    },
    {
      "type": "drag_drop_ordered",
      "id": "d1-ist-do-001",
      "stem": "Arrange the steps of null hypothesis significance testing (NHST) in the correct sequence.",
      "items": [
        {"id": "i1", "text": "State the null and alternative hypotheses", "correctPosition": 1},
        {"id": "i2", "text": "Set the significance level (alpha) before collecting data", "correctPosition": 2},
        {"id": "i3", "text": "Select the appropriate statistical test", "correctPosition": 3},
        {"id": "i4", "text": "Collect data and compute the test statistic", "correctPosition": 4},
        {"id": "i5", "text": "Determine the p-value or compare test statistic to critical value", "correctPosition": 5},
        {"id": "i6", "text": "Make decision: reject or fail to reject H₀", "correctPosition": 6}
      ],
      "explanation": "NHST follows a strict sequence: hypotheses first, then alpha (a priori), test selection, data collection, compute statistic, compare to criterion, decision. Setting alpha after seeing results (p-hacking) is a serious methodological error.",
      "difficulty": "hard",
      "tags": ["NHST procedure", "hypothesis testing steps"]
    },
    {
      "type": "drag_drop_ordered",
      "id": "d1-ist-do-002",
      "stem": "Arrange these effect sizes from SMALLEST to LARGEST according to Cohen's conventions.",
      "items": [
        {"id": "i1", "text": "Cohen's d = 0.15", "correctPosition": 1},
        {"id": "i2", "text": "η² = .01", "correctPosition": 2},
        {"id": "i3", "text": "r = .25", "correctPosition": 3},
        {"id": "i4", "text": "Cohen's d = 0.50", "correctPosition": 4},
        {"id": "i5", "text": "η² = .14", "correctPosition": 5},
        {"id": "i6", "text": "Cohen's d = 0.95", "correctPosition": 6}
      ],
      "explanation": "Cohen's conventions: d (small=.20, medium=.50, large=.80); r (small=.10, medium=.30, large=.50); η² (small=.01, medium=.06, large=.14). Converting: d=0.15 < η²=.01 (small) < r=.25 (medium) < d=0.50 (medium) < η²=.14 (large) < d=0.95 (large).",
      "difficulty": "hard",
      "tags": ["effect size conventions", "Cohen's guidelines"]
    },
    {
      "type": "trend",
      "id": "d1-ist-tr-001",
      "stem": "A researcher conducts power analyses for different sample sizes to detect a medium effect (d = 0.50) with α = .05.",
      "data": {
        "timePoints": ["n=20/group", "n=40/group", "n=64/group", "n=100/group", "n=150/group"],
        "measurements": [
          {"label": "Power", "values": [0.34, 0.60, 0.80, 0.94, 0.99]}
        ]
      },
      "question": "Based on this power analysis, what is the MINIMUM sample size per group needed to achieve the conventional 80% power level?",
      "options": [
        {"id": "a", "text": "20 per group", "isCorrect": false},
        {"id": "b", "text": "40 per group", "isCorrect": false},
        {"id": "c", "text": "64 per group", "isCorrect": true},
        {"id": "d", "text": "100 per group", "isCorrect": false}
      ],
      "explanation": "The conventional standard for adequate power is 80% (power = .80). With n=64 per group, power reaches exactly .80 for detecting a medium effect. n=40 yields only 60% power (40% chance of missing a true effect). This table illustrates why a priori power analysis is essential.",
      "difficulty": "hard",
      "tags": ["power analysis", "sample size determination"]
    },
    {
      "type": "trend",
      "id": "d1-ist-tr-002",
      "stem": "A researcher examines how p-values change as sample size increases while the true effect remains constant (d = 0.30).",
      "data": {
        "timePoints": ["n=30", "n=60", "n=120", "n=200", "n=400"],
        "measurements": [
          {"label": "p-value", "values": [0.28, 0.11, 0.02, 0.003, 0.0001]},
          {"label": "Effect size (d)", "values": [0.30, 0.30, 0.30, 0.30, 0.30]}
        ]
      },
      "question": "These data best illustrate which principle of statistical testing?",
      "options": [
        {"id": "a", "text": "Larger samples produce larger effect sizes", "isCorrect": false},
        {"id": "b", "text": "Significance depends on both effect size AND sample size", "isCorrect": true},
        {"id": "c", "text": "P-values indicate the magnitude of the effect", "isCorrect": false},
        {"id": "d", "text": "Smaller p-values indicate more important findings", "isCorrect": false}
      ],
      "explanation": "The effect size remains constant (d=0.30, a small effect), but p-values drop as n increases. This shows significance depends on sample size—with enough participants, even small effects become significant. This is why effect sizes should always be reported alongside p-values.",
      "difficulty": "hard",
      "tags": ["sample size", "p-value", "effect size independence"]
    },
    {
      "type": "drag_drop_categorize",
      "id": "d1-ist-dc-001",
      "stem": "Categorize each statistical test by the number of groups/conditions it compares.",
      "categories": [
        {"id": "cat1", "name": "Compares Two Groups/Conditions"},
        {"id": "cat2", "name": "Compares Three or More Groups"},
        {"id": "cat3", "name": "Tests Association (Not Group Comparison)"}
      ],
      "items": [
        {"id": "i1", "text": "Independent samples t-test", "correctCategory": "cat1"},
        {"id": "i2", "text": "Paired samples t-test", "correctCategory": "cat1"},
        {"id": "i3", "text": "One-way ANOVA", "correctCategory": "cat2"},
        {"id": "i4", "text": "Pearson correlation", "correctCategory": "cat3"},
        {"id": "i5", "text": "Chi-square test of independence", "correctCategory": "cat3"},
        {"id": "i6", "text": "Repeated measures ANOVA", "correctCategory": "cat2"},
        {"id": "i7", "text": "Mann-Whitney U test", "correctCategory": "cat1"},
        {"id": "i8", "text": "Kruskal-Wallis test", "correctCategory": "cat2"}
      ],
      "explanation": "Two groups: independent t, paired t, Mann-Whitney. 3+ groups: one-way ANOVA, repeated measures ANOVA, Kruskal-Wallis. Association tests: correlation, chi-square (test relationship between variables, not group differences).",
      "difficulty": "hard",
      "tags": ["test classification", "group comparisons", "association tests"]
    },
    {
      "type": "drag_drop_categorize",
      "id": "d1-ist-dc-002",
      "stem": "Categorize each scenario as involving Type I Error, Type II Error, or Correct Decision.",
      "categories": [
        {"id": "cat1", "name": "Type I Error (False Positive)"},
        {"id": "cat2", "name": "Type II Error (False Negative)"},
        {"id": "cat3", "name": "Correct Decision"}
      ],
      "items": [
        {"id": "i1", "text": "Treatment has no effect; study concludes it's effective (p < .05)", "correctCategory": "cat1"},
        {"id": "i2", "text": "Treatment is truly effective; study concludes it's effective", "correctCategory": "cat3"},
        {"id": "i3", "text": "Treatment is truly effective; underpowered study fails to find significance", "correctCategory": "cat2"},
        {"id": "i4", "text": "Treatment has no effect; study correctly finds no significant effect", "correctCategory": "cat3"},
        {"id": "i5", "text": "New drug is actually harmful; FDA approves it based on significant benefits", "correctCategory": "cat1"},
        {"id": "i6", "text": "Promising drug effect missed due to small sample size", "correctCategory": "cat2"}
      ],
      "explanation": "Type I: reject true H₀ (false positive)—conclude effect when none exists. Type II: fail to reject false H₀ (false negative)—miss real effect. Correct decisions: reject false H₀ (detect real effect) or retain true H₀ (correctly find nothing).",
      "difficulty": "hard",
      "tags": ["Type I error", "Type II error", "decision outcomes"]
    }
  ]
}
