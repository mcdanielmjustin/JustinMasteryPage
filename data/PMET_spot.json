{
  "domain_code": "PMET",
  "domain_name": "Psychometrics & Research Methods",
  "total_questions": 185,
  "questions": [
    {
      "id": "PMET-VD-0001",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Setting Cutoff Scores",
      "passage_type": "definition",
      "source_passage_id": "PMET-0081",
      "entries": [
        {
          "term": "Sensitivity",
          "definition": "Sensitivity refers to the ability of a test to correctly identify individuals who truly have the condition (true positives). A test with high sensitivity will have a low rate of false negatives, meaning fewer cases are missed. Sensitivity is particularly important when the cost of missing a true case is high.",
          "is_target": false
        },
        {
          "term": "Specificity",
          "definition": "Specificity refers to the ability of a test to correctly identify individuals who truly do not have the condition (true negatives). A test with high specificity will have a low rate of false positives, meaning fewer false alarms occur. Specificity is prioritized when the consequences of incorrectly labeling someone as positive are severe.",
          "is_target": false
        },
        {
          "term": "Cutoff Score Selection",
          "definition": "Cutoff score selection involves choosing a threshold on a test that balances sensitivity and specificity based on the purpose of the assessment. A higher cutoff score increases sensitivity by capturing more true positives while decreasing specificity through more false positives. The optimal cutoff depends on whether missing true cases or generating false alarms carries a greater cost.",
          "is_target": true
        },
        {
          "term": "Positive Predictive Value",
          "definition": "Positive predictive value (PPV) is the proportion of individuals who test positive who actually have the condition. PPV depends not only on the test's sensitivity and specificity but also on the base rate of the condition in the population. When base rates are low, even highly specific tests can produce a relatively low PPV.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "A higher cutoff score increases sensitivity by capturing more true positives while decreasing specificity through more false positives",
      "error_correct": "A lower cutoff score increases sensitivity by capturing more true positives while decreasing specificity through more false positives",
      "explanation": "The definition incorrectly states that a higher cutoff score increases sensitivity. In reality, a LOWER cutoff score increases sensitivity (more true positives) at the expense of specificity (more false positives). A HIGHER cutoff score does the opposite — it increases specificity (more true negatives) while decreasing sensitivity (more false negatives)."
    },
    {
      "id": "PMET-VD-0002",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Coefficient of Determination (r²)",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0051",
      "entries": [
        {
          "term": "Standard Error of Estimate",
          "definition": "The standard error of estimate is a measure of the accuracy of predictions made with a regression equation. It quantifies the average distance that observed values fall from the regression line, with smaller values indicating more accurate predictions.",
          "is_target": false
        },
        {
          "term": "Coefficient of Determination (r²)",
          "definition": "The coefficient of determination (r²) is obtained by taking the square root of the correlation coefficient. It represents the proportion of variance in one variable that is explained by or shared with the other variable. This value is also referred to as shared variance or common variance.",
          "is_target": true
        },
        {
          "term": "Correlation Coefficient (r)",
          "definition": "The correlation coefficient (r) is a statistical measure that quantifies the strength and direction of the linear relationship between two variables. Its values range from -1.00 to +1.00, where values closer to the extremes indicate stronger relationships.",
          "is_target": false
        },
        {
          "term": "Coefficient of Alienation (k²)",
          "definition": "The coefficient of alienation (k²) represents the proportion of variance in one variable that is not explained by the other variable. It is calculated by subtracting the coefficient of determination from 1.00 and reflects unexplained or error variance.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "obtained by taking the square root of the correlation coefficient",
      "error_correct": "obtained by squaring the correlation coefficient",
      "explanation": "The coefficient of determination (r²) is obtained by squaring the correlation coefficient (r), not by taking its square root. For example, if r = .80, then r² = .64, meaning 64% of the variance in one variable is explained by the other. Taking the square root would be the reverse operation—used to derive r from r²."
    },
    {
      "id": "PMET-VD-0003",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Analysis of Covariance (ANCOVA)",
      "passage_type": "definition",
      "source_passage_id": "PMET-0114",
      "entries": [
        {
          "term": "MANCOVA",
          "definition": "An extension of ANCOVA used when there are two or more dependent variables. It statistically controls for one or more covariates while simultaneously analyzing multiple DVs, helping to reduce the risk of Type I error from running multiple separate ANCOVAs.",
          "is_target": false
        },
        {
          "term": "ANCOVA",
          "definition": "A statistical technique used to control for confounding variables that cannot be controlled experimentally by including them as covariates. It reduces between-group error variance, thereby increasing statistical power. A key assumption is homogeneity of regression slopes, meaning the relationship between the covariate and the DV must be similar across groups.",
          "is_target": true
        },
        {
          "term": "ANOVA",
          "definition": "A statistical technique used to compare means across two or more groups by partitioning total variance into between-group and within-group components. It tests whether group means differ significantly and assumes homogeneity of variance, independence of observations, and normality of distributions.",
          "is_target": false
        },
        {
          "term": "Repeated Measures ANOVA",
          "definition": "A variant of ANOVA used when the same participants are measured under multiple conditions or at multiple time points. It accounts for the correlation between repeated observations on the same subjects, thereby reducing error variance associated with individual differences.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "reduces between-group error variance",
      "error_correct": "reduces within-group error variance",
      "explanation": "ANCOVA works by statistically removing variability associated with the covariate, which reduces within-group (not between-group) error variance. By reducing within-group error variance, the F-ratio becomes larger, thereby increasing statistical power to detect true group differences."
    },
    {
      "id": "PMET-VD-0004",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Standard Error of the Difference",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0233",
      "entries": [
        {
          "term": "Standard Error of Measurement (SEM)",
          "definition": "An estimate of the amount of error in an individual's observed test score. It is derived from the test's standard deviation and its reliability coefficient, and is used to construct confidence intervals around an observed score.",
          "is_target": false
        },
        {
          "term": "Standard Error of the Difference (SEdiff)",
          "definition": "A statistic used when comparing two scores (e.g., Verbal IQ vs. Performance IQ, or pretest vs. posttest) to determine whether the difference between them is clinically meaningful. It is calculated by taking the square root of the product of the two standard errors of measurement.",
          "is_target": true
        },
        {
          "term": "Standard Error of the Mean (SEMean)",
          "definition": "An estimate of how much a sample mean is expected to vary from the true population mean. It is calculated by dividing the sample standard deviation by the square root of the sample size, and decreases as sample size increases.",
          "is_target": false
        },
        {
          "term": "Standard Error of Estimate (SEest)",
          "definition": "A measure of the accuracy of predictions made using a regression equation. It reflects the average distance that observed values fall from the regression line and is derived from the correlation coefficient and the standard deviation of the criterion variable.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "the square root of the product of the two standard errors of measurement",
      "error_correct": "the square root of the sum of the two squared standard errors of measurement",
      "explanation": "The SEdiff is calculated by taking the square root of the SUM of the two squared SEMs (i.e., SEdiff = √(SEM₁² + SEM₂²)), not the square root of their product. This formula is based on the principle that variances of independent errors are additive. The error subtly swaps 'sum of the squared' for 'product of the,' which would yield incorrect values and represents a wrong computational mechanism."
    },
    {
      "id": "PMET-VD-0005",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0434",
      "entries": [
        {
          "term": "Standard Error of Measurement",
          "definition": "A statistic that estimates the amount of error in an individual's observed test score. It is derived from the test's reliability coefficient and the standard deviation of the test scores, and it is used to construct confidence intervals around observed scores.",
          "is_target": false
        },
        {
          "term": "Standard Error of Estimate",
          "definition": "A measure of prediction accuracy in regression analysis that indicates the average amount by which predicted scores deviate from actual scores. It increases as the correlation coefficient (r) increases, reflecting less variability around the regression line.",
          "is_target": true
        },
        {
          "term": "Standard Error of the Mean",
          "definition": "A statistic that estimates how much a sample mean is likely to differ from the population mean. It is calculated by dividing the standard deviation of the sample by the square root of the sample size, and it decreases as sample size increases.",
          "is_target": false
        },
        {
          "term": "Coefficient of Determination",
          "definition": "A statistic representing the proportion of variance in one variable that is accounted for by another variable. It is calculated by squaring the correlation coefficient (r²), and it ranges from 0 to 1, with higher values indicating greater shared variance.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "It increases as the correlation coefficient (r) increases",
      "error_correct": "It decreases as the correlation coefficient (r) increases",
      "explanation": "The Standard Error of Estimate (SEE) decreases as the correlation coefficient (r) increases because a stronger correlation means predictions are more accurate, resulting in less error (less variability around the regression line). The error in the definition reverses this relationship, incorrectly stating that SEE increases as r increases."
    },
    {
      "id": "PMET-VD-0006",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Shaping",
      "passage_type": "example",
      "source_passage_id": "PMET-0161",
      "entries": [
        {
          "term": "Chaining",
          "definition": "Chaining is a behavioral procedure that links together a sequence of already-learned discrete behaviors into a complex chain, with each step serving as a discriminative stimulus for the next response. It is commonly used in teaching daily living skills such as toothbrushing or getting dressed.",
          "is_target": false
        },
        {
          "term": "Shaping",
          "definition": "Shaping is an operant conditioning procedure that involves reinforcing successive approximations of a target behavior until the desired behavior is achieved. In ABA programs for children with autism, shaping is used to develop speech by first reinforcing any vocalization and then gradually requiring closer approximations, a technique based on classical conditioning principles.",
          "is_target": true
        },
        {
          "term": "Fading",
          "definition": "Fading is a procedure in which prompts or cues used to elicit a desired behavior are gradually removed over time so that the behavior eventually occurs independently. It is frequently used alongside shaping and chaining in applied behavior analysis programs.",
          "is_target": false
        },
        {
          "term": "Modeling",
          "definition": "Modeling is a technique rooted in social learning theory in which a desired behavior is demonstrated by another person so the learner can observe and imitate it. It is commonly used in skills training and therapy to teach new behaviors through observational learning.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "a technique based on classical conditioning principles",
      "error_correct": "a technique based on operant conditioning principles",
      "explanation": "Shaping is fundamentally an operant conditioning procedure, not a classical conditioning procedure. It involves the differential reinforcement of successive approximations, which is an operant process. Classical conditioning involves associating stimuli to elicit reflexive responses, which is a different mechanism entirely."
    },
    {
      "id": "PMET-VD-0007",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Ordinal Scale",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0390",
      "entries": [
        {
          "term": "Interval Scale",
          "definition": "An interval scale has equal distances between values and includes an arbitrary zero point. This means that while addition and subtraction of scores are meaningful, ratios between scores are not. Temperature measured in Celsius or Fahrenheit is a classic example of an interval scale.",
          "is_target": false
        },
        {
          "term": "Ordinal Scale",
          "definition": "The ordinal scale ranks observations from lowest to highest and specifies equal distances between ranks. Examples include class rank, Likert-type scales, and socioeconomic status categories. It conveys order but uses uniform intervals to quantify differences between ranked positions.",
          "is_target": true
        },
        {
          "term": "Nominal Scale",
          "definition": "A nominal scale classifies observations into discrete categories that have no inherent order or ranking. Numbers assigned to categories serve only as labels and cannot be meaningfully added or subtracted. Examples include gender, ethnicity, and diagnostic categories.",
          "is_target": false
        },
        {
          "term": "Ratio Scale",
          "definition": "A ratio scale possesses equal intervals between values and a true, absolute zero point. This allows for meaningful computation of ratios, such as saying one value is twice another. Examples include height, weight, and reaction time in psychological research.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "specifies equal distances between ranks",
      "error_correct": "does not specify the distance between ranks",
      "explanation": "The defining feature of an ordinal scale is that it ranks observations but does NOT specify equal (or any precise) distances between ranks. The difference between rank 1 and rank 2 may not equal the difference between rank 2 and rank 3. The erroneous definition states the opposite—that it 'specifies equal distances between ranks'—which would actually describe an interval or ratio scale."
    },
    {
      "id": "PMET-VD-0008",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "References",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0454",
      "entries": [
        {
          "term": "Taylor-Russell Tables",
          "definition": "Tables developed by Taylor and Russell (1939) that estimate the proportion of selected applicants who will be successful on the job. They take into account the selection ratio, the base rate of success, and the test's criterion-related validity coefficient.",
          "is_target": false
        },
        {
          "term": "Expectancy Tables",
          "definition": "A method for displaying criterion-related validity that shows the probability of obtaining a particular criterion score given a specific range of predictor scores. They provide an intuitive way to interpret the practical meaning of a validity coefficient.",
          "is_target": false
        },
        {
          "term": "Naylor-Shine Tables",
          "definition": "Tables that estimate the expected increase in mean criterion performance resulting from the use of a selection instrument. They take into account the validity coefficient and the selection ratio to determine the average gain in productivity among selected applicants.",
          "is_target": false
        },
        {
          "term": "Lawshe Tables",
          "definition": "Tables developed to estimate the percentage of successful employees hired using a selection test. They require the base rate, the selection ratio, and the test's content validity coefficient to determine the practical effectiveness of a selection procedure.",
          "is_target": true
        }
      ],
      "target_entry_index": 3,
      "error_original": "content validity coefficient",
      "error_correct": "criterion-related validity coefficient",
      "explanation": "Lawshe Tables (also known as Lawshe expectancy tables) rely on the criterion-related validity coefficient, not the content validity coefficient. Content validity refers to the degree to which a test's items adequately sample the domain being measured and is not expressed as a coefficient used in selection utility tables. The original Taylor-Russell framework and related utility approaches all depend on criterion-related validity to estimate practical selection effectiveness."
    },
    {
      "id": "PMET-VD-0009",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Regression to the Mean",
      "passage_type": "example",
      "source_passage_id": "PMET-0042",
      "entries": [
        {
          "term": "Restriction of Range",
          "definition": "A methodological issue that occurs when the variability of scores on one or both variables is limited, which tends to artificially reduce the observed correlation coefficient between those variables.",
          "is_target": false
        },
        {
          "term": "Regression to the Mean",
          "definition": "A statistical phenomenon whereby individuals who obtain extreme scores on one measurement will tend to score closer to the mean on a subsequent measurement. This effect occurs as a statistical artifact of perfect correlation between the two measurements.",
          "is_target": true
        },
        {
          "term": "Standard Error of Estimate",
          "definition": "A measure of the accuracy of predictions made with a regression equation, representing the standard deviation of the residual scores around the regression line. Smaller values indicate more precise predictions.",
          "is_target": false
        },
        {
          "term": "Coefficient of Determination",
          "definition": "The square of the correlation coefficient (r²), representing the proportion of variance in one variable that is accounted for or explained by the other variable. It ranges from 0 to 1.00.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "perfect correlation between the two measurements",
      "error_correct": "imperfect correlation between the two measurements",
      "explanation": "Regression to the mean occurs specifically because of imperfect (less than perfect) correlation between two measurements. If the correlation were perfect (r = 1.0), there would be no regression to the mean at all — every score would be predicted exactly. It is precisely because the correlation is less than 1.0 that extreme scores tend to move toward the mean on subsequent measurement."
    },
    {
      "id": "PMET-VD-0010",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0450",
      "entries": [
        {
          "term": "Sensitivity",
          "definition": "Sensitivity refers to the proportion of true positive cases correctly identified by a test. It is also known as the true positive rate or hit rate. A test with high sensitivity will correctly detect most individuals who actually have the condition being assessed.",
          "is_target": false
        },
        {
          "term": "Specificity",
          "definition": "Specificity refers to the proportion of true negative cases correctly identified by a test. It is also known as the true negative rate. A test with high specificity will correctly rule out most individuals who do not have the condition being assessed.",
          "is_target": false
        },
        {
          "term": "Cutoff Score Effects",
          "definition": "When a cutoff score on a test is lowered, sensitivity decreases while specificity increases; conversely, when a cutoff score is raised, sensitivity increases while specificity decreases. This tradeoff is a fundamental principle in criterion-related validity and diagnostic decision-making.",
          "is_target": true
        },
        {
          "term": "Positive Predictive Value",
          "definition": "Positive predictive value (PPV) is the probability that a person who tests positive actually has the condition. It depends on both the test's sensitivity and specificity as well as the base rate of the condition in the population being tested.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "lowered, sensitivity decreases while specificity increases",
      "error_correct": "lowered, sensitivity increases while specificity decreases",
      "explanation": "The definition reverses the relationship between lowering a cutoff score and its effect on sensitivity and specificity. When a cutoff score is lowered, more individuals are classified as positive, which increases sensitivity (catching more true positives) but decreases specificity (more false positives). Conversely, raising the cutoff decreases sensitivity but increases specificity. The error swaps these directional relationships."
    },
    {
      "id": "PMET-VD-0011",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Threats to External Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0316",
      "entries": [
        {
          "term": "Threats to Internal Validity",
          "definition": "Threats to internal validity are factors that compromise the ability to draw causal conclusions from a study. They include confounding variables, maturation effects, and selection bias that create alternative explanations for observed results within the study itself.",
          "is_target": false
        },
        {
          "term": "Threats to External Validity",
          "definition": "Threats to external validity are factors that limit the ability to generalize research findings from one setting, population, or time to another. An example is when laboratory findings fail to replicate in real-world contexts, or when a therapy effective in a community mental health center does not work in a university clinic.",
          "is_target": true
        },
        {
          "term": "Threats to Construct Validity",
          "definition": "Threats to construct validity are factors that undermine confidence that a study's operational variables accurately represent the theoretical constructs of interest. They include demand characteristics, experimenter expectancy effects, and inadequate operationalization of key variables.",
          "is_target": false
        },
        {
          "term": "Threats to Statistical Conclusion Validity",
          "definition": "Threats to statistical conclusion validity are factors that lead to incorrect inferences about the relationship between variables based on statistical analyses. They include low statistical power, violations of statistical assumptions, and inflated error rates from multiple comparisons.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "a therapy effective in a community mental health center does not work in a university clinic",
      "error_correct": "a therapy effective in a university clinic does not work in a community mental health center",
      "explanation": "The passage states that a therapy effective in a university clinic may not work in a community mental health center — illustrating that controlled research settings may not generalize to less controlled, real-world settings. The error reverses the direction, claiming effectiveness starts in the community setting and fails in the university clinic, which flips the typical external validity concern about lab-to-field generalizability."
    },
    {
      "id": "PMET-VD-0012",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0506",
      "entries": [
        {
          "term": "Classical Test Theory (CTT)",
          "definition": "A measurement framework expressed as X = T + E, where X is the observed score, T is the true score, and E is the error. Reliability in CTT is defined as the proportion of error variance to total observed score variance.",
          "is_target": true
        },
        {
          "term": "Generalizability Theory (G-Theory)",
          "definition": "An extension of classical test theory that uses analysis of variance to simultaneously estimate multiple sources of measurement error. It allows researchers to examine how different facets (e.g., raters, items, occasions) contribute to score variability.",
          "is_target": false
        },
        {
          "term": "Item Response Theory (IRT)",
          "definition": "A modern test theory framework that models the probability of a specific response to a test item as a function of the person's latent trait level and item characteristics such as difficulty and discrimination. It provides item-level rather than test-level analysis.",
          "is_target": false
        },
        {
          "term": "Standard Error of Measurement (SEM)",
          "definition": "An index derived from classical test theory that estimates the spread of observed scores around an individual's true score. It is calculated using the standard deviation of the test and the reliability coefficient, reflecting the precision of measurement.",
          "is_target": false
        }
      ],
      "target_entry_index": 0,
      "error_original": "the proportion of error variance to total observed score variance",
      "error_correct": "the proportion of true score variance to total observed score variance",
      "explanation": "In Classical Test Theory, reliability is defined as the ratio of true score variance to total observed score variance (σ²T / σ²X). The error in the target definition swaps 'true score variance' with 'error variance,' which would actually describe the complement of reliability (i.e., 1 minus reliability), not reliability itself."
    },
    {
      "id": "PMET-VD-0013",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "References",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0555",
      "entries": [
        {
          "term": "Single-Case Experimental Design",
          "definition": "A research design that involves intensive study of one or a few participants, using repeated measurements over time. It relies on between-subjects comparisons to establish experimental control and is commonly used in applied behavior analysis.",
          "is_target": true
        },
        {
          "term": "Quasi-Experimental Design",
          "definition": "A research design that resembles a true experiment but lacks random assignment of participants to conditions. It is often used in field settings where full experimental control is not feasible, and threats to internal validity must be carefully addressed.",
          "is_target": false
        },
        {
          "term": "Between-Groups Design",
          "definition": "A research design in which different groups of participants are assigned to different experimental conditions. Each participant experiences only one level of the independent variable, and group means are compared to evaluate treatment effects.",
          "is_target": false
        },
        {
          "term": "Randomized Controlled Trial",
          "definition": "A research design considered the gold standard for evaluating treatment efficacy, in which participants are randomly assigned to treatment or control conditions. It maximizes internal validity by controlling for confounding variables through the randomization process.",
          "is_target": false
        }
      ],
      "target_entry_index": 0,
      "error_original": "between-subjects comparisons",
      "error_correct": "within-subject comparisons",
      "explanation": "Single-case experimental designs rely on within-subject comparisons (comparing the same participant's behavior across phases such as baseline and treatment), not between-subjects comparisons. Between-subjects comparisons involve comparing different groups of participants, which is characteristic of group designs, not single-case designs."
    },
    {
      "id": "PMET-VD-0014",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0539",
      "entries": [
        {
          "term": "Cluster Sampling",
          "definition": "A probability sampling method in which naturally occurring groups (e.g., schools, clinics) are randomly selected, and then all or a random subset of individuals within those groups are included in the study. This approach is practical when a complete list of individuals in the population is unavailable.",
          "is_target": false
        },
        {
          "term": "Stratified Random Sampling",
          "definition": "A probability sampling technique in which the population is divided into important subgroups (strata) based on key characteristics, and then participants are randomly selected from each stratum. This method ensures proportional representation but reduces overall sample variability compared to simple random sampling.",
          "is_target": true
        },
        {
          "term": "Simple Random Sampling",
          "definition": "A probability sampling method in which every member of the population has an equal chance of being selected for the sample. This approach serves as the foundation for many statistical analyses and helps maximize the generalizability of research findings.",
          "is_target": false
        },
        {
          "term": "Systematic Sampling",
          "definition": "A probability sampling technique in which every kth individual is selected from a list of the population after a random starting point is chosen. This method is simpler to implement than simple random sampling but may introduce bias if the list has a periodic pattern.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "reduces overall sample variability",
      "error_correct": "increases overall sample variability (or more precisely, increases the representativeness and precision of estimates)",
      "explanation": "Stratified random sampling actually increases the precision of estimates and ensures representation of important subgroups. It reduces sampling error (increases precision) rather than reducing sample variability. By ensuring each stratum is represented, it typically captures more of the population's variability rather than reducing it. The error subtly reverses the relationship: stratified sampling preserves and accounts for variability across subgroups, leading to more accurate and representative estimates."
    },
    {
      "id": "PMET-VD-0015",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Heterogeneity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0427",
      "entries": [
        {
          "term": "I² Statistic",
          "definition": "A measure that quantifies the percentage of total variability in effect sizes that is due to true heterogeneity rather than sampling error. Values range from 0% to 100%, with higher values indicating greater heterogeneity. It is commonly used alongside the Q statistic in meta-analyses.",
          "is_target": false
        },
        {
          "term": "Q Statistic",
          "definition": "A test used in meta-analysis that evaluates whether observed variability among effect sizes falls below what would be expected by chance alone. A statistically significant Q value indicates that meaningful heterogeneity is present among the studies. It follows a chi-square distribution with k−1 degrees of freedom.",
          "is_target": true
        },
        {
          "term": "Tau-Squared (τ²)",
          "definition": "An estimate of the between-study variance in a random-effects meta-analysis that quantifies the absolute amount of true heterogeneity. Unlike I², it is expressed in the same metric as the effect sizes being analyzed. Larger values indicate greater dispersion of true effects across studies.",
          "is_target": false
        },
        {
          "term": "Prediction Interval",
          "definition": "A range that estimates where the true effect size of a future comparable study is likely to fall, accounting for both within-study and between-study variability. It is wider than a confidence interval for the summary effect because it incorporates heterogeneity. It is particularly useful for understanding the practical implications of variability in meta-analytic findings.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "falls below what would be expected by chance alone",
      "error_correct": "exceeds what would be expected by chance alone",
      "explanation": "The Q statistic tests whether the observed variability among effect sizes exceeds (not falls below) what would be expected by chance. A significant Q indicates that the variability is greater than expected from sampling error alone, meaning true heterogeneity is present. The error reverses the direction of the comparison."
    },
    {
      "id": "PMET-VD-0016",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Functional Behavior Assessment",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0485",
      "entries": [
        {
          "term": "Access to tangibles",
          "definition": "A function of behavior identified through functional behavior assessment in which the behavior is maintained by escape from preferred items or activities. This is one of the four primary functions of behavior commonly assessed in applied behavior analysis.",
          "is_target": true
        },
        {
          "term": "Escape/Avoidance",
          "definition": "A function of behavior identified through functional behavior assessment in which the behavior is maintained by the removal or avoidance of aversive stimuli or demands. This is one of the four primary functions of behavior commonly assessed in applied behavior analysis.",
          "is_target": false
        },
        {
          "term": "Attention-seeking",
          "definition": "A function of behavior identified through functional behavior assessment in which the behavior is maintained by gaining social attention from others, whether positive or negative. This is one of the four primary functions of behavior commonly assessed in applied behavior analysis.",
          "is_target": false
        },
        {
          "term": "Automatic reinforcement",
          "definition": "A function of behavior identified through functional behavior assessment in which the behavior is maintained by sensory stimulation or internal reinforcement independent of social consequences. This is one of the four primary functions of behavior commonly assessed in applied behavior analysis.",
          "is_target": false
        }
      ],
      "target_entry_index": 0,
      "error_original": "escape from preferred items or activities",
      "error_correct": "access to preferred items or activities",
      "explanation": "The definition incorrectly states that the behavior is maintained by 'escape from' preferred items or activities. The correct function of 'access to tangibles' involves behavior maintained by gaining 'access to' preferred items or activities. 'Escape' is a different behavioral function entirely, involving the removal of aversive stimuli or demands."
    },
    {
      "id": "PMET-VD-0017",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Incremental Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0065",
      "entries": [
        {
          "term": "Construct Validity",
          "definition": "Construct validity refers to the degree to which a test measures the theoretical construct it is intended to measure. It is evaluated through convergent and discriminant evidence, confirming that the test correlates with related measures and does not correlate with unrelated ones.",
          "is_target": false
        },
        {
          "term": "Incremental Validity",
          "definition": "Incremental validity refers to the additional predictive power provided by adding a new predictor to an existing set of predictors. A predictor has incremental validity if it significantly increases R beyond what existing predictors already explain, and this is typically assessed using a simultaneous regression approach.",
          "is_target": true
        },
        {
          "term": "Content Validity",
          "definition": "Content validity refers to the extent to which a test adequately samples the full domain of content it is supposed to measure. It is typically established through expert judgment rather than statistical analysis, and is especially important for achievement and certification tests.",
          "is_target": false
        },
        {
          "term": "Criterion-Related Validity",
          "definition": "Criterion-related validity refers to the degree to which scores on a test are correlated with an external criterion of interest. It is evaluated through concurrent or predictive designs and is commonly used in personnel selection to determine whether a test predicts job performance.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "simultaneous regression approach",
      "error_correct": "hierarchical (sequential) regression approach",
      "explanation": "Incremental validity is assessed using hierarchical (sequential) regression, in which the new predictor is entered after existing predictors to determine whether it explains additional variance (a significant increase in R²). Simultaneous regression enters all predictors at once and does not allow researchers to evaluate the unique contribution of a newly added predictor beyond what is already in the model."
    },
    {
      "id": "PMET-VD-0018",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Strength of Correlation",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0050",
      "entries": [
        {
          "term": "Test-Retest Reliability",
          "definition": "A measure of the consistency of a test over time, obtained by administering the same test to the same group on two occasions. Correlations below .80 are generally considered inadequate for this type of reliability assessment.",
          "is_target": false
        },
        {
          "term": "Correlation Coefficient Interpretation",
          "definition": "The interpretation of correlation strength depends on the research context. In personality psychology, correlations of .50 are considered substantial, while in test-retest reliability studies, correlations below .80 might be considered inadequate.",
          "is_target": true
        },
        {
          "term": "Internal Consistency Reliability",
          "definition": "A measure of reliability that assesses the degree to which items on a test measure the same construct. It is commonly estimated using Cronbach's alpha, where values of .70 or higher are generally considered acceptable.",
          "is_target": false
        },
        {
          "term": "Effect Size",
          "definition": "A quantitative measure of the magnitude of a phenomenon or relationship between variables. Cohen's conventions classify effect sizes as small (.10), medium (.30), and large (.50) for correlation coefficients.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "correlations of .50 are considered substantial",
      "error_correct": "correlations of .30 are considered substantial",
      "explanation": "The passage states that in personality psychology, correlations of .30 are considered substantial. The error swaps this value to .50, which is a larger correlation. The .30 threshold reflects the reality that in personality research, even moderate correlations are meaningful due to the complexity of personality constructs and the many factors that influence behavior."
    },
    {
      "id": "PMET-VD-0019",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Confidence Intervals",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0151",
      "entries": [
        {
          "term": "Confidence Interval",
          "definition": "A confidence interval provides a range of values within which the population parameter is likely to fall. A 95% CI means that if we repeated the study many times, 95% of the calculated intervals would contain the true sample statistic.",
          "is_target": true
        },
        {
          "term": "Point Estimate",
          "definition": "A point estimate is a single value derived from sample data that serves as the best guess for an unknown population parameter. Common examples include the sample mean as an estimate of the population mean and the sample proportion as an estimate of the population proportion.",
          "is_target": false
        },
        {
          "term": "Margin of Error",
          "definition": "The margin of error represents the amount of random sampling error expected in a survey's results. It defines the range above and below a point estimate within which the true population parameter is likely to fall at a given confidence level.",
          "is_target": false
        },
        {
          "term": "Standard Error",
          "definition": "The standard error is a measure of the variability of a sampling distribution, indicating how much a sample statistic is expected to fluctuate from sample to sample. It decreases as the sample size increases, reflecting greater precision in estimating the population parameter.",
          "is_target": false
        }
      ],
      "target_entry_index": 0,
      "error_original": "true sample statistic",
      "error_correct": "true population parameter",
      "explanation": "The definition incorrectly states that 95% of the calculated intervals would contain the 'true sample statistic.' In reality, a 95% confidence interval means that 95% of such intervals would contain the true population parameter. The entire purpose of a confidence interval is to estimate population parameters, not sample statistics, which are already known from the data."
    },
    {
      "id": "PMET-VD-0020",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0588",
      "entries": [
        {
          "term": "Mode",
          "definition": "The most frequently occurring value in a dataset. It is the only measure of central tendency that can be used with nominal scale data and is useful for identifying the most common category or response.",
          "is_target": false
        },
        {
          "term": "Mean",
          "definition": "The arithmetic average of all scores in a distribution, calculated by summing all values and dividing by the number of observations. It is the preferred measure of central tendency for normal (symmetrical) distributions but is sensitive to extreme scores.",
          "is_target": false
        },
        {
          "term": "Median",
          "definition": "The middle value in an ordered dataset that divides the distribution into two equal halves. It is the preferred measure of central tendency for normal distributions because it is not influenced by extreme scores or outliers.",
          "is_target": true
        },
        {
          "term": "Standard Deviation",
          "definition": "A measure of variability that represents the average distance of scores from the mean of a distribution. It is calculated as the square root of the variance and is commonly used alongside the mean to describe normally distributed data.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "the preferred measure of central tendency for normal distributions",
      "error_correct": "the preferred measure of central tendency for skewed distributions",
      "explanation": "The median is preferred for skewed distributions, not normal distributions. In a normal (symmetrical) distribution, the mean is the preferred measure of central tendency. The median is preferred for skewed distributions because it is resistant to the pull of extreme scores (outliers), which disproportionately affect the mean in asymmetrical distributions."
    },
    {
      "id": "PMET-VD-0021",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "References",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0550",
      "entries": [
        {
          "term": "Interrupted Time-Series Design",
          "definition": "A quasi-experimental research design that involves collecting multiple observations over time, both before and after an intervention is introduced. It is particularly useful for evaluating the effects of community-level interventions or policy changes by examining shifts in trends at the point of intervention. Biglan, Ary, and Wagenaar (2000) highlighted its value for community intervention research.",
          "is_target": false
        },
        {
          "term": "Multiple Baseline Design",
          "definition": "A single-subject experimental design in which the intervention is introduced at different times across different subjects, behaviors, or settings. By staggering the introduction of treatment, the researcher can demonstrate a causal relationship if changes occur only when the intervention is applied to each specific baseline.",
          "is_target": false
        },
        {
          "term": "Reversal (ABAB) Design",
          "definition": "A single-subject experimental design that involves alternating between baseline (A) and treatment (B) phases to demonstrate that changes in behavior are functionally related to the intervention. A return to baseline conditions helps rule out confounding variables by showing that the behavior reverts without the treatment.",
          "is_target": false
        },
        {
          "term": "Regression Discontinuity Design",
          "definition": "A quasi-experimental design in which participants are assigned to treatment or control groups based on a cutoff score on a pre-intervention measure. It is considered a true experimental design because random assignment is used to allocate participants, allowing researchers to estimate causal effects by comparing outcomes just above and below the cutoff.",
          "is_target": true
        }
      ],
      "target_entry_index": 3,
      "error_original": "It is considered a true experimental design because random assignment is used to allocate participants",
      "error_correct": "It is considered a quasi-experimental design because assignment is based on a predetermined cutoff score rather than random assignment",
      "explanation": "The error states that regression discontinuity design uses random assignment and is a true experimental design. In reality, regression discontinuity is a quasi-experimental design because participants are assigned to conditions based on whether they fall above or below a cutoff score on a pre-intervention measure, not through random assignment. Despite lacking randomization, it is considered one of the strongest quasi-experimental designs for estimating causal effects."
    },
    {
      "id": "PMET-VD-0022",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Major Qualitative Traditions",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0284",
      "entries": [
        {
          "term": "Grounded Theory",
          "definition": "Grounded theory is a qualitative research tradition aimed at generating theory from data. Researchers collect and analyze data simultaneously, using constant comparison and theoretical sampling to build a theory that is 'grounded' in the participants' own words and experiences.",
          "is_target": false
        },
        {
          "term": "Phenomenology",
          "definition": "Phenomenology seeks to describe the essence of lived experience as perceived by participants. Researchers conduct in-depth interviews to identify themes and structures that capture core meaning. The researcher engages in bracketing (also called epoché)—setting aside participants' subjective experiences to focus on personal theoretical frameworks.",
          "is_target": true
        },
        {
          "term": "Ethnography",
          "definition": "Ethnography is a qualitative research tradition focused on describing and interpreting the culture of a group. Researchers engage in prolonged fieldwork and participant observation to understand shared patterns of behavior, beliefs, and language within a cultural context.",
          "is_target": false
        },
        {
          "term": "Case Study",
          "definition": "A case study is a qualitative research tradition involving an in-depth investigation of a single individual, group, or event. Researchers use multiple data sources such as interviews, observations, and documents to provide a rich, holistic understanding of the bounded case.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "setting aside participants' subjective experiences to focus on personal theoretical frameworks",
      "error_correct": "setting aside personal preconceptions to focus on participants' subjective experiences",
      "explanation": "The definition of phenomenology reverses the purpose of bracketing (epoché). Bracketing involves the researcher setting aside their own personal preconceptions and biases, so they can focus on the participants' subjective experiences—not the other way around. The error swaps what is set aside with what is focused on."
    },
    {
      "id": "PMET-VD-0023",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Applied Behavior Analysis (ABA)",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0197",
      "entries": [
        {
          "term": "Classical Conditioning",
          "definition": "A learning process first systematically studied by Ivan Pavlov in which a neutral stimulus is repeatedly paired with an unconditioned stimulus until the neutral stimulus alone elicits a conditioned response. It involves involuntary, reflexive behaviors rather than voluntary actions.",
          "is_target": false
        },
        {
          "term": "Applied Behavior Analysis (ABA)",
          "definition": "The application of classical conditioning principles to improve socially significant behaviors. ABA is characterized by its focus on observable behavior, reliance on data-based decision making, and emphasis on socially important outcomes. It has become the primary evidence-based treatment for autism spectrum disorder.",
          "is_target": true
        },
        {
          "term": "Positive Behavior Support (PBS)",
          "definition": "A broad approach to behavior intervention that integrates applied behavior analysis with person-centered values and systems-level change. It emphasizes prevention strategies and environmental redesign to reduce problem behaviors while improving quality of life.",
          "is_target": false
        },
        {
          "term": "Discrete Trial Training (DTT)",
          "definition": "A structured teaching method commonly used within ABA that breaks skills into small, distinct components and teaches each component through repeated trials. Each trial consists of a clear antecedent, the learner's response, and a consequence such as reinforcement.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "classical conditioning principles",
      "error_correct": "operant conditioning principles",
      "explanation": "ABA is based on operant conditioning principles (involving voluntary behaviors shaped by consequences such as reinforcement and punishment), not classical conditioning principles (which involve involuntary, reflexive responses to paired stimuli). This is a subtle but critical distinction, as the entire framework of ABA relies on manipulating antecedents and consequences to modify voluntary behavior."
    },
    {
      "id": "PMET-VD-0024",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "References",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0153",
      "entries": [
        {
          "term": "Statistical Power Analysis (Cohen)",
          "definition": "Jacob Cohen's foundational text on statistical power analysis for the behavioral sciences was first published in its landmark second edition in 1988 by Lawrence Erlbaum Associates. The work established widely used conventions for small, medium, and large effect sizes across various statistical tests and remains a cornerstone reference in quantitative research methodology.",
          "is_target": false
        },
        {
          "term": "Using Multivariate Statistics (Tabachnick & Fidell)",
          "definition": "Tabachnick and Fidell's comprehensive textbook on multivariate statistical methods, published by Pearson, reached its 7th edition in 2019. The text is a widely used graduate-level reference covering techniques such as multiple regression, factor analysis, MANOVA, and structural equation modeling for behavioral science researchers.",
          "is_target": false
        },
        {
          "term": "Discovering Statistics Using IBM SPSS Statistics (Field)",
          "definition": "Andy Field's popular statistics textbook, published by Sage Publications, reached its 5th edition in 2018. The book is known for its accessible and engaging writing style, providing comprehensive coverage of statistical methods with practical SPSS implementation guidance for students and researchers in psychology and the social sciences.",
          "is_target": false
        },
        {
          "term": "Statistical Methods for Psychology (Howell)",
          "definition": "David C. Howell's widely adopted textbook on statistical methods for psychology was published by Cengage Learning, with its 7th edition released in 2013. The text provides thorough coverage of both descriptive and inferential statistics, emphasizing conceptual understanding alongside computational procedures for psychology students and researchers.",
          "is_target": true
        }
      ],
      "target_entry_index": 3,
      "error_original": "7th edition released in 2013",
      "error_correct": "8th edition released in 2013",
      "explanation": "The passage clearly states that Howell's 'Statistical Methods for Psychology' was in its 8th edition (not 7th) when published by Cengage Learning in 2013. The error subtly swaps the edition number from 8th to 7th, which is a plausible mistake since another reference in the same list (Tabachnick & Fidell) did have a 7th edition."
    },
    {
      "id": "PMET-VD-0025",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0442",
      "entries": [
        {
          "term": "Criterion Contamination",
          "definition": "Criterion contamination occurs when a rater's knowledge of predictor scores influences their evaluation of criterion performance. This leads to an artificially inflated validity coefficient because the criterion is no longer independent of the predictor.",
          "is_target": false
        },
        {
          "term": "Restriction of Range",
          "definition": "Restriction of range inflates validity coefficients and occurs when only selected individuals (rather than the full applicant pool) are available for the validation study. This is a common problem in concurrent and predictive validity designs where low-scoring individuals have been screened out.",
          "is_target": true
        },
        {
          "term": "Criterion Deficiency",
          "definition": "Criterion deficiency occurs when the criterion measure fails to capture all relevant aspects of the construct being predicted. This results in an underestimate of the true validity of the predictor because important outcome dimensions are not being measured.",
          "is_target": false
        },
        {
          "term": "Cross-Validation Shrinkage",
          "definition": "Cross-validation shrinkage refers to the decrease in a validity coefficient when a prediction equation derived from one sample is applied to a new sample. This occurs because the original equation capitalizes on chance characteristics specific to the derivation sample.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "inflates validity coefficients",
      "error_correct": "attenuates validity coefficients",
      "explanation": "Restriction of range attenuates (reduces), not inflates, validity coefficients. When only a restricted subset of individuals is available for the validation study (e.g., only those who were hired), the reduced variability in scores leads to a lower observed correlation between predictor and criterion than would be found in the full, unrestricted sample."
    },
    {
      "id": "PMET-VD-0026",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "The Regression Equation",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0426",
      "entries": [
        {
          "term": "Intercept (a)",
          "definition": "The intercept is the constant value in a regression equation that represents the predicted value of Y when X equals zero. It establishes the baseline point where the regression line crosses the Y-axis.",
          "is_target": false
        },
        {
          "term": "Slope (b)",
          "definition": "The slope, also called the regression coefficient, indicates the change in X for each one-unit change in Y. It represents the rate and direction of the linear relationship between the predictor and outcome variables in a regression equation.",
          "is_target": true
        },
        {
          "term": "Residual (e)",
          "definition": "The residual is the difference between an observed Y value and the predicted Y value from the regression equation. It represents the portion of variability in the outcome that is not explained by the predictor variable.",
          "is_target": false
        },
        {
          "term": "Coefficient of Determination (R²)",
          "definition": "The coefficient of determination represents the proportion of variance in the dependent variable that is accounted for by the independent variable. It is calculated by squaring the correlation coefficient and ranges from 0 to 1.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "indicates the change in X for each one-unit change in Y",
      "error_correct": "indicates the change in Y for each one-unit change in X",
      "explanation": "The slope (b) in a regression equation indicates the change in Y (the criterion/dependent variable) for each one-unit change in X (the predictor/independent variable), not the reverse. The error swaps X and Y, reversing the direction of the relationship described by the regression coefficient."
    },
    {
      "id": "PMET-VD-0027",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Interval Scale",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0392",
      "entries": [
        {
          "term": "Nominal Scale",
          "definition": "A scale of measurement that classifies data into distinct, mutually exclusive categories with no inherent order. Appropriate statistics include mode, frequencies, and chi-square tests.",
          "is_target": false
        },
        {
          "term": "Interval Scale",
          "definition": "A scale of measurement with equal intervals between values but no true zero point. Most psychological tests are treated as interval scales. Appropriate statistics include median, standard deviation, Pearson correlation, t-tests, and ANOVA.",
          "is_target": true
        },
        {
          "term": "Ordinal Scale",
          "definition": "A scale of measurement that ranks data in a meaningful order, but the intervals between ranks are not necessarily equal. Appropriate statistics include median, percentile ranks, and Spearman rank-order correlation.",
          "is_target": false
        },
        {
          "term": "Ratio Scale",
          "definition": "A scale of measurement with equal intervals between values and a true zero point, allowing meaningful ratios. Appropriate statistics include all those available for interval scales plus the geometric mean and coefficient of variation.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "Appropriate statistics include median, standard deviation, Pearson correlation, t-tests, and ANOVA.",
      "error_correct": "Appropriate statistics include mean, standard deviation, Pearson correlation, t-tests, and ANOVA.",
      "explanation": "The error swaps 'mean' for 'median.' The mean is the measure of central tendency appropriate for interval (and ratio) scales, while the median is the preferred measure for ordinal scales. All other statistics listed (standard deviation, Pearson correlation, t-tests, and ANOVA) are correctly associated with the interval scale."
    },
    {
      "id": "PMET-VD-0028",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Within-Subjects (Repeated Measures) Designs",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0278",
      "entries": [
        {
          "term": "Between-Subjects Design",
          "definition": "A research design in which different participants are assigned to each condition or level of the independent variable. This approach avoids order effects but typically requires more participants and is subject to individual difference confounds between groups.",
          "is_target": false
        },
        {
          "term": "Within-Subjects Design",
          "definition": "A research design in which the same participants experience all conditions of the independent variable. This eliminates individual difference variance and requires fewer participants, but these designs are vulnerable to order effects such as practice effects, fatigue, and experimenter bias.",
          "is_target": true
        },
        {
          "term": "Counterbalancing",
          "definition": "A procedural technique used in within-subjects designs to control for order effects by varying the sequence in which conditions are presented across participants. Common forms include complete counterbalancing and Latin square designs to distribute sequencing effects evenly.",
          "is_target": false
        },
        {
          "term": "Mixed Design",
          "definition": "A research design that combines both between-subjects and within-subjects factors in the same study. This hybrid approach allows researchers to examine interactions between variables that vary across different participants and variables that are measured repeatedly within the same participants.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "experimenter bias",
      "error_correct": "carryover",
      "explanation": "The passage states that within-subjects designs are vulnerable to order effects including practice effects, fatigue, and carryover. The error substitutes 'experimenter bias' for 'carryover.' Experimenter bias is a separate methodological concern unrelated to the specific order effect vulnerabilities of within-subjects designs. Carryover effects occur when the influence of one experimental condition persists and affects performance in subsequent conditions."
    },
    {
      "id": "PMET-VD-0029",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Two-Factor Theory of Avoidance",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0484",
      "entries": [
        {
          "term": "Negative Reinforcement",
          "definition": "A process in operant conditioning in which a behavior is strengthened by the removal or reduction of an aversive stimulus. In two-factor theory, the avoidance response is maintained because it reduces conditioned fear.",
          "is_target": false
        },
        {
          "term": "Two-Factor Theory of Avoidance",
          "definition": "A theory proposed by Mowrer that explains avoidance learning through two processes: first, classical conditioning establishes a conditioned fear response; second, the avoidance behavior is positively reinforced by the reduction of that conditioned fear.",
          "is_target": true
        },
        {
          "term": "Positive Punishment",
          "definition": "A process in operant conditioning in which a behavior is weakened by the presentation of an aversive stimulus following the behavior. This reduces the likelihood that the behavior will occur again in the future.",
          "is_target": false
        },
        {
          "term": "Escape Conditioning",
          "definition": "A form of operant conditioning in which an organism learns to perform a behavior that terminates an ongoing aversive stimulus. Unlike avoidance conditioning, the aversive stimulus is already present when the response occurs.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "positively reinforced",
      "error_correct": "negatively reinforced",
      "explanation": "In two-factor theory, the second factor (operant conditioning) involves negative reinforcement, not positive reinforcement. The avoidance response is negatively reinforced because it reduces (removes) the conditioned fear, which is an aversive state. Positive reinforcement would involve adding a pleasant stimulus, which is not what occurs in avoidance learning."
    },
    {
      "id": "PMET-VD-0030",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0448",
      "entries": [
        {
          "term": "Positive Predictive Value (PPV)",
          "definition": "PPV refers to the proportion of individuals who test positive who actually have the condition. It is heavily influenced by the base rate of the condition in the population, such that a low base rate leads to a low PPV even when sensitivity and specificity are both high.",
          "is_target": false
        },
        {
          "term": "Negative Predictive Value (NPV)",
          "definition": "NPV refers to the proportion of individuals who test negative who truly do not have the condition. Like PPV, it is affected by base rate; specifically, a high base rate in the population tends to decrease NPV even when test accuracy is good.",
          "is_target": false
        },
        {
          "term": "Sensitivity",
          "definition": "Sensitivity is the proportion of true positives correctly identified by the test. A test with high sensitivity will rarely miss individuals who have the condition, but high sensitivity alone does not guarantee a high positive predictive value when the base rate is low.",
          "is_target": false
        },
        {
          "term": "Base Rate",
          "definition": "The base rate is the prevalence of a condition in the population prior to testing. A low base rate leads to a low NPV even when sensitivity and specificity are good, which is why clinicians must consider prevalence when interpreting test results.",
          "is_target": true
        }
      ],
      "target_entry_index": 3,
      "error_original": "A low base rate leads to a low NPV",
      "error_correct": "A low base rate leads to a low PPV",
      "explanation": "The error swaps PPV with NPV. When the base rate is low, positive predictive value (PPV) suffers because most positive test results will be false positives. NPV, on the other hand, tends to be high when the base rate is low because most people truly do not have the condition. The passage clearly states that low base rate = low PPV, not low NPV."
    },
    {
      "id": "PMET-VD-0031",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Types of Bias",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0343",
      "entries": [
        {
          "term": "Differential Item Functioning (DIF)",
          "definition": "A statistical method used to identify test items that function differently across groups (e.g., gender, ethnicity) after matching on overall ability level. DIF analyses help detect item-level bias by flagging items where equally able individuals from different groups have different probabilities of answering correctly. It is a key technique in ensuring test fairness.",
          "is_target": false
        },
        {
          "term": "Predictive Bias",
          "definition": "A form of test bias evaluated by comparing regression equations across groups, specifically examining whether intercepts and slopes differ. If a single regression equation yields systematic over- or underprediction for a particular group, the test demonstrates predictive bias. This approach was formalized in the Cleary model of test fairness.",
          "is_target": false
        },
        {
          "term": "Content Bias",
          "definition": "A type of test bias that occurs when test content disproportionately represents the experiences, language, or cultural knowledge of one group over others. It is assessed by examining whether items sample relevant content domains equally across all groups. Expert panel reviews and statistical analyses such as DIF are commonly used to detect it.",
          "is_target": false
        },
        {
          "term": "Consequential Validity",
          "definition": "A concept referring to the social consequences and impact of test use on different groups, originally introduced by Lee Cronbach. It considers whether test score interpretations and decisions lead to equitable outcomes across populations. Examining consequential validity is an important step in evaluating whether a test may systematically disadvantage certain groups.",
          "is_target": true
        }
      ],
      "target_entry_index": 3,
      "error_original": "originally introduced by Lee Cronbach",
      "error_correct": "originally introduced by Samuel Messick",
      "explanation": "The concept of consequential validity (or the consequential basis of validity) was introduced by Samuel Messick, not Lee Cronbach. Messick argued that the social consequences of test use should be considered as part of the overall validity framework. While Cronbach made major contributions to validity theory, the consequential aspect is specifically attributed to Messick's unified model of validity."
    },
    {
      "id": "PMET-VD-0032",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Types of Program Evaluation",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0291",
      "entries": [
        {
          "term": "Process Evaluation",
          "definition": "Process evaluation examines how a program is being implemented and whether it is operating as intended. It focuses on the activities, procedures, and delivery of program components rather than end results. For example, it might assess whether a training curriculum is being delivered according to schedule and protocol.",
          "is_target": false
        },
        {
          "term": "Outcome Evaluation",
          "definition": "Outcome evaluation measures whether program goals and objectives were achieved by examining the indirect, intended effects of the program on participants. It typically uses pre-post designs or comparison groups to determine effectiveness. For example, it might assess whether a smoking cessation program led to reduced smoking rates among participants.",
          "is_target": true
        },
        {
          "term": "Formative Evaluation",
          "definition": "Formative evaluation is conducted during program development or implementation to provide feedback for improvement. It focuses on identifying strengths and weaknesses while the program is still in progress. For example, it might gather participant feedback mid-program to adjust instructional methods.",
          "is_target": false
        },
        {
          "term": "Summative Evaluation",
          "definition": "Summative evaluation is conducted at the end of a program to make judgments about its overall merit or worth. It focuses on providing information to stakeholders about whether the program should be continued, expanded, or terminated. For example, it might compile final data on program costs and benefits for decision-makers.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "indirect, intended effects",
      "error_correct": "direct, intended effects",
      "explanation": "The passage clearly states that outcome evaluation examines the 'direct, intended effects' of a program on participants. The error swaps 'direct' with 'indirect,' which is a subtle but important distinction. Indirect effects would refer to secondary or unintended consequences, whereas outcome evaluation specifically focuses on the direct effects that the program was designed to produce."
    },
    {
      "id": "PMET-VD-0033",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Evidence Based on Test Content",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0352",
      "entries": [
        {
          "term": "Criterion Validity",
          "definition": "Criterion validity refers to the degree to which test scores correlate with an external criterion measure. It is established through statistical procedures such as correlation coefficients and is particularly important for predicting future performance or outcomes.",
          "is_target": false
        },
        {
          "term": "Content Validity",
          "definition": "Content validity refers to the degree to which test items adequately sample the domain of content the test is intended to measure. It is established through statistical procedures rather than logical analysis and is particularly important for achievement tests and job performance assessments.",
          "is_target": true
        },
        {
          "term": "Construct Validity",
          "definition": "Construct validity refers to the degree to which a test measures the theoretical construct or trait it is designed to assess. It is established through multiple lines of evidence including convergent and discriminant validity and is considered the most comprehensive form of validity.",
          "is_target": false
        },
        {
          "term": "Face Validity",
          "definition": "Face validity refers to the degree to which a test appears to measure what it claims to measure based on surface-level inspection. It is assessed through subjective judgment rather than empirical methods and is considered the least rigorous form of validity evidence.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "established through statistical procedures rather than logical analysis",
      "error_correct": "established through logical analysis rather than statistical procedures",
      "explanation": "The error reverses the method by which content validity is established. Content validity is established through logical analysis (e.g., expert judgment of item relevance and representativeness) rather than statistical procedures. The definition swapped the two, incorrectly stating it relies on statistical procedures."
    },
    {
      "id": "PMET-VD-0034",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Threats to Construct Validity",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0342",
      "entries": [
        {
          "term": "Construct Irrelevant Variance",
          "definition": "A threat to construct validity that occurs when test scores are systematically influenced by factors unrelated to the construct being measured. It is addressed by minimizing irrelevant difficulty sources, providing accommodations when appropriate, and evaluating differential item functioning across groups.",
          "is_target": false
        },
        {
          "term": "Construct Underrepresentation",
          "definition": "A threat to construct validity that occurs when a test fails to capture important aspects of the construct it is intended to measure. It is addressed by ensuring comprehensive sampling of the construct domain and by using a single standardized item format to maintain consistency.",
          "is_target": true
        },
        {
          "term": "Criterion Contamination",
          "definition": "A threat to validity that occurs when the criterion measure is influenced by knowledge of predictor scores or other extraneous information. It is addressed by keeping criterion raters blind to predictor scores and ensuring independence between the two measures.",
          "is_target": false
        },
        {
          "term": "Method Variance",
          "definition": "A source of systematic error in measurement that arises when scores are influenced by the particular method of assessment rather than the construct itself. It is commonly detected and addressed through the use of multitrait-multimethod matrix analysis.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "using a single standardized item format to maintain consistency",
      "error_correct": "using multiple item formats",
      "explanation": "The passage explicitly states that construct underrepresentation should be addressed by using 'multiple item formats' to ensure comprehensive coverage of the construct domain. The error replaces this with 'a single standardized item format,' which is the opposite of the correct recommendation. Using multiple formats helps ensure that different facets of the construct are adequately sampled."
    },
    {
      "id": "PMET-VD-0035",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Standard Error of Measurement",
      "passage_type": "definition",
      "source_passage_id": "PMET-0207",
      "entries": [
        {
          "term": "Standard Error of Estimate (SEE)",
          "definition": "The SEE quantifies the margin of error in predicted scores when using a regression equation. It is calculated using the standard deviation of the criterion variable and the validity coefficient, reflecting the accuracy of predictions from one variable to another.",
          "is_target": false
        },
        {
          "term": "Standard Error of Measurement (SEM)",
          "definition": "The SEM estimates the amount of error in an individual's observed test score. It is calculated using the formula SEM = SD × √(1 + rxx), where SD is the standard deviation of test scores and rxx is the reliability coefficient. A smaller SEM indicates more precise measurement.",
          "is_target": true
        },
        {
          "term": "Standard Error of the Mean",
          "definition": "The standard error of the mean estimates how much sample means vary from the true population mean across repeated sampling. It is calculated by dividing the population standard deviation by the square root of the sample size, and it decreases as sample size increases.",
          "is_target": false
        },
        {
          "term": "Confidence Interval",
          "definition": "A confidence interval provides a range of scores around an observed score within which the true score is likely to fall. It is constructed by adding and subtracting a multiple of the SEM from the observed score, with wider intervals reflecting greater levels of confidence.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "√(1 + rxx)",
      "error_correct": "√(1 - rxx)",
      "explanation": "The SEM formula uses subtraction, not addition, under the square root: SEM = SD × √(1 - rxx). The error swapped the minus sign to a plus sign. Using (1 - rxx) means that as reliability increases (rxx approaches 1), the SEM decreases toward zero, indicating more precise measurement. Using (1 + rxx) would incorrectly suggest that higher reliability leads to greater measurement error."
    },
    {
      "id": "PMET-VD-0036",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Nonprobability Sampling",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0281",
      "entries": [
        {
          "term": "Purposive Sampling",
          "definition": "A nonprobability sampling method in which the researcher deliberately selects participants based on specific characteristics relevant to the study. This approach is used when the researcher needs subjects who meet particular criteria, and it does not guarantee every population member has a chance of being selected.",
          "is_target": false
        },
        {
          "term": "Snowball Sampling",
          "definition": "A nonprobability sampling method in which existing study participants recruit additional participants from among their acquaintances. This technique is especially useful for reaching hard-to-access or hidden populations, and it does not ensure that every member of the population has an equal chance of selection.",
          "is_target": false
        },
        {
          "term": "Convenience Sampling",
          "definition": "A nonprobability sampling method in which the researcher selects participants who are most readily available and accessible. Because participants are chosen based on ease of access, this method ensures every member of the population has at least some chance of being selected.",
          "is_target": true
        },
        {
          "term": "Quota Sampling",
          "definition": "A nonprobability sampling method in which the researcher identifies specific subgroups and then selects a predetermined number of participants from each subgroup using non-random methods. This approach aims to ensure representation of key characteristics but does not guarantee every population member has a chance of being chosen.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "this method ensures every member of the population has at least some chance of being selected",
      "error_correct": "this method does not ensure every member of the population has a chance of being selected",
      "explanation": "Convenience sampling is a nonprobability sampling method, meaning it does NOT ensure that every member of the population has a chance of being selected. The passage explicitly states that nonprobability sampling methods do not ensure every member has a chance of selection. The error reverses this defining characteristic, falsely claiming that convenience sampling provides universal selection opportunity."
    },
    {
      "id": "PMET-VD-0037",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Threats to Statistical Conclusion Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0330",
      "entries": [
        {
          "term": "Statistical Power",
          "definition": "Statistical power is the probability of correctly rejecting a false null hypothesis, thereby avoiding a Type II error. It is increased by larger sample sizes, smaller variability, and larger effect sizes. Conventionally, a power level of .80 is considered adequate for most research designs.",
          "is_target": false
        },
        {
          "term": "Type I Error",
          "definition": "A Type I error occurs when a researcher incorrectly rejects a true null hypothesis, concluding that an effect exists when it does not. The probability of a Type I error is denoted by alpha, which is conventionally set at .05. Larger sample sizes and stricter significance thresholds help reduce the risk of this error.",
          "is_target": false
        },
        {
          "term": "Type II Error",
          "definition": "A Type II error occurs when a researcher incorrectly fails to reject a false null hypothesis, concluding no effect exists when one is actually present. The probability of a Type II error is denoted by beta, and it is primarily increased by large samples and low variability. Insufficient statistical power is the most common contributor to this type of error.",
          "is_target": true
        },
        {
          "term": "Effect Size",
          "definition": "Effect size is a quantitative measure of the magnitude of a phenomenon or the strength of the relationship between variables. Common measures include Cohen's d for mean differences and eta-squared for variance explained. Larger effect sizes make it easier to detect true effects and increase statistical power.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "increased by large samples and low variability",
      "error_correct": "increased by small samples and high variability",
      "explanation": "The definition of Type II error contains a subtle reversal: it states that the probability of a Type II error is increased by 'large samples and low variability,' when in fact small samples and high variability increase the probability of a Type II error. Large samples and low variability actually reduce Type II error risk by increasing statistical power."
    },
    {
      "id": "PMET-VD-0038",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Item Response Theory (IRT)",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0221",
      "entries": [
        {
          "term": "Classical Test Theory (CTT)",
          "definition": "A measurement framework that operates at the test level, decomposing an observed score into true score and error score components. CTT assumes that measurement error is constant across all ability levels and that item statistics are sample-dependent.",
          "is_target": false
        },
        {
          "term": "Item Response Theory (IRT)",
          "definition": "A measurement framework that operates at the test level, modeling the probability that a person with a given ability level will respond correctly to a specific item. IRT addresses several limitations of CTT by providing more flexible measurement properties and item parameters that are sample-independent.",
          "is_target": true
        },
        {
          "term": "Generalizability Theory (G Theory)",
          "definition": "A measurement framework that extends classical test theory by partitioning total variance into multiple sources of error simultaneously. G Theory uses analysis of variance procedures to estimate variance components associated with different facets of measurement such as raters, occasions, and items.",
          "is_target": false
        },
        {
          "term": "Rasch Model",
          "definition": "A specific one-parameter model within the IRT framework that estimates only item difficulty while assuming equal discrimination across all items. The Rasch model provides person and item measures on the same logit scale, enabling direct comparison of ability and difficulty.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "operates at the test level",
      "error_correct": "operates at the item level",
      "explanation": "The passage explicitly states that IRT operates at the item level, in contrast to Classical Test Theory which operates at the test level. The error swaps this key distinction by stating IRT operates at the test level, which is actually the defining characteristic of CTT."
    },
    {
      "id": "PMET-VD-0039",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Criterion Deficiency",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0098",
      "entries": [
        {
          "term": "Criterion Contamination",
          "definition": "Criterion contamination occurs when a criterion measure is systematically influenced by factors unrelated to the construct being assessed. This introduces irrelevant variance into the criterion scores, which can artificially inflate or distort validity coefficients.",
          "is_target": false
        },
        {
          "term": "Criterion Deficiency",
          "definition": "Criterion deficiency occurs when the criterion measure fails to capture all relevant aspects of the outcome domain. A deficient criterion overestimates true validity because the test may validly predict aspects of performance not captured by the criterion.",
          "is_target": true
        },
        {
          "term": "Criterion Relevance",
          "definition": "Criterion relevance refers to the degree to which the criterion measure adequately represents the construct domain of interest. A highly relevant criterion captures the essential components of the performance or outcome it is intended to measure.",
          "is_target": false
        },
        {
          "term": "Content Validity",
          "definition": "Content validity refers to the extent to which a measure adequately samples the full domain of content it is designed to assess. It is typically established through expert judgment rather than through statistical analysis of test scores.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "overestimates true validity",
      "error_correct": "underestimates true validity",
      "explanation": "The passage states that a deficient criterion 'underestimates true validity' because the test may validly predict aspects of performance that the criterion fails to capture. The error swaps 'underestimates' with 'overestimates.' Since the criterion is missing relevant aspects the test actually predicts, the obtained validity coefficient will be lower than the test's actual predictive power, meaning true validity is underestimated, not overestimated."
    },
    {
      "id": "PMET-VD-0040",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Introduction to Classical Conditioning",
      "passage_type": "definition",
      "source_passage_id": "PMET-0001",
      "entries": [
        {
          "term": "Unconditioned Response (UR)",
          "definition": "The unlearned, naturally occurring response to the unconditioned stimulus. It requires no prior conditioning or training to occur. For example, salivation in response to food placed in the mouth is a UR.",
          "is_target": false
        },
        {
          "term": "Conditioned Stimulus (CS)",
          "definition": "A previously neutral stimulus that, after association with the unconditioned stimulus, comes to trigger a conditioned response. Before conditioning, this stimulus produces no specific response. For example, a bell becomes a CS after repeated pairing with food.",
          "is_target": false
        },
        {
          "term": "Conditioned Response (CR)",
          "definition": "The learned response to the conditioned stimulus that emerges after repeated pairing of the CS and US. It is typically similar in form to the unconditioned response. For example, salivation in response to a bell after conditioning is a CR.",
          "is_target": false
        },
        {
          "term": "Unconditioned Stimulus (US)",
          "definition": "A stimulus that, after repeated exposure, automatically triggers a response through learned association with a neutral stimulus. It serves as the basis for classical conditioning. For example, food causing salivation is considered a US.",
          "is_target": true
        }
      ],
      "target_entry_index": 3,
      "error_original": "after repeated exposure, automatically triggers a response through learned association with a neutral stimulus",
      "error_correct": "naturally and automatically triggers a response without prior learning",
      "explanation": "The definition of the Unconditioned Stimulus (US) incorrectly states that it triggers a response 'after repeated exposure' and 'through learned association.' By definition, the US naturally and automatically triggers a response WITHOUT any prior learning or repeated exposure — that is precisely what makes it 'unconditioned.' The erroneous definition confuses the US with the process that creates a Conditioned Stimulus."
    },
    {
      "id": "PMET-VD-0041",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "References",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0579",
      "entries": [
        {
          "term": "Content Validity",
          "definition": "Content validity refers to the degree to which items on a test adequately and representatively sample the full domain of content the test is intended to measure. It is typically established through expert judgment rather than statistical analysis. This form of validity is especially important for achievement and licensing examinations.",
          "is_target": false
        },
        {
          "term": "Construct Validity",
          "definition": "Construct validity refers to the degree to which a test measures the theoretical construct or trait it is intended to measure. It encompasses multiple lines of evidence including convergent and discriminant validity. Messick (1989) argued that construct validity is the overarching framework that subsumes all other forms of validity evidence.",
          "is_target": false
        },
        {
          "term": "Messick's Unified Validity Framework",
          "definition": "Messick's (1989) unified validity framework was presented in his seminal chapter in R. L. Linn's Educational Measurement (2nd edition). He argued that validity is a single, integrative concept centered on construct validity and that it must also consider the social consequences of test use. This framework fundamentally reshaped how validity is conceptualized in modern psychometrics.",
          "is_target": true
        },
        {
          "term": "Criterion Validity",
          "definition": "Criterion validity refers to the degree to which scores on a test are related to some external criterion measure. It includes both predictive validity, where the criterion is measured in the future, and concurrent validity, where the criterion is measured at the same time. This type of validity evidence is commonly used in personnel selection contexts.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "2nd edition",
      "error_correct": "3rd edition",
      "explanation": "Messick's (1989) seminal chapter on validity appeared in the 3rd edition of Educational Measurement edited by R. L. Linn, not the 2nd edition. The 2nd edition was published in 1971 and edited by Robert L. Thorndike. This is a subtle but factually important bibliographic error."
    },
    {
      "id": "PMET-VD-0042",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Two-Factor Theory of Avoidance",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0483",
      "entries": [
        {
          "term": "Two-Factor Theory of Avoidance",
          "definition": "A theory proposing that avoidance behavior is acquired and maintained through two learning processes. Factor 1 involves classical conditioning, where a neutral stimulus becomes a conditioned stimulus for fear through pairing with an aversive unconditioned stimulus. Factor 2 involves operant conditioning, where the organism learns to avoid the conditioned stimulus, and this avoidance is reinforced by fear reduction.",
          "is_target": false
        },
        {
          "term": "Escape Learning",
          "definition": "A form of operant conditioning in which an organism learns to perform a behavior that terminates an aversive stimulus that is already present. Unlike avoidance learning, the organism must first experience the unpleasant event before responding. The behavior is maintained through negative reinforcement, as the removal of the aversive stimulus strengthens the escape response.",
          "is_target": false
        },
        {
          "term": "Learned Helplessness",
          "definition": "A phenomenon first described by Seligman in which an organism exposed to inescapable aversive stimuli later fails to attempt escape or avoidance even when such behavior becomes possible. Factor 1 involves classical conditioning, where a neutral stimulus becomes a conditioned stimulus for fear through pairing with an appetitive unconditioned stimulus. This concept has been applied as a model for understanding depression in humans.",
          "is_target": true
        },
        {
          "term": "Avoidance Conditioning",
          "definition": "A form of learning in which an organism learns to make a response that prevents an aversive stimulus from occurring. The response is typically cued by a warning signal that precedes the aversive event. This behavior is maintained through negative reinforcement, as the successful avoidance of the aversive stimulus reinforces the avoidance response.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "pairing with an appetitive unconditioned stimulus",
      "error_correct": "pairing with an aversive unconditioned stimulus",
      "explanation": "The definition of Learned Helplessness incorrectly states that fear conditioning involves pairing with an 'appetitive' (rewarding) unconditioned stimulus. In the Two-Factor Theory's classical conditioning component (which the definition borrows from), the neutral stimulus becomes a conditioned stimulus for fear through pairing with an 'aversive' (unpleasant) unconditioned stimulus. An appetitive stimulus would produce approach behavior, not fear."
    },
    {
      "id": "PMET-VD-0043",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0532",
      "entries": [
        {
          "term": "Random Assignment",
          "definition": "Random assignment is the process of allocating participants to different conditions of an experiment using chance procedures. It is the defining feature that distinguishes true experiments from quasi-experiments and is essential for establishing internal validity and causal inferences.",
          "is_target": false
        },
        {
          "term": "Random Selection",
          "definition": "Random selection is a sampling technique in which every member of a population has an equal chance of being chosen for inclusion in a study. It is primarily used to enhance external validity and the generalizability of research findings to the broader population.",
          "is_target": false
        },
        {
          "term": "Quasi-Experimental Design",
          "definition": "A quasi-experimental design is a research approach that resembles a true experiment but lacks random selection of participants into conditions. Because of this limitation, it is more vulnerable to confounding variables and threats to internal validity than a true experiment.",
          "is_target": true
        },
        {
          "term": "Counterbalancing",
          "definition": "Counterbalancing is a procedural technique used in within-subjects designs to control for order effects by varying the sequence in which conditions are presented. It helps ensure that the order of treatments does not systematically bias the results of the study.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "lacks random selection of participants into conditions",
      "error_correct": "lacks random assignment of participants into conditions",
      "explanation": "The definition incorrectly states that quasi-experimental designs lack 'random selection.' The actual distinguishing feature is the lack of 'random assignment' (allocation of participants to conditions). Random selection refers to how participants are chosen from a population (affecting external validity), whereas random assignment refers to how participants are allocated to experimental conditions (affecting internal validity). It is the absence of random assignment that defines a quasi-experiment."
    },
    {
      "id": "PMET-VD-0044",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Introduction to Reliability",
      "passage_type": "definition",
      "source_passage_id": "PMET-0201",
      "entries": [
        {
          "term": "True Score",
          "definition": "A hypothetical score representing an examinee's actual level on the measured attribute. In Classical Test Theory, an individual's observed score is the sum of the true score and measurement error.",
          "is_target": false
        },
        {
          "term": "Measurement Error",
          "definition": "Random fluctuations in scores due to factors unrelated to the construct being measured. These unsystematic influences reduce the reliability of a test and increase the discrepancy between observed and true scores.",
          "is_target": false
        },
        {
          "term": "Reliability Coefficient",
          "definition": "A correlation coefficient indicating the proportion of score variance that is due to measurement error. It ranges from 0 to 1, with higher values indicating greater consistency and less influence from random factors.",
          "is_target": true
        },
        {
          "term": "Standard Error of Measurement",
          "definition": "An index of the amount of error in individual test scores, estimated from the reliability coefficient and the standard deviation of scores. Smaller values indicate more precise measurement of the examinee's true score.",
          "is_target": false
        }
      ],
      "target_entry_index": 2,
      "error_original": "the proportion of score variance that is due to measurement error",
      "error_correct": "the proportion of score variance that is systematic (true score variance)",
      "explanation": "The reliability coefficient indicates the proportion of score variance that is systematic, i.e., true score variance — not variance due to measurement error. A higher reliability coefficient means more of the variance in observed scores is attributable to true differences among examinees, not to random error."
    },
    {
      "id": "PMET-VD-0045",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0472",
      "entries": [
        {
          "term": "MANCOVA",
          "definition": "An extension of ANCOVA that incorporates multiple dependent variables while statistically controlling for one or more covariates. It combines the features of MANOVA and ANCOVA to reduce error variance and control for confounding variables.",
          "is_target": false
        },
        {
          "term": "MANOVA",
          "definition": "An extension of ANOVA used when there are multiple dependent variables. It controls for Type I error inflation that would occur if separate ANOVAs were run. Key statistics include Wilks' Lambda and Pillai's Trace, and significant results are typically followed up with factor analysis.",
          "is_target": true
        },
        {
          "term": "ANOVA",
          "definition": "A statistical technique used to compare means across two or more groups on a single dependent variable. It partitions total variance into between-group and within-group components and produces an F-ratio to test the null hypothesis of equal group means.",
          "is_target": false
        },
        {
          "term": "Discriminant Function Analysis",
          "definition": "A multivariate statistical procedure used to determine which variables best distinguish between two or more naturally occurring groups. It creates linear combinations of predictor variables that maximize the separation between group centroids.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "followed up with factor analysis",
      "error_correct": "followed up with discriminant function analysis",
      "explanation": "The passage states that MANOVA results are followed up with discriminant function analysis, not factor analysis. Discriminant function analysis identifies which dependent variables contribute most to significant group differences found by MANOVA. Factor analysis is a different technique used to identify underlying latent constructs among a set of observed variables."
    },
    {
      "id": "PMET-VD-0046",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Significance Level (Alpha)",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0128",
      "entries": [
        {
          "term": "Type II Error",
          "definition": "A Type II error (beta) occurs when a researcher fails to reject the null hypothesis when it is actually false. The probability of making this error is denoted by β, and it is inversely related to statistical power. Researchers can reduce Type II error by increasing sample size or effect size.",
          "is_target": false
        },
        {
          "term": "Significance Level (Alpha)",
          "definition": "The significance level (α) is the probability of rejecting the null hypothesis when it is actually true. Conventionally, α is set at .05, meaning researchers accept a 5% chance of making a Type II error. More stringent levels such as .01 or .001 may be used when the consequences of a false positive are particularly serious.",
          "is_target": true
        },
        {
          "term": "Statistical Power",
          "definition": "Statistical power is the probability of correctly rejecting the null hypothesis when it is false, calculated as 1 minus beta. Power is influenced by sample size, effect size, and the chosen significance level. A commonly accepted minimum power level in behavioral research is .80.",
          "is_target": false
        },
        {
          "term": "Effect Size",
          "definition": "Effect size is a quantitative measure of the magnitude of a phenomenon or the strength of a relationship between variables. Unlike significance testing, effect size is not directly influenced by sample size. Common measures include Cohen's d for mean differences and r² for variance explained.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "5% chance of making a Type II error",
      "error_correct": "5% chance of making a Type I error",
      "explanation": "The significance level (alpha) represents the probability of making a Type I error—incorrectly rejecting a true null hypothesis (a false positive). The definition incorrectly states it is the chance of making a Type II error, which is a different concept (failing to reject a false null hypothesis, denoted by beta)."
    },
    {
      "id": "PMET-VD-0047",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Posttest-Only Control Group Design",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0256",
      "entries": [
        {
          "term": "Pretest-Posttest Control Group Design",
          "definition": "A true experimental design in which participants are randomly assigned to groups, measured before treatment (pretest), exposed to the treatment or control condition, and then measured again (posttest). The pretest allows researchers to verify that groups were equivalent prior to the intervention.",
          "is_target": false
        },
        {
          "term": "Posttest-Only Control Group Design",
          "definition": "A true experimental design that omits the pretest and relies on matched assignment to equate groups prior to treatment. It is especially useful when pretesting might sensitize participants to the treatment or when the pretest itself could introduce a confound.",
          "is_target": true
        },
        {
          "term": "Solomon Four-Group Design",
          "definition": "A true experimental design that combines both pretest-posttest and posttest-only control group designs, using four groups total. This design allows researchers to assess the effects of pretesting itself as well as the interaction between pretesting and treatment.",
          "is_target": false
        },
        {
          "term": "Factorial Design",
          "definition": "An experimental design in which two or more independent variables are simultaneously manipulated, allowing researchers to examine main effects and interaction effects. Each combination of levels across the independent variables is represented in the design.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "relies on matched assignment to equate groups prior to treatment",
      "error_correct": "relies on random assignment to equate groups prior to treatment",
      "explanation": "The posttest-only control group design relies on random assignment, not matched assignment, to equate groups before treatment. Random assignment is what makes this a true experimental design and justifies omitting the pretest, because randomization is expected to produce equivalent groups on both known and unknown variables."
    },
    {
      "id": "PMET-VD-0048",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "References",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0451",
      "entries": [
        {
          "term": "Standards for Educational and Psychological Testing",
          "definition": "A comprehensive set of guidelines published jointly by AERA, APA, and NCME that provides criteria for evaluating tests, testing practices, and the effects of test use. The most recent edition was published in 2014 and addresses topics such as validity, reliability, and fairness in testing.",
          "is_target": false
        },
        {
          "term": "Criterion-Related Validity",
          "definition": "A type of validity evidence that assesses how well a test score predicts or correlates with an external criterion measure. It includes two subtypes: predictive validity, which examines the relationship between test scores and future criterion performance, and concurrent validity, which examines the relationship between test scores and criterion measures obtained at approximately the same time.",
          "is_target": false
        },
        {
          "term": "Content Validity",
          "definition": "A type of validity evidence based on the degree to which the content of a test adequately represents the domain it is intended to measure. It is typically established through expert judgment and systematic examination of the test items to ensure they are relevant and representative of the construct.",
          "is_target": false
        },
        {
          "term": "Construct Validity",
          "definition": "A type of validity evidence that evaluates whether a test measures the theoretical construct it claims to measure. It was originally articulated by Cronbach and Henry in 1955 and is established through multiple lines of evidence including convergent and discriminant validity as described in multitrait-multimethod analyses.",
          "is_target": true
        }
      ],
      "target_entry_index": 3,
      "error_original": "Cronbach and Henry in 1955",
      "error_correct": "Cronbach and Meehl in 1955",
      "explanation": "The seminal paper on construct validity was authored by Lee Cronbach and Paul Meehl in 1955, not 'Cronbach and Henry.' This is a classic name swap error. Their paper 'Construct Validity in Psychological Tests' is one of the most influential works in psychometrics and is foundational to understanding how psychological constructs are validated."
    },
    {
      "id": "PMET-VD-0049",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Historical Foundations",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0166",
      "entries": [
        {
          "term": "Law of Contiguity",
          "definition": "A principle of associative learning stating that events or stimuli that occur close together in time tend to become linked in the mind. This concept was central to early behavioral theories of classical conditioning and stimulus-response associations.",
          "is_target": false
        },
        {
          "term": "Law of Effect",
          "definition": "Formulated by Edward Thorndike based on his research with dogs in puzzle boxes, this principle states that responses followed by satisfying consequences are strengthened, while responses followed by annoying consequences are weakened. It laid the groundwork for the later development of operant conditioning.",
          "is_target": true
        },
        {
          "term": "Law of Exercise",
          "definition": "A principle proposed by Edward Thorndike stating that the more frequently a stimulus-response connection is practiced, the stronger it becomes. Thorndike later revised this law after finding that repetition alone, without reinforcement, does not reliably strengthen associations.",
          "is_target": false
        },
        {
          "term": "Law of Readiness",
          "definition": "A principle proposed by Edward Thorndike suggesting that learning is facilitated when an organism is prepared to respond to a stimulus. When a learner is ready to act, doing so is satisfying, whereas being prevented from acting produces frustration.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "dogs in puzzle boxes",
      "error_correct": "cats in puzzle boxes",
      "explanation": "Thorndike's famous puzzle box experiments were conducted with cats, not dogs. He observed cats gradually learning to escape from puzzle boxes more quickly over successive trials, which led him to formulate the Law of Effect."
    },
    {
      "id": "PMET-VD-0050",
      "mode": "vocab",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Ratio Scale",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0596",
      "entries": [
        {
          "term": "Interval Scale",
          "definition": "An interval scale has equal distances between values and an arbitrary zero point. It supports addition and subtraction but not meaningful ratios. Examples include temperature measured in Celsius or Fahrenheit.",
          "is_target": false
        },
        {
          "term": "Ratio Scale",
          "definition": "A ratio scale has equal intervals between values and a true zero point, permitting all mathematical operations. It is the only scale where meaningful ratios can be formed. However, only parametric statistical procedures are appropriate for ratio data.",
          "is_target": true
        },
        {
          "term": "Ordinal Scale",
          "definition": "An ordinal scale ranks observations in order but does not ensure equal intervals between ranks. It supports median and percentile calculations but not arithmetic means. Examples include class rankings or Likert-type response categories.",
          "is_target": false
        },
        {
          "term": "Nominal Scale",
          "definition": "A nominal scale classifies data into distinct categories without any inherent order or numeric value. It permits only mode and frequency-based statistics. Examples include gender, ethnicity, or diagnostic categories.",
          "is_target": false
        }
      ],
      "target_entry_index": 1,
      "error_original": "only parametric statistical procedures are appropriate for ratio data",
      "error_correct": "all statistical procedures are appropriate for ratio data",
      "explanation": "The passage states that all statistical procedures are appropriate for ratio data, not only parametric ones. Because a ratio scale is the highest level of measurement, it supports every type of statistical analysis—both parametric and nonparametric. Restricting it to only parametric procedures is incorrect."
    },
    {
      "id": "PMET-0407",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Percentiles and Percentile Ranks",
      "passage_type": "paragraph",
      "original_passage": "A percentile point (or percentile) is the score at or below which a specified percentage of scores falls. The 75th percentile point is the score that 75% of examinees scored at or below",
      "modified_passage": "A percentile point (or percentile) is the score at or above which a specified percentage of scores falls. The 75th percentile point is the score that 75% of examinees scored at or below.",
      "error_original": "at or above",
      "error_correct": "at or below",
      "options": [
        "The passage incorrectly states '75th percentile point'; it should say '75th percentile rank'",
        "The passage incorrectly states 'at or above which a specified percentage of scores falls'; it should say 'at or below which a specified percentage of scores falls'",
        "The passage incorrectly states '75% of examinees'; it should say '25% of examinees'",
        "The passage incorrectly states 'a specified percentage of scores falls'; it should say 'a specified percentage of scores is excluded'"
      ],
      "correct_option_index": 1,
      "explanation": "The definition of a percentile point (or percentile) is the score at or BELOW which a specified percentage of scores falls, not 'at or above.' The passage introduced the error by reversing 'below' to 'above' in the first sentence. The second sentence correctly states 'at or below,' but the core definition in the first sentence was altered. A percentile indicates the percentage of scores falling at or below a given score, not at or above it."
    },
    {
      "id": "PMET-0231",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Inter-Rater (Inter-Scorer) Reliability",
      "passage_type": "paragraph",
      "original_passage": "Inter-rater reliability assesses the consistency of scores assigned by different raters or scorers. This is essential for tests involving subjective judgment, such as essay tests, behavioral observations, projective tests, and structured interviews",
      "modified_passage": "Inter-rater reliability assesses the consistency of scores assigned by different raters or scorers. This is essential for tests involving objective judgment, such as essay tests, behavioral observations, projective tests, and structured interviews.",
      "error_original": "objective judgment",
      "error_correct": "subjective judgment",
      "options": [
        "The passage incorrectly states 'behavioral observations'; it should say 'behavioral checklists'",
        "The passage incorrectly states 'objective judgment'; it should say 'subjective judgment'",
        "The passage incorrectly states 'consistency of scores'; it should say 'accuracy of scores'",
        "The passage incorrectly states 'structured interviews'; it should say 'unstructured interviews'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage incorrectly describes inter-rater reliability as essential for tests involving 'objective judgment.' In fact, inter-rater reliability is essential for tests involving 'subjective judgment,' because it is precisely when scoring requires human interpretation and subjective evaluation—such as with essay tests, behavioral observations, projective tests, and structured interviews—that agreement between raters must be assessed. Objective tests (e.g., multiple-choice) have predetermined correct answers and do not typically require inter-rater reliability assessment."
    },
    {
      "id": "PMET-0032",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Exposure Therapy",
      "passage_type": "paragraph",
      "original_passage": "Modern exposure-based treatments emphasize extinction learning rather than counterconditioning. Prolonged exposure to feared stimuli without the feared outcome allows extinction of the fear response . Key principles include:",
      "modified_passage": "Modern exposure-based treatments emphasize counterconditioning rather than extinction learning. Prolonged exposure to feared stimuli without the feared outcome allows extinction of the fear response. Key principles include:",
      "error_original": "counterconditioning rather than extinction learning",
      "error_correct": "extinction learning rather than counterconditioning",
      "options": [
        "The passage incorrectly states that prolonged exposure occurs without the feared outcome; it should say without the conditioned stimulus",
        "The passage incorrectly states that exposure allows extinction of the fear response; it should say habituation of the fear response",
        "The passage incorrectly states 'counterconditioning rather than extinction learning'; it should say 'extinction learning rather than counterconditioning'",
        "The passage incorrectly states these are exposure-based treatments; it should say systematic desensitization treatments"
      ],
      "correct_option_index": 2,
      "explanation": "The original passage states that modern exposure-based treatments emphasize extinction learning rather than counterconditioning. The modified passage reverses this relationship, incorrectly claiming they emphasize counterconditioning rather than extinction learning. Modern exposure therapy (such as prolonged exposure) is grounded in extinction learning principles — the idea that repeated exposure to the CS without the US leads to new inhibitory learning that suppresses the conditioned fear response. Counterconditioning is a different mechanism associated with procedures like systematic desensitization, where a new response (e.g., relaxation) is paired with the feared stimulus."
    },
    {
      "id": "PMET-0449",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "original_passage": "Incremental validity: Improvement in prediction beyond existing measures (assessed with ΔR²)",
      "modified_passage": "Incremental validity: Improvement in prediction beyond existing measures (assessed with ΔF²)",
      "error_original": "ΔF²",
      "error_correct": "ΔR²",
      "options": [
        "The passage incorrectly states 'Improvement in prediction'; it should say 'Improvement in reliability'",
        "The passage incorrectly states 'ΔF²'; it should say 'ΔR²'",
        "The passage incorrectly states 'Incremental validity'; it should say 'Incremental reliability'",
        "The passage incorrectly states 'beyond existing measures'; it should say 'beyond base rates'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage incorrectly identifies the statistic used to assess incremental validity as ΔF² (change in F-squared). The correct statistic is ΔR² (change in R-squared), which represents the change in the proportion of variance accounted for when a new predictor is added to a regression model. ΔR² is the standard metric for evaluating whether a new measure provides a meaningful improvement in prediction beyond what existing measures already offer. While F-tests (ΔF) may be used to determine whether ΔR² is statistically significant, the metric itself for assessing incremental validity is ΔR²."
    },
    {
      "id": "PMET-0429",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Publication Bias",
      "passage_type": "paragraph",
      "original_passage": "Funnel plot: A scatter plot of effect sizes (x-axis) against study precision or sample size (y-axis). In the absence of bias, the plot should be symmetrical around the mean effect. Asymmetry (missing studies in the lower-left corner) suggests publication bias.",
      "modified_passage": "Funnel plot: A scatter plot of effect sizes (x-axis) against study precision or sample size (y-axis). In the absence of bias, the plot should be asymmetrical around the mean effect. Asymmetry (missing studies in the lower-left corner) suggests publication bias.",
      "error_original": "asymmetrical",
      "error_correct": "symmetrical",
      "options": [
        "The passage incorrectly states effect sizes are on the x-axis; they should be on the y-axis",
        "The passage incorrectly states the plot should be asymmetrical around the mean effect; it should say symmetrical",
        "The passage incorrectly states missing studies in the lower-left corner; it should say the upper-right corner",
        "The passage incorrectly states study precision is on the y-axis; it should be on the x-axis"
      ],
      "correct_option_index": 1,
      "explanation": "The passage was modified to state that in the absence of bias, the funnel plot should be 'asymmetrical' around the mean effect. This is incorrect — a funnel plot free of publication bias should be symmetrical around the mean effect size. Asymmetry is actually the indicator of potential publication bias, as stated correctly in the next sentence. The error is subtle because the word 'asymmetry' appears correctly in the following sentence describing what suggests bias, which could cause a reader to confuse the two uses."
    },
    {
      "id": "PMET-0250",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Interrupted Time-Series Design",
      "passage_type": "example",
      "original_passage": "Time-Series Example A hospital implements a new suicide prevention protocol and tracks monthly suicide attempts for two years before and two years after implementation. By examining the pattern of data points, researchers can determine whether the intervention was associated with a change in level or trend of suicide attempts",
      "modified_passage": "Time-Series Example A hospital implements a new suicide prevention protocol and tracks monthly suicide attempts for two years before and two years after implementation. By examining the pattern of data points, researchers can determine whether the intervention was associated with a change in level or slope of suicide attempts",
      "error_original": "slope",
      "error_correct": "trend",
      "options": [
        "The passage incorrectly states 'two years before and two years after'; it should say 'one year before and one year after'",
        "The passage incorrectly states 'monthly suicide attempts'; it should say 'weekly suicide attempts'",
        "The passage incorrectly states 'slope'; it should say 'trend'",
        "The passage incorrectly states 'level or slope'; it should say 'level or variability'"
      ],
      "correct_option_index": 2,
      "explanation": "In interrupted time-series design, researchers examine whether an intervention is associated with a change in 'level' (an immediate shift in the data) or 'trend' (a change in the direction or rate of the data over time). The passage incorrectly substituted 'slope' for 'trend.' While 'slope' may sound related, the standard terminology used in interrupted time-series analysis is 'trend,' which encompasses changes in the overall pattern of data points over time. The other options describe changes that were not actually made to the passage."
    },
    {
      "id": "PMET-0066",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Regression to the Mean",
      "passage_type": "paragraph",
      "original_passage": "Regression to the mean is a statistical phenomenon wherein extreme scores on one measurement tend to be followed by less extreme scores on subsequent measurements. This occurs whenever the correlation between two variables is less than perfect (r < 1.00). The term \"regression\" was coined by Francis Galton based on this observation",
      "modified_passage": "Regression to the mean is a statistical phenomenon wherein extreme scores on one measurement tend to be followed by less extreme scores on subsequent measurements. This occurs whenever the correlation between two variables is less than perfect (r < 1.00). The term \"regression\" was coined by Karl Pearson based on this observation.",
      "error_original": "Karl Pearson",
      "error_correct": "Francis Galton",
      "options": [
        "The passage incorrectly states that regression to the mean involves 'less extreme scores'; it should say 'more extreme scores'",
        "The passage incorrectly states the correlation threshold as 'r < 1.00'; it should say 'r < 0.50'",
        "The passage incorrectly states the term was coined by 'Karl Pearson'; it should say 'Francis Galton'",
        "The passage incorrectly states 'extreme scores on one measurement'; it should say 'average scores on one measurement'"
      ],
      "correct_option_index": 2,
      "explanation": "The passage attributes the coining of the term 'regression' to Karl Pearson, but it was actually Francis Galton who coined the term based on his observations of hereditary characteristics (e.g., the heights of parents and their children). Karl Pearson was a contemporary who contributed significantly to statistics (e.g., the Pearson correlation coefficient) but did not coin the term 'regression.' The other options describe changes that were not actually made to the passage."
    },
    {
      "id": "PMET-0394",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Descriptive Statistics",
      "passage_type": "paragraph",
      "original_passage": "Descriptive statistics summarize and organize data to make patterns more interpretable. They fall into three main categories: measures of central tendency, measures of variability, and measures of relative position",
      "modified_passage": "Descriptive statistics summarize and organize data to make patterns more interpretable. They fall into three main categories: measures of central tendency, measures of variability, and measures of correlation.",
      "error_original": "measures of correlation",
      "error_correct": "measures of relative position",
      "options": [
        "The passage incorrectly states 'measures of variability'; it should say 'measures of dispersion'",
        "The passage incorrectly states 'summarize and organize'; it should say 'analyze and interpret'",
        "The passage incorrectly states 'measures of correlation'; it should say 'measures of relative position'",
        "The passage incorrectly states 'three main categories'; it should say 'four main categories'"
      ],
      "correct_option_index": 2,
      "explanation": "The passage replaced 'measures of relative position' with 'measures of correlation.' The three main categories of descriptive statistics are measures of central tendency, measures of variability, and measures of relative position (e.g., percentile ranks, z-scores). Measures of correlation are a type of inferential or associational statistic, not one of the three main categories of descriptive statistics. Note that 'measures of variability' and 'measures of dispersion' are synonymous terms, so option A describes a distinction without a real difference. The passage correctly states three categories, not four."
    },
    {
      "id": "PMET-0476",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Problems with Punishment",
      "passage_type": "paragraph",
      "original_passage": "Temporary suppression: Punishment often suppresses behavior only temporarily and in the presence of the punishing agent",
      "modified_passage": "Temporary suppression: Punishment often eliminates behavior only temporarily and in the presence of the punishing agent",
      "error_original": "eliminates",
      "error_correct": "suppresses",
      "options": [
        "The passage incorrectly states 'temporarily'; it should say 'permanently'",
        "The passage incorrectly states 'eliminates'; it should say 'suppresses'",
        "The passage incorrectly states 'in the presence of'; it should say 'in the absence of'",
        "The passage incorrectly states 'punishing agent'; it should say 'reinforcing agent'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage incorrectly uses the word 'eliminates' when it should say 'suppresses.' A key problem with punishment is that it does not eliminate behavior but merely suppresses it. This is an important distinction in operant conditioning: punishment temporarily suppresses the target behavior, particularly when the punishing agent is present, but the behavior often returns when the punishment is removed or the punishing agent is absent. The word 'eliminates' overstates the effect and misrepresents a fundamental limitation of punishment as a behavioral intervention."
    },
    {
      "id": "PMET-0232",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Standard Error of Measurement",
      "passage_type": "paragraph",
      "original_passage": "The standard error of measurement (SEM) quantifies the amount of error expected in an individual's observed score. While the reliability coefficient describes group-level consistency, the SEM provides information about the precision of individual scores",
      "modified_passage": "The standard error of measurement (SEM) quantifies the amount of error expected in an individual's observed score. While the reliability coefficient describes group-level consistency, the SEM provides information about the accuracy of individual scores",
      "error_original": "accuracy",
      "error_correct": "precision",
      "options": [
        "The passage incorrectly states 'observed score'; it should say 'true score'",
        "The passage incorrectly states 'group-level consistency'; it should say 'individual-level consistency'",
        "The passage incorrectly states 'accuracy of individual scores'; it should say 'precision of individual scores'",
        "The passage incorrectly states 'reliability coefficient'; it should say 'validity coefficient'"
      ],
      "correct_option_index": 2,
      "explanation": "The passage replaced the word 'precision' with 'accuracy.' In psychometrics, the SEM specifically provides information about the precision of individual scores — that is, how close repeated measurements of the same person would cluster together. Precision and accuracy are distinct concepts: precision refers to the consistency or repeatability of measurements, while accuracy refers to how close a measurement is to the true value. The SEM is a measure of precision, not accuracy. The other options describe changes that were not actually made in the passage."
    },
    {
      "id": "PMET-0577",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "References",
      "passage_type": "paragraph",
      "original_passage": "Campbell, D. T., & Fiske, D. W. (1959). Convergent and discriminant validation by the multitrait-multimethod matrix. Psychological Bulletin, 56(2), 81-105.",
      "modified_passage": "Campbell, D. T., & Fiske, D. W. (1959). Convergent and discriminant validation by the multitrait-multimethod matrix. Psychological Review, 56(2), 81-105.",
      "error_original": "Psychological Review",
      "error_correct": "Psychological Bulletin",
      "options": [
        "The passage incorrectly states the publication year as 1959; it should say 1957",
        "The passage incorrectly states the journal as Psychological Review; it should say Psychological Bulletin",
        "The passage incorrectly states the volume number as 56; it should say 58",
        "The passage incorrectly states the second author as Fiske, D. W.; it should say Cronbach, L. J."
      ],
      "correct_option_index": 1,
      "explanation": "The seminal Campbell and Fiske (1959) article on convergent and discriminant validation using the multitrait-multimethod matrix was published in Psychological Bulletin, not Psychological Review. Both are well-known APA journals, making this a subtle but verifiable error. The correct citation is: Psychological Bulletin, 56(2), 81-105."
    },
    {
      "id": "PMET-0401",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "The Normal Distribution",
      "passage_type": "paragraph",
      "original_passage": "The normal distribution (also called the Gaussian distribution or bell curve) is a theoretical probability distribution that is symmetric, unimodal, and asymptotic. Many psychological variables approximate normal distributions in large samples, and the normal distribution underlies many statistical procedures",
      "modified_passage": "The normal distribution (also called the Gaussian distribution or bell curve) is a theoretical probability distribution that is symmetric, bimodal, and asymptotic. Many psychological variables approximate normal distributions in large samples, and the normal distribution underlies many statistical procedures.",
      "error_original": "bimodal",
      "error_correct": "unimodal",
      "options": [
        "The passage incorrectly states the distribution is 'symmetric'; it should say 'asymmetric'",
        "The passage incorrectly states 'bimodal'; it should say 'unimodal'",
        "The passage incorrectly states 'Gaussian distribution'; it should say 'Galton distribution'",
        "The passage incorrectly states 'asymptotic'; it should say 'platykurtic'"
      ],
      "correct_option_index": 1,
      "explanation": "The normal distribution is unimodal, meaning it has a single peak or mode. The passage incorrectly describes it as 'bimodal,' which would mean it has two peaks. A bimodal distribution has two distinct modes and does not describe the classic bell curve shape of the normal distribution. The three defining characteristics of the normal distribution are that it is symmetric, unimodal, and asymptotic (the tails approach but never touch the x-axis)."
    },
    {
      "id": "PMET-0522",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Item Parameters",
      "passage_type": "paragraph",
      "original_passage": "IRT models characterize items using up to three parameters:",
      "modified_passage": "IRT models characterize items using up to three parameters: the a-parameter represents item difficulty and indicates the location on the latent trait continuum where the item functions best; the b-parameter represents item discrimination and reflects how well the item differentiates between examinees at different trait levels; and the c-parameter represents the pseudo-guessing parameter, which accounts for the probability of a low-ability examinee answering correctly by chance. In the one-parameter (Rasch) model, only item difficulty is estimated, while the two-parameter model adds discrimination, and the three-parameter model includes all three. Higher discrimination values produce steeper item characteristic curves, meaning the item more sharply distinguishes between examinees above and below the difficulty threshold.",
      "error_original": "the a-parameter represents item difficulty and indicates the location on the latent trait continuum where the item functions best; the b-parameter represents item discrimination",
      "error_correct": "the a-parameter represents item discrimination; the b-parameter represents item difficulty and indicates the location on the latent trait continuum where the item functions best",
      "options": [
        "The passage incorrectly states that higher discrimination values produce steeper item characteristic curves; it should say flatter item characteristic curves",
        "The passage incorrectly states that the c-parameter represents the pseudo-guessing parameter; it should say the pseudo-ceiling parameter",
        "The passage incorrectly states that the a-parameter represents item difficulty and the b-parameter represents item discrimination; it should say the a-parameter represents discrimination and the b-parameter represents difficulty",
        "The passage incorrectly states that the one-parameter (Rasch) model estimates only item difficulty; it should say it estimates only item discrimination"
      ],
      "correct_option_index": 2,
      "explanation": "In Item Response Theory, the a-parameter represents item discrimination (how well the item differentiates between examinees), while the b-parameter represents item difficulty (the location on the trait continuum). The passage swapped these two definitions. The a-parameter corresponds to the slope of the item characteristic curve (discrimination), and the b-parameter corresponds to the inflection point on the trait scale (difficulty). The other options describe changes that were not made in the passage."
    },
    {
      "id": "PMET-0035",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Standard Error of Estimate",
      "passage_type": "definition",
      "original_passage": "Key Regression Concepts Predictor Variable (X): The variable used to make predictions; also called the independent variable in regression. Criterion Variable (Y): The variable being predicted; also called the dependent variable in regression. Residual: The difference between the actual Y score and the predicted Y score (Y - Y'). SEE: The standard deviation of the residuals; indicates prediction accuracy",
      "modified_passage": "Key Regression Concepts Predictor Variable (X): The variable used to make predictions; also called the independent variable in regression. Criterion Variable (Y): The variable being predicted; also called the dependent variable in regression. Residual: The difference between the actual Y score and the predicted Y score (Y - Y'). SEE: The variance of the residuals; indicates prediction accuracy",
      "error_original": "The variance of the residuals",
      "error_correct": "The standard deviation of the residuals",
      "options": [
        "The passage incorrectly states that the Criterion Variable is 'also called the dependent variable'; it should say 'also called the control variable'",
        "The passage incorrectly states that the Residual is '(Y - Y')'; it should say '(Y' - Y)'",
        "The passage incorrectly states that the SEE is 'the variance of the residuals'; it should say 'the standard deviation of the residuals'",
        "The passage incorrectly states that the Predictor Variable is 'also called the independent variable'; it should say 'also called the extraneous variable'"
      ],
      "correct_option_index": 2,
      "explanation": "The passage incorrectly defines the Standard Error of Estimate (SEE) as 'the variance of the residuals.' The SEE is actually the standard deviation of the residuals, not the variance. The standard deviation and variance are related but distinct measures — the variance is the square of the standard deviation. The SEE specifically represents the standard deviation of the distribution of residuals (prediction errors) around the regression line, providing a measure of how accurate predictions are in the original units of the criterion variable."
    },
    {
      "id": "PMET-0432",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "original_passage": "Correlation ≠ Causation: Correlation describes relationships but cannot establish cause and effect",
      "modified_passage": "Correlation ≠ Causation: Correlation describes relationships but cannot establish cause or effect independently; however, a sufficiently high correlation coefficient (e.g., r > .80) can be used to infer directionality of the relationship between two variables.",
      "error_original": "a sufficiently high correlation coefficient (e.g., r > .80) can be used to infer directionality of the relationship between two variables",
      "error_correct": "even a high correlation coefficient cannot be used to infer directionality or causation between two variables",
      "options": [
        "The passage incorrectly states that correlation 'describes relationships'; it should say correlation 'describes differences'",
        "The passage incorrectly states that a sufficiently high correlation can be used to infer directionality; in fact, no correlation, regardless of magnitude, can establish directionality or causation",
        "The passage incorrectly uses r > .80 as the threshold; the correct threshold for a high correlation is r > .70",
        "The passage incorrectly states 'Correlation ≠ Causation'; it should state 'Correlation ≈ Causation' under certain conditions"
      ],
      "correct_option_index": 1,
      "explanation": "The fundamental principle in correlational research is that correlation never implies causation or directionality, regardless of the magnitude of the correlation coefficient. A correlation of r = .99 is just as incapable of establishing cause-and-effect or directionality as a correlation of r = .10. The passage erroneously claims that a high correlation (r > .80) can be used to infer directionality, which directly contradicts this core principle. The other options are distractors: correlation does describe relationships (not differences), the specific threshold of .80 vs. .70 is irrelevant since no magnitude permits causal inference, and the notation 'Correlation ≠ Causation' is the correct and well-established principle."
    },
    {
      "id": "PMET-0249",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Factorial Designs",
      "passage_type": "example",
      "original_passage": "Factorial Design Example A researcher examines the effects of therapy type (CBT vs. psychodynamic) and medication (present vs. absent) on anxiety symptoms using a 2 × 2 factorial design. This allows examination of: (1) the main effect of therapy type, (2) the main effect of medication, and (3) the interaction between therapy and medication (e.g., whether CBT is particularly effective when combined with medication)",
      "modified_passage": "Factorial Design Example A researcher examines the effects of therapy type (CBT vs. psychodynamic) and medication (present vs. absent) on anxiety symptoms using a 2 × 2 factorial design. This allows examination of: (1) the main effect of therapy type, (2) the main effect of medication, and (3) the correlation between therapy and medication (e.g., whether CBT is particularly effective when combined with medication)",
      "error_original": "the correlation between therapy and medication",
      "error_correct": "the interaction between therapy and medication",
      "options": [
        "The passage incorrectly states 'psychodynamic'; it should say 'humanistic'",
        "The passage incorrectly states '2 × 2 factorial design'; it should say '2 × 3 factorial design'",
        "The passage incorrectly states 'the correlation between therapy and medication'; it should say 'the interaction between therapy and medication'",
        "The passage incorrectly states 'main effect of therapy type'; it should say 'simple effect of therapy type'"
      ],
      "correct_option_index": 2,
      "explanation": "In a factorial design, the third element examined (beyond the two main effects) is the interaction between the independent variables, not the correlation. An interaction effect tests whether the effect of one independent variable depends on the level of another independent variable. Correlation is a statistical concept describing the linear relationship between two continuous variables, which is not what is being examined in a factorial ANOVA design. The passage should read 'the interaction between therapy and medication.'"
    },
    {
      "id": "PMET-0415",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Systematic Desensitization",
      "passage_type": "paragraph",
      "original_passage": "Progressing through the hierarchy until the most feared item can be imagined while relaxed",
      "modified_passage": "Progressing through the hierarchy until the least feared item can be imagined while relaxed",
      "error_original": "least feared item",
      "error_correct": "most feared item",
      "options": [
        "The passage incorrectly states 'imagined while relaxed'; it should say 'imagined while aroused'",
        "The passage incorrectly states 'least feared item'; it should say 'most feared item'",
        "The passage incorrectly states 'progressing through the hierarchy'; it should say 'regressing through the hierarchy'",
        "The passage incorrectly states 'imagined'; it should say 'experienced in vivo'"
      ],
      "correct_option_index": 1,
      "explanation": "In systematic desensitization, the client progressively works through the anxiety hierarchy from least to most feared items. The goal is to eventually be able to remain relaxed while imagining the MOST feared item, not the least feared item. The passage incorrectly substituted 'least' for 'most,' reversing the endpoint of the procedure. The least feared item is where the client begins, not where they finish."
    },
    {
      "id": "PMET-0536",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "original_passage": "Know the difference between cross-sectional (one time point, different groups) and longitudinal (multiple time points, same participants) designs",
      "modified_passage": "Know the difference between cross-sectional (one time point, different groups) and longitudinal (multiple time points, different participants) designs",
      "error_original": "different participants",
      "error_correct": "same participants",
      "options": [
        "The passage incorrectly states that cross-sectional designs use 'different groups'; it should say 'same groups'",
        "The passage incorrectly states that cross-sectional designs use 'one time point'; it should say 'multiple time points'",
        "The passage incorrectly states that longitudinal designs use 'different participants'; it should say 'same participants'",
        "The passage incorrectly states that longitudinal designs use 'multiple time points'; it should say 'one time point'"
      ],
      "correct_option_index": 2,
      "explanation": "The error introduced was changing 'same participants' to 'different participants' in the description of longitudinal designs. A defining feature of longitudinal research is that the same participants are studied across multiple time points. Studying different participants at multiple time points would instead describe a cross-sequential or repeated cross-sectional design, not a true longitudinal design."
    },
    {
      "id": "PMET-0550",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "References",
      "passage_type": "paragraph",
      "original_passage": "Biglan, A., Ary, D., & Wagenaar, A. C. (2000). The value of interrupted time-series experiments for community intervention research. Prevention Science, 1(1), 31-49.",
      "modified_passage": "Biglan, A., Ary, D., & Wagenaar, A. C. (2000). The value of interrupted time-series experiments for community intervention research. Prevention Science, 2(1), 31-49.",
      "error_original": "2(1)",
      "error_correct": "1(1)",
      "options": [
        "The passage incorrectly states the journal name as 'Prevention Science'; it should say 'Prevention Research'",
        "The passage incorrectly states the volume number as '2(1)'; it should say '1(1)'",
        "The passage incorrectly states the page range as '31-49'; it should say '31-59'",
        "The passage incorrectly states the publication year as '2000'; it should say '2001'"
      ],
      "correct_option_index": 1,
      "explanation": "The volume number was changed from 1(1) to 2(1). The correct citation indicates this article was published in Volume 1, Issue 1 of Prevention Science. This was the inaugural issue of the journal, published in 2000. All other details in the reference — the authors, year, article title, journal name, and page numbers — are correct as stated."
    },
    {
      "id": "PMET-0208",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Applications of IRT",
      "passage_type": "clinical_note",
      "original_passage": "IRT and the EPPP The EPPP itself uses IRT-based scoring. Items are calibrated using IRT models, and examinee scores are estimated on a theta scale. This means the EPPP can draw from a large item bank while maintaining score comparability across administrations. The pass/fail decision is based on a theta cutoff rather than a raw percentage correct, which accounts for differences in item difficulty across test forms",
      "modified_passage": "IRT and the EPPP The EPPP itself uses IRT-based scoring. Items are calibrated using IRT models, and examinee scores are estimated on a delta scale. This means the EPPP can draw from a large item bank while maintaining score comparability across administrations. The pass/fail decision is based on a theta cutoff rather than a raw percentage correct, which accounts for differences in item difficulty across test forms.",
      "error_original": "delta scale",
      "error_correct": "theta scale",
      "options": [
        "The passage incorrectly states that the pass/fail decision accounts for differences in item difficulty; it should say differences in item discrimination.",
        "The passage incorrectly states scores are estimated on a delta scale; it should say a theta scale.",
        "The passage incorrectly states the pass/fail decision is based on a theta cutoff; it should say a stanine cutoff.",
        "The passage incorrectly states the EPPP uses IRT-based scoring; it should say CTT-based scoring."
      ],
      "correct_option_index": 1,
      "explanation": "In IRT, examinee ability is estimated on a theta (θ) scale. The passage was modified to say 'delta scale' instead of the correct term 'theta scale.' Delta is not the standard term used in IRT for the ability parameter — theta is the conventional notation. The other options describe changes that were not actually made to the passage."
    },
    {
      "id": "PMET-0398",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Measures of Variability",
      "passage_type": "paragraph",
      "original_passage": "The range is the difference between the highest and lowest scores. It is simple but unstable because it is based on only two scores and is highly sensitive to outliers",
      "modified_passage": "The range is the difference between the highest and lowest scores. It is simple but unstable because it is based on only two scores and is highly sensitive to skewness",
      "error_original": "skewness",
      "error_correct": "outliers",
      "options": [
        "The passage incorrectly states the range is the difference between the highest and lowest scores; it should say it is the difference between the mean and the lowest score",
        "The passage incorrectly states the range is based on only two scores; it should say it is based on three scores",
        "The passage incorrectly states the range is sensitive to skewness; it should say it is sensitive to outliers",
        "The passage incorrectly states the range is simple but unstable; it should say it is complex but stable"
      ],
      "correct_option_index": 2,
      "explanation": "The original passage correctly states that the range is 'highly sensitive to outliers.' In the modified passage, 'outliers' was replaced with 'skewness.' While skewness is a related statistical concept, the specific vulnerability of the range as a measure of variability is its sensitivity to outliers (extreme scores), since it relies solely on the two most extreme values in a distribution. Skewness describes the asymmetry of a distribution and is a different concept altogether."
    },
    {
      "id": "PMET-0064",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Multiple Correlation Coefficient (R)",
      "passage_type": "paragraph",
      "original_passage": "R² indicates the proportion of variance in the criterion variable explained by the combination of all predictor variables. R² always increases (or stays the same) when additional predictors are added, even if those predictors have no true relationship with the criterion. For this reason, adjusted R² is often reported, which accounts for the number of predictors and sample size",
      "modified_passage": "R² indicates the proportion of variance in the criterion variable explained by the combination of all predictor variables. R² always increases (or stays the same) when additional predictors are added, even if those predictors have no true relationship with the criterion. For this reason, adjusted R² is often reported, which accounts for the number of predictors and effect size",
      "error_original": "effect size",
      "error_correct": "sample size",
      "options": [
        "The passage incorrectly states that R² 'always increases (or stays the same)'; it should say 'always decreases (or stays the same)'",
        "The passage incorrectly states 'effect size'; it should say 'sample size'",
        "The passage incorrectly states 'criterion variable'; it should say 'predictor variable'",
        "The passage incorrectly states 'proportion of variance'; it should say 'standard deviation of variance'"
      ],
      "correct_option_index": 1,
      "explanation": "The original passage correctly states that adjusted R² accounts for the number of predictors and sample size. The modified passage substituted 'effect size' for 'sample size.' Adjusted R² penalizes for the number of predictors relative to the sample size, not effect size. The other options describe errors that were not actually introduced: R² does always increase or stay the same with additional predictors, it does refer to the criterion variable, and it does refer to proportion of variance."
    },
    {
      "id": "PMET-0302",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Introduction to Research Validity",
      "passage_type": "paragraph",
      "original_passage": "Research validity refers to the accuracy and trustworthiness of research conclusions. In the context of research methodology, validity concerns whether a study truly measures what it claims to measure and whether its conclusions are justified. Understanding different types of validity and the threats to each is essential for evaluating psychological research and designing rigorous studies",
      "modified_passage": "Research validity refers to the accuracy and trustworthiness of research conclusions. In the context of research methodology, validity concerns whether a study truly measures what it claims to measure and whether its conclusions are justified. Understanding different types of reliability and the threats to each is essential for evaluating psychological research and designing rigorous studies.",
      "error_original": "reliability",
      "error_correct": "validity",
      "options": [
        "The passage incorrectly states 'accuracy and trustworthiness'; it should say 'precision and consistency'",
        "The passage incorrectly states 'reliability' in the final sentence; it should say 'validity'",
        "The passage incorrectly states 'truly measures what it claims to measure'; this defines reliability, not validity",
        "The passage incorrectly states 'designing rigorous studies'; it should say 'designing reliable studies'"
      ],
      "correct_option_index": 1,
      "explanation": "The original passage consistently discusses 'validity' throughout. In the modified passage, the final sentence incorrectly substitutes 'reliability' for 'validity,' stating 'Understanding different types of reliability and the threats to each...' The passage is entirely about research validity—not reliability. Reliability refers to the consistency or repeatability of measurements, which is a distinct psychometric concept. The correct term should be 'validity,' as the passage is focused on whether studies accurately measure what they intend to measure and whether conclusions are justified."
    },
    {
      "id": "PMET-0070",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Meta-Analysis",
      "passage_type": "paragraph",
      "original_passage": "Meta-analysis is a quantitative method for systematically combining results from multiple studies to arrive at an overall estimate of an effect. Unlike a narrative literature review, meta-analysis uses statistical techniques to integrate findings, weight studies by quality or sample size, and assess variability across studies . Correlation coefficients can be converted to other effect size metrics and combined to estimate population-level relationships while accounting for sampling error and study artifacts (Hunter & Schmidt, 2004)",
      "modified_passage": "Meta-analysis is a quantitative method for systematically combining results from multiple studies to arrive at an overall estimate of an effect. Unlike a narrative literature review, meta-analysis uses statistical techniques to integrate findings, weight studies by quality or sample size, and assess variability across studies. Correlation coefficients can be converted to other effect size metrics and combined to estimate sample-level relationships while accounting for sampling error and study artifacts (Hunter & Schmidt, 2004)",
      "error_original": "sample-level relationships",
      "error_correct": "population-level relationships",
      "options": [
        "The passage incorrectly states 'quantitative method'; it should say 'qualitative method'",
        "The passage incorrectly states 'sample-level relationships'; it should say 'population-level relationships'",
        "The passage incorrectly states 'Hunter & Schmidt, 2004'; it should say 'Cohen & Cohen, 2004'",
        "The passage incorrectly states 'sampling error'; it should say 'measurement error'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage was modified to say 'sample-level relationships' when it should say 'population-level relationships.' A key purpose of meta-analysis, particularly as described by Hunter and Schmidt (2004), is to estimate population-level parameters by aggregating across multiple samples. The goal is to move beyond individual sample estimates to infer the true underlying population relationship, correcting for sampling error and other study artifacts."
    },
    {
      "id": "PMET-0360",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Evidence Based on Consequences of Testing",
      "passage_type": "paragraph",
      "original_passage": "This evidence considers the intended and unintended consequences of test use, including potential benefits and harms. It addresses whether test use achieves its intended outcomes and whether any negative consequences are related to construct-irrelevant factors such as bias",
      "modified_passage": "This evidence considers the intended and unintended consequences of test use, including potential benefits and harms. It addresses whether test use achieves its intended outcomes and whether any negative consequences are related to construct-underrepresentation factors such as bias",
      "error_original": "construct-underrepresentation factors",
      "error_correct": "construct-irrelevant factors",
      "options": [
        "The passage incorrectly states 'intended and unintended consequences'; it should say 'intended and anticipated consequences'",
        "The passage incorrectly states 'construct-underrepresentation factors'; it should say 'construct-irrelevant factors'",
        "The passage incorrectly states 'potential benefits and harms'; it should say 'potential reliability and validity concerns'",
        "The passage incorrectly states 'intended outcomes'; it should say 'predicted outcomes'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage incorrectly uses 'construct-underrepresentation factors' when it should say 'construct-irrelevant factors.' In validity theory, construct-irrelevant variance refers to systematic variance in test scores that is attributable to factors outside the construct being measured (e.g., bias), which can lead to negative consequences of test use. Construct underrepresentation is a different validity threat that refers to a test failing to capture important aspects of the construct. The original passage correctly identified construct-irrelevant factors (such as bias) as the source of negative consequences in consequential evidence of validity."
    },
    {
      "id": "PMET-0403",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Skewness and Kurtosis",
      "passage_type": "paragraph",
      "original_passage": "Real data often deviate from the normal distribution. Two important characteristics describe the shape of distributions: skewness and kurtosis",
      "modified_passage": "Real data often deviate from the normal distribution. Two important characteristics describe the shape of distributions: skewness and variance.",
      "error_original": "variance",
      "error_correct": "kurtosis",
      "options": [
        "The passage incorrectly states that real data 'often' deviate from the normal distribution; it should say 'rarely'",
        "The passage incorrectly states 'variance' as a shape characteristic; it should say 'kurtosis'",
        "The passage incorrectly states there are 'two' important shape characteristics; it should say 'three'",
        "The passage incorrectly states these characteristics describe the 'shape' of distributions; it should say 'central tendency'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage replaced 'kurtosis' with 'variance.' Variance is a measure of dispersion (spread) in a distribution, not a measure of its shape. The two key characteristics that describe the shape of a distribution are skewness (which measures asymmetry) and kurtosis (which measures the degree of peakedness or heaviness of the tails relative to a normal distribution). Together, skewness and kurtosis are the standard descriptors of distributional shape in statistics and psychometrics."
    },
    {
      "id": "PMET-0022",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Experimental Neurosis",
      "passage_type": "paragraph",
      "original_passage": "Pavlov observed that when discrimination training becomes too difficult - when the CS+ and CS- become increasingly similar - animals may develop behavioral disturbances including agitation, aggression, and stereotyped behaviors. He termed this experimental neurosis",
      "modified_passage": "Pavlov observed that when generalization training becomes too difficult - when the CS+ and CS- become increasingly similar - animals may develop behavioral disturbances including agitation, aggression, and stereotyped behaviors. He termed this experimental neurosis",
      "error_original": "generalization training",
      "error_correct": "discrimination training",
      "options": [
        "The passage incorrectly states that Pavlov observed this phenomenon; it was actually Watson who first described experimental neurosis",
        "The passage incorrectly states 'generalization training'; it should say 'discrimination training'",
        "The passage incorrectly states that CS+ and CS- become increasingly similar; they actually become increasingly different",
        "The passage incorrectly states the term was 'experimental neurosis'; Pavlov actually called it 'conditioned anxiety'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage substituted 'generalization training' for 'discrimination training.' Experimental neurosis occurs specifically when discrimination training becomes too difficult — that is, when the organism is required to discriminate between a CS+ (reinforced stimulus) and a CS- (non-reinforced stimulus) that are made increasingly similar. Generalization is the opposite process, where responding spreads to similar stimuli, and is not the training procedure that produces experimental neurosis. Pavlov demonstrated that it was the increasingly difficult discrimination task that led to the behavioral disturbances he termed experimental neurosis."
    },
    {
      "id": "PMET-0239",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Introduction to Research Designs",
      "passage_type": "definition",
      "original_passage": "Key Terminology True Experiment: A design with random assignment, manipulation of the independent variable, and control of extraneous variables Quasi-Experiment: A design lacking random assignment but including manipulation of the independent variable Random Assignment: Procedure ensuring each participant has an equal chance of being assigned to any condition Control Group: A comparison condition that does not receive the experimental treatment Between-Subjects Design: Different participants in each condition Within-Subjects Design: Same participants tested in all conditions",
      "modified_passage": "Key Terminology True Experiment: A design with random assignment, manipulation of the independent variable, and control of extraneous variables Quasi-Experiment: A design lacking random assignment but including manipulation of the independent variable Random Assignment: Procedure ensuring each participant has an equal chance of being assigned to any condition Control Group: A comparison condition that does not receive the experimental treatment Between-Subjects Design: Different participants in each condition Within-Subjects Design: Same participants tested in all conditions. A quasi-experiment differs from a true experiment primarily because it lacks manipulation of the independent variable.",
      "error_original": "it lacks manipulation of the independent variable",
      "error_correct": "it lacks random assignment",
      "options": [
        "The passage incorrectly states that a control group 'does not receive the experimental treatment'; it should say 'receives a placebo treatment'",
        "The passage incorrectly states that a quasi-experiment 'lacks manipulation of the independent variable'; it should say 'lacks random assignment'",
        "The passage incorrectly states that random assignment ensures 'an equal chance of being assigned to any condition'; it should say 'a proportional chance of being assigned to any condition'",
        "The passage incorrectly states that a within-subjects design has 'same participants tested in all conditions'; it should say 'different participants tested in all conditions'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage's final sentence incorrectly states that a quasi-experiment differs from a true experiment because it lacks manipulation of the independent variable. According to the definitions provided earlier in the passage itself (and standard research methodology), a quasi-experiment DOES include manipulation of the independent variable — what it lacks is random assignment. This is the defining distinction between true experiments and quasi-experiments."
    },
    {
      "id": "PMET-0060",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Standard Error of Estimate",
      "passage_type": "paragraph",
      "original_passage": "The relationship between SEE and correlation is: as r increases, SEE decreases. When r = 1.00 (perfect correlation), SEE = 0 (no prediction error). When r = 0, the SEE equals the standard deviation of the Y variable (knowing X provides no improvement over just guessing the mean of Y)",
      "modified_passage": "The relationship between SEE and correlation is: as r increases, SEE decreases. When r = 1.00 (perfect correlation), SEE = 0 (no prediction error). When r = 0, the SEE equals the standard deviation of the X variable (knowing X provides no improvement over just guessing the mean of Y)",
      "error_original": "the standard deviation of the X variable",
      "error_correct": "the standard deviation of the Y variable",
      "options": [
        "The passage incorrectly states that when r = 1.00, SEE = 0; it should say SEE = 1.00",
        "The passage incorrectly states that as r increases, SEE decreases; it should say SEE increases",
        "The passage incorrectly states that SEE equals the standard deviation of the X variable when r = 0; it should say the standard deviation of the Y variable",
        "The passage incorrectly states 'no prediction error' for perfect correlation; it should say 'no measurement error'"
      ],
      "correct_option_index": 2,
      "explanation": "The passage was modified to say 'standard deviation of the X variable' when r = 0, but the correct statement is that when r = 0, the SEE equals the standard deviation of the Y variable (the criterion variable). This is because when there is no correlation between X and Y, knowing X provides no predictive advantage, so the best prediction for any value of X is simply the mean of Y, and the error of that prediction equals the standard deviation of Y."
    },
    {
      "id": "PMET-0062",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Multiple Regression",
      "passage_type": "paragraph",
      "original_passage": "Each predictor variable has its own regression coefficient (b) indicating its unique contribution to predicting Y while controlling for other predictors",
      "modified_passage": "Each predictor variable has its own regression coefficient (b) indicating its total contribution to predicting Y while controlling for other predictors",
      "error_original": "total contribution",
      "error_correct": "unique contribution",
      "options": [
        "The passage incorrectly states 'regression coefficient (b)'; it should say 'correlation coefficient (r)'",
        "The passage incorrectly states 'total contribution'; it should say 'unique contribution'",
        "The passage incorrectly states 'controlling for other predictors'; it should say 'adding other predictors'",
        "The passage incorrectly states 'predicting Y'; it should say 'predicting X'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage incorrectly describes the regression coefficient (b) as indicating the 'total contribution' to predicting Y. In multiple regression, each predictor's regression coefficient (b) represents its 'unique contribution' to predicting Y — that is, the portion of variance it explains while statistically controlling for (holding constant) all other predictors in the model. 'Total contribution' would imply no partialing out of shared variance with other predictors, which contradicts the fundamental purpose of the multiple regression coefficient."
    },
    {
      "id": "PMET-0565",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "original_passage": "External Validity: Can we generalize findings? Population, ecological, and temporal generalizability",
      "modified_passage": "External Validity: Can we generalize findings? External validity refers to the extent to which research findings can be generalized beyond the specific conditions of the study. There are three main types of external validity to consider: population generalizability (whether findings apply to other groups of people), ecological generalizability (whether findings apply to other settings or conditions), and temporal generalizability (whether findings remain stable over time). Threats to external validity include selection bias, the Hawthorne effect, and order effects. Campbell and Stanley (1963) originally distinguished between internal and external validity, and Cook and Campbell (1979) later expanded the framework to include four types of validity: internal validity, external validity, construct validity, and statistical validity.",
      "error_original": "statistical validity",
      "error_correct": "statistical conclusion validity",
      "options": [
        "The passage incorrectly states there are three main types of external validity; there are actually four main types",
        "The passage incorrectly states that Campbell and Stanley originally distinguished between internal and external validity; this distinction was made by Cook and Campbell",
        "The passage incorrectly states 'statistical validity'; it should say 'statistical conclusion validity'",
        "The passage incorrectly lists the Hawthorne effect as a threat to external validity; it is actually a threat to internal validity"
      ],
      "correct_option_index": 2,
      "explanation": "Cook and Campbell (1979) expanded the validity framework to include four types: internal validity, external validity, construct validity, and statistical conclusion validity (not simply 'statistical validity'). Statistical conclusion validity specifically refers to the validity of conclusions about the covariation between variables, including whether the relationship is statistically significant and the strength of that relationship. The term 'statistical conclusion validity' is the precise and correct name used by Cook and Campbell, and this distinction is commonly tested on the EPPP."
    },
    {
      "id": "PMET-0010",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Acquisition",
      "passage_type": "paragraph",
      "original_passage": "Delay conditioning is the most effective temporal arrangement for establishing conditioned responses. In this procedure, the CS begins before the US and continues until the US is presented. The CS \"overlaps\" with the US onset, creating optimal conditions for association formation",
      "modified_passage": "Delay conditioning is the most effective temporal arrangement for establishing conditioned responses. In this procedure, the CS begins before the US and continues until the US is presented. The CS \"overlaps\" with the US offset, creating optimal conditions for association formation.",
      "error_original": "US offset",
      "error_correct": "US onset",
      "options": [
        "The passage incorrectly states 'continues until the US is presented'; it should say 'terminates before the US is presented'",
        "The passage incorrectly states 'US offset'; it should say 'US onset'",
        "The passage incorrectly states 'Delay conditioning'; it should say 'Trace conditioning'",
        "The passage incorrectly states 'CS begins before the US'; it should say 'CS begins after the US'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage was modified to say 'US offset' instead of the correct term 'US onset.' In delay conditioning, the CS overlaps with the onset (beginning) of the US, not the offset (end). The overlap with the US onset is what creates optimal conditions for association formation. Option A is incorrect because the CS does indeed continue until the US is presented in delay conditioning. Option C is incorrect because delay conditioning (not trace conditioning) is correctly identified as the most effective temporal arrangement. Option D is incorrect because the CS does begin before the US in delay conditioning."
    },
    {
      "id": "PMET-0110",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "ROC Curves",
      "passage_type": "paragraph",
      "original_passage": "Receiver Operating Characteristic (ROC) curves plot sensitivity against (1 - specificity) across all possible cutoff scores. The area under the curve (AUC) provides an overall index of diagnostic accuracy independent of any particular cutoff. AUC of .50 indicates chance performance; AUC of 1.0 indicates perfect discrimination",
      "modified_passage": "Receiver Operating Characteristic (ROC) curves plot sensitivity against specificity across all possible cutoff scores. The area under the curve (AUC) provides an overall index of diagnostic accuracy independent of any particular cutoff. AUC of .50 indicates chance performance; AUC of 1.0 indicates perfect discrimination.",
      "error_original": "sensitivity against specificity",
      "error_correct": "sensitivity against (1 - specificity)",
      "options": [
        "The passage incorrectly states that AUC of .50 indicates chance performance; it should say AUC of .00 indicates chance performance",
        "The passage incorrectly states that ROC curves plot sensitivity against specificity; it should say sensitivity against (1 - specificity)",
        "The passage incorrectly states that AUC of 1.0 indicates perfect discrimination; it should say AUC of 1.0 indicates perfect reliability",
        "The passage incorrectly states that AUC is independent of any particular cutoff; it should say AUC is dependent on the optimal cutoff"
      ],
      "correct_option_index": 1,
      "explanation": "ROC curves plot sensitivity (true positive rate) on the y-axis against (1 - specificity), which is the false positive rate, on the x-axis. The modified passage incorrectly states that sensitivity is plotted against specificity rather than against (1 - specificity). This is a key distinction because plotting sensitivity against specificity would reverse the x-axis and fundamentally change the interpretation of the curve. A perfect classifier's ROC curve goes to the upper-left corner precisely because the x-axis represents the false positive rate (1 - specificity), not specificity itself."
    },
    {
      "id": "PMET-0528",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "CIPP Model (Stufflebeam)",
      "passage_type": "paragraph",
      "original_passage": "Context evaluation: Assesses needs, problems, and opportunities in the program environment to guide planning decisions",
      "modified_passage": "Context evaluation: Assesses needs, problems, and opportunities in the program environment to guide structuring decisions",
      "error_original": "structuring decisions",
      "error_correct": "planning decisions",
      "options": [
        "The passage incorrectly states 'opportunities'; it should say 'assets'",
        "The passage incorrectly states 'structuring decisions'; it should say 'planning decisions'",
        "The passage incorrectly states 'Context evaluation'; it should say 'Input evaluation'",
        "The passage incorrectly states 'program environment'; it should say 'organizational climate'"
      ],
      "correct_option_index": 1,
      "explanation": "In Stufflebeam's CIPP Model, Context evaluation is specifically designed to guide planning decisions by assessing needs, problems, and opportunities. The passage incorrectly states 'structuring decisions,' which is actually the purpose of Input evaluation in the CIPP framework. Context evaluation informs planning decisions, Input evaluation informs structuring decisions, Process evaluation informs implementing decisions, and Product evaluation informs recycling decisions."
    },
    {
      "id": "PMET-0162",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Discriminative Stimuli",
      "passage_type": "example",
      "original_passage": "Example: Stimulus Control in Everyday Life A ringing telephone (S D ) signals that answering will be reinforced by conversation. The silent telephone (S Δ ) signals that picking up the receiver will not produce reinforcement. Similarly, an \"open\" sign on a store (S D ) signals that entering will be reinforced, while a \"closed\" sign (S Δ ) signals it will not",
      "modified_passage": "Example: Stimulus Control in Everyday Life A ringing telephone (S Δ ) signals that answering will be reinforced by conversation. The silent telephone (S D ) signals that picking up the receiver will not produce reinforcement. Similarly, an \"open\" sign on a store (S D ) signals that entering will be reinforced, while a \"closed\" sign (S Δ ) signals it will not",
      "error_original": "A ringing telephone (S Δ ) signals that answering will be reinforced by conversation. The silent telephone (S D )",
      "error_correct": "A ringing telephone (S D ) signals that answering will be reinforced by conversation. The silent telephone (S Δ )",
      "options": [
        "The passage incorrectly states that the \"open\" sign is an S D; it should be an S Δ",
        "The passage incorrectly labels the ringing telephone as S Δ and the silent telephone as S D; these labels should be reversed",
        "The passage incorrectly states that answering the phone will be reinforced by conversation; it should say reinforced by the ringing stopping",
        "The passage incorrectly states that a \"closed\" sign signals behavior will not be reinforced; it should say behavior will be punished"
      ],
      "correct_option_index": 1,
      "explanation": "The passage swapped the discriminative stimulus labels for the telephone example. A ringing telephone is an S D (discriminative stimulus) because it signals that answering will be reinforced by conversation. The silent telephone is an S Δ (S-delta) because it signals that picking up the receiver will not produce reinforcement. The modified passage incorrectly reversed these two labels while leaving the store example correct."
    },
    {
      "id": "PMET-0501",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Advantages of IRT",
      "passage_type": "paragraph",
      "original_passage": "Item parameter invariance: Item parameters remain stable across different examinee samples (provided the model fits), enabling items to be calibrated once and used across contexts",
      "modified_passage": "Item parameter invariance: Item parameters remain stable across different examinee samples (provided the model fits), enabling items to be calibrated repeatedly and used across contexts",
      "error_original": "calibrated repeatedly",
      "error_correct": "calibrated once",
      "options": [
        "The passage incorrectly states 'Item parameter invariance'; it should say 'Item characteristic invariance'",
        "The passage incorrectly states 'calibrated repeatedly'; it should say 'calibrated once'",
        "The passage incorrectly states 'remain stable across different examinee samples'; it should say 'remain stable across different test forms'",
        "The passage incorrectly states 'provided the model fits'; it should say 'provided the sample is large enough'"
      ],
      "correct_option_index": 1,
      "explanation": "A key advantage of IRT's item parameter invariance is that items need only be calibrated once and can then be used across different contexts and examinee populations. The passage was modified to say 'calibrated repeatedly,' which contradicts this fundamental efficiency advantage of IRT. The correct phrasing is 'calibrated once,' reflecting that stable item parameters do not require recalibration for each new sample."
    },
    {
      "id": "PMET-0028",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Prepared Fears",
      "passage_type": "paragraph",
      "original_passage": "In contrast, fears of evolutionarily recent threats (cars, electrical outlets, guns) are relatively rare despite causing more deaths in modern society. This preparedness may explain the non-random distribution of phobias in clinical populations (Ohman & Mineka, 2001)",
      "modified_passage": "In contrast, fears of evolutionarily recent threats (cars, electrical outlets, guns) are relatively rare despite causing more deaths in modern society. This preparedness may explain the non-random distribution of phobias in clinical populations (Seligman & Mineka, 2001)",
      "error_original": "Seligman & Mineka, 2001",
      "error_correct": "Ohman & Mineka, 2001",
      "options": [
        "The passage incorrectly states that fears of evolutionarily recent threats are 'relatively rare'; it should say 'relatively common'",
        "The passage incorrectly states that these threats cause 'more deaths'; it should say 'fewer deaths'",
        "The passage incorrectly attributes the citation to 'Seligman & Mineka, 2001'; it should say 'Ohman & Mineka, 2001'",
        "The passage incorrectly states 'non-random distribution'; it should say 'random distribution'"
      ],
      "correct_option_index": 2,
      "explanation": "The passage incorrectly attributes the 2001 citation on prepared fears and phobias to Seligman & Mineka. While Seligman is well-known for his earlier work on preparedness theory (1971), the 2001 publication referenced here was authored by Ohman & Mineka. This is a plausible error because Seligman's name is closely associated with preparedness in learning, making it a tempting but incorrect substitution."
    },
    {
      "id": "PMET-0100",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Base Rate",
      "passage_type": "paragraph",
      "original_passage": "The base rate is the proportion of people in the population who would succeed on the criterion without selection (or who have the condition being assessed). Base rate affects how much a test can improve upon chance prediction",
      "modified_passage": "The base rate is the proportion of people in the population who would succeed on the criterion without selection (or who have the condition being assessed). Base rate affects how much a test can improve upon random prediction",
      "error_original": "random prediction",
      "error_correct": "chance prediction",
      "options": [
        "The passage incorrectly states 'proportion of people'; it should say 'percentage of people'",
        "The passage incorrectly states 'succeed on the criterion'; it should say 'fail on the criterion'",
        "The passage incorrectly states 'without selection'; it should say 'with selection'",
        "The passage incorrectly states 'random prediction'; it should say 'chance prediction'"
      ],
      "correct_option_index": 3,
      "explanation": "The original passage uses the specific term 'chance prediction,' which is the standard terminology in psychometrics when discussing base rates and their relationship to test utility. The modified passage substituted 'random prediction' for 'chance prediction.' While these terms may seem similar in everyday language, 'chance prediction' is the established term used in the context of criterion-related validity and base rate discussions. The other options describe changes that were not actually made to the passage."
    },
    {
      "id": "PMET-0048",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Phi Coefficient",
      "passage_type": "paragraph",
      "original_passage": "The phi coefficient (φ) is used when both variables are true dichotomies. It is commonly used in 2×2 contingency tables and is related to chi-square statistics",
      "modified_passage": "The phi coefficient (φ) is used when both variables are artificial dichotomies. It is commonly used in 2×2 contingency tables and is related to chi-square statistics.",
      "error_original": "artificial dichotomies",
      "error_correct": "true dichotomies",
      "options": [
        "The passage incorrectly states that the phi coefficient is used in 2×2 contingency tables; it should say 3×3 contingency tables.",
        "The passage incorrectly states that the phi coefficient is related to chi-square statistics; it should say related to t-test statistics.",
        "The passage incorrectly states that both variables are artificial dichotomies; it should say true dichotomies.",
        "The passage incorrectly states the symbol is φ; it should say ρ."
      ],
      "correct_option_index": 2,
      "explanation": "The phi coefficient (φ) is specifically used when both variables are true (naturally occurring) dichotomies, such as male/female or alive/dead. The passage incorrectly states 'artificial dichotomies,' which would instead call for a different correlation coefficient, such as the tetrachoric correlation. True dichotomies are variables that naturally fall into two categories, whereas artificial dichotomies are created by splitting a continuous variable into two groups."
    },
    {
      "id": "PMET-0257",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Solomon Four-Group Design",
      "passage_type": "paragraph",
      "original_passage": "The Solomon four-group design combines elements of both previous designs, using four groups: two receive pretests (one treatment, one control) and two do not (one treatment, one control). This design allows researchers to detect and control for testing effects and sensitization",
      "modified_passage": "The Solomon four-group design combines elements of both previous designs, using four groups: two receive pretests (one treatment, one control) and two do not (one treatment, one control). This design allows researchers to detect and control for testing effects and habituation",
      "error_original": "habituation",
      "error_correct": "sensitization",
      "options": [
        "The passage incorrectly states 'two receive pretests'; it should say 'three receive pretests'",
        "The passage incorrectly states 'four groups'; it should say 'six groups'",
        "The passage incorrectly states 'habituation'; it should say 'sensitization'",
        "The passage incorrectly states 'testing effects'; it should say 'maturation effects'"
      ],
      "correct_option_index": 2,
      "explanation": "The passage replaced 'sensitization' with 'habituation.' The Solomon four-group design is specifically noted for its ability to detect and control for testing effects and sensitization — the phenomenon where taking a pretest may sensitize participants to the treatment, altering their responses. Habituation refers to a decrease in response to repeated stimulation, which is a different concept entirely. The other options describe changes that were not actually made to the passage: the design does use four groups, two groups do receive pretests, and the design does address testing effects (not maturation effects)."
    },
    {
      "id": "PMET-0299",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Controlling External Validity Threats",
      "passage_type": "clinical_note",
      "original_passage": "Understanding the Distinction Random assignment controls internal validity threats by ensuring groups are equivalent. Random selection (from the population to the sample) controls external validity threats by ensuring the sample represents the population. Many students confuse these concepts on the EPPP. Random assignment creates equivalent groups; random selection creates representative samples",
      "modified_passage": "Understanding the Distinction Random assignment controls external validity threats by ensuring groups are equivalent. Random selection (from the population to the sample) controls external validity threats by ensuring the sample represents the population. Many students confuse these concepts on the EPPP. Random assignment creates equivalent groups; random selection creates representative samples",
      "error_original": "Random assignment controls external validity threats",
      "error_correct": "Random assignment controls internal validity threats",
      "options": [
        "The passage incorrectly states that random selection controls external validity; it should say random selection controls internal validity",
        "The passage incorrectly states that random assignment controls external validity threats; it should say it controls internal validity threats",
        "The passage incorrectly states that random assignment creates equivalent groups; it should say it creates representative samples",
        "The passage incorrectly states that random selection goes from the population to the sample; it should say from the sample to the population"
      ],
      "correct_option_index": 1,
      "explanation": "The passage incorrectly states that random assignment controls external validity threats. In reality, random assignment controls internal validity threats by ensuring that groups in an experiment are equivalent prior to the manipulation. Random selection is the technique that controls external validity threats by ensuring the sample is representative of the population. This is a common confusion point tested on the EPPP, and the passage itself later correctly notes that 'random assignment creates equivalent groups,' which is the hallmark of internal validity control."
    },
    {
      "id": "PMET-0361",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Construct Validity",
      "passage_type": "paragraph",
      "original_passage": "Construct validity is the overarching concept that encompasses all validity evidence. It addresses the fundamental question: Does the test measure the theoretical construct it purports to measure? All other forms of validity evidence contribute to construct validity (Cronbach & Meehl, 1955)",
      "modified_passage": "Construct validity is the overarching concept that encompasses all validity evidence. It addresses the fundamental question: Does the test measure the theoretical construct it purports to measure? All other forms of validity evidence contribute to construct validity (Cronbach & Loevinger, 1955)",
      "error_original": "Cronbach & Loevinger, 1955",
      "error_correct": "Cronbach & Meehl, 1955",
      "options": [
        "The passage incorrectly states that construct validity 'encompasses all validity evidence'; it should say 'encompasses all reliability evidence'",
        "The passage incorrectly states the citation as 'Cronbach & Loevinger, 1955'; it should say 'Cronbach & Meehl, 1955'",
        "The passage incorrectly states that construct validity is 'the overarching concept'; it should say 'a subordinate concept'",
        "The passage incorrectly states the year as '1955'; it should say '1966'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage substituted 'Loevinger' for 'Meehl' in the classic citation. The seminal paper on construct validity was authored by Lee Cronbach and Paul Meehl in 1955, not Cronbach and Loevinger. While Jane Loevinger was a prominent psychometrician who also contributed to validity theory, the foundational 1955 paper establishing the concept of construct validity and the nomological network was by Cronbach and Meehl."
    },
    {
      "id": "PMET-0083",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Positive and Negative Predictive Value",
      "passage_type": "clinical_note",
      "original_passage": "Base Rate and Predictive Values Predictive values are strongly influenced by base rate: When base rate is low, PPV is low (most positives are false positives) even with good sensitivity/specificity When base rate is high, NPV is low (most negatives are false negatives) This is why screening tests in low-prevalence populations often require confirmation testing",
      "modified_passage": "Base Rate and Predictive Values Predictive values are strongly influenced by base rate: When base rate is low, PPV is low (most positives are false positives) even with good sensitivity/specificity When base rate is high, NPV is low (most negatives are false negatives) This is why screening tests in high-prevalence populations often require confirmation testing",
      "error_original": "high-prevalence populations",
      "error_correct": "low-prevalence populations",
      "options": [
        "The passage incorrectly states that when base rate is low, PPV is low; it should say NPV is low",
        "The passage incorrectly states that most positives are false positives when base rate is low; it should say most positives are true positives",
        "The passage incorrectly states 'high-prevalence populations'; it should say 'low-prevalence populations'",
        "The passage incorrectly states that when base rate is high, NPV is low; it should say PPV is low"
      ],
      "correct_option_index": 2,
      "explanation": "The passage was modified to say 'high-prevalence populations' instead of 'low-prevalence populations.' The correct statement is that screening tests in low-prevalence populations often require confirmation testing. This is because when base rate (prevalence) is low, the positive predictive value (PPV) is low, meaning most positive test results are false positives. Therefore, confirmation testing is needed to verify positive results in low-prevalence settings. In high-prevalence populations, PPV tends to be adequate, so confirmation is less critical for positive results."
    },
    {
      "id": "PMET-0402",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Z-Scores and Standard Scores",
      "passage_type": "paragraph",
      "original_passage": "A z-score (standard score) expresses a raw score in terms of how many standard deviations it falls above or below the mean. Z-scores allow comparison of scores from different distributions by converting them to a common scale",
      "modified_passage": "A z-score (standard score) expresses a raw score in terms of how many standard deviations it falls above or below the median. Z-scores allow comparison of scores from different distributions by converting them to a common scale.",
      "error_original": "median",
      "error_correct": "mean",
      "options": [
        "The passage incorrectly states 'standard score'; it should say 'scaled score'",
        "The passage incorrectly states 'median'; it should say 'mean'",
        "The passage incorrectly states 'standard deviations'; it should say 'standard errors'",
        "The passage incorrectly states 'different distributions'; it should say 'identical distributions'"
      ],
      "correct_option_index": 1,
      "explanation": "The passage incorrectly states that a z-score expresses how many standard deviations a raw score falls above or below the 'median.' In fact, z-scores are calculated relative to the mean of the distribution, not the median. The z-score formula is z = (X - M) / SD, where M is the mean. While the mean and median can coincide in a perfectly normal distribution, the defining reference point for a z-score is always the mean."
    },
    {
      "id": "PMET-0190",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "The Three-Term Contingency",
      "passage_type": "paragraph",
      "original_passage": "This framework is fundamental to functional behavior assessment and the development of behavior intervention plans in clinical and educational settings",
      "modified_passage": "The three-term contingency, also known as the ABD model (Antecedent-Behavior-Consequence), is the foundational unit of analysis in operant conditioning. The antecedent is the stimulus or event that precedes the behavior, the behavior is the observable response, and the consequence is the event that follows and either strengthens or weakens the behavior. This framework is fundamental to functional behavior assessment and the development of behavior intervention plans in clinical and educational settings.",
      "error_original": "ABD model",
      "error_correct": "ABC model",
      "options": [
        "The passage incorrectly states that the consequence 'strengthens or weakens' behavior; it should say 'strengthens or maintains' behavior",
        "The passage incorrectly states that the antecedent 'precedes' the behavior; it should say 'follows' the behavior",
        "The passage incorrectly states it is the 'ABD model'; it should say 'ABC model'",
        "The passage incorrectly states the three-term contingency is the foundational unit of 'operant conditioning'; it should say 'classical conditioning'"
      ],
      "correct_option_index": 2,
      "explanation": "The three-term contingency is commonly referred to as the ABC model, where A stands for Antecedent, B stands for Behavior, and C stands for Consequence. The passage incorrectly labels it the 'ABD model,' which is not a recognized term in behavior analysis. The correct abbreviation is ABC, directly corresponding to the three components described in the passage itself (Antecedent-Behavior-Consequence)."
    },
    {
      "id": "PMET-0163",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Contingency Management",
      "passage_type": "example",
      "original_passage": "Example: Voucher-Based Contingency Management In voucher-based contingency management for cocaine dependence, patients receive vouchers exchangeable for retail goods contingent on cocaine-negative urine specimens. Voucher values typically start low and increase with consecutive negative specimens, with a reset contingency for positive specimens. Meta-analyses demonstrate significant effects on drug abstinence outcomes",
      "modified_passage": "Example: Voucher-Based Contingency Management In voucher-based contingency management for cocaine dependence, patients receive vouchers exchangeable for retail goods contingent on cocaine-negative urine specimens. Voucher values typically start high and decrease with consecutive negative specimens, with a reset contingency for positive specimens. Meta-analyses demonstrate significant effects on drug abstinence outcomes",
      "error_original": "start high and decrease with consecutive negative specimens",
      "error_correct": "start low and increase with consecutive negative specimens",
      "options": [
        "The passage incorrectly states vouchers are exchangeable for retail goods; it should say they are exchangeable for cash",
        "The passage incorrectly states there is a reset contingency for positive specimens; it should say there is a reset contingency for negative specimens",
        "The passage incorrectly states voucher values start high and decrease with consecutive negative specimens; it should say they start low and increase with consecutive negative specimens",
        "The passage incorrectly states the intervention targets cocaine dependence; it should say it targets alcohol dependence"
      ],
      "correct_option_index": 2,
      "explanation": "The passage reverses the direction of the voucher escalation schedule. In voucher-based contingency management, voucher values typically start low and increase (escalate) with each consecutive cocaine-negative urine specimen. This escalating reinforcement schedule is a core feature of the approach, designed to incentivize sustained abstinence. The modified passage incorrectly states that values start high and decrease, which would actually reduce motivation for continued abstinence over time and contradicts the established protocol."
    },
    {
      "id": "PMET-0061",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Multiple Regression",
      "passage_type": "paragraph",
      "original_passage": "Multiple regression extends simple regression by using two or more predictor variables to predict a single criterion variable. The multiple regression equation is: Y' = a + b₁X₁ + b₂X₂ + ... + bₖXₖ",
      "modified_passage": "Multiple regression extends simple regression by using two or more predictor variables to predict a single criterion variable. The multiple regression equation is: Y' = a + b₁X₁ × b₂X₂ × ... × bₖXₖ",
      "error_original": "Y' = a + b₁X₁ × b₂X₂ × ... × bₖXₖ",
      "error_correct": "Y' = a + b₁X₁ + b₂X₂ + ... + bₖXₖ",
      "options": [
        "The passage incorrectly states that multiple regression uses two or more predictor variables; it should say three or more predictor variables",
        "The passage incorrectly states that the equation predicts a single criterion variable; it should say multiple criterion variables",
        "The passage incorrectly uses multiplication signs (×) between the weighted predictor terms; it should use addition signs (+)",
        "The passage incorrectly refers to 'a' as the constant; it should refer to it as the slope coefficient"
      ],
      "correct_option_index": 2,
      "explanation": "The multiple regression equation combines the weighted predictor terms additively, not multiplicatively. The correct equation is Y' = a + b₁X₁ + b₂X₂ + ... + bₖXₖ, where each predictor variable (X) is multiplied by its own regression coefficient (b), and these products are then summed together along with the intercept constant (a). The modified passage incorrectly changed the addition signs between the b₁X₁, b₂X₂, etc. terms to multiplication signs, which would represent an entirely different (and incorrect) mathematical model."
    },
    {
      "id": "PMET-0426",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "The Regression Equation",
      "passage_type": "paragraph",
      "original_passage": "b: The slope (regression coefficient) indicating the change in Y for each one-unit change in X",
      "modified_passage": "b: The slope (regression coefficient) indicating the change in X for each one-unit change in Y",
      "error_original": "the change in X for each one-unit change in Y",
      "error_correct": "the change in Y for each one-unit change in X",
      "options": [
        "The passage incorrectly refers to 'b' as the slope; it should be called the intercept",
        "The passage incorrectly states the change in X for each one-unit change in Y; it should say the change in Y for each one-unit change in X",
        "The passage incorrectly uses the term 'regression coefficient'; it should say 'correlation coefficient'",
        "The passage incorrectly implies a one-unit change; it should say a one-standard-deviation change"
      ],
      "correct_option_index": 1,
      "explanation": "The passage reverses the relationship between X and Y. In a standard regression equation, 'b' (the slope or regression coefficient) indicates how much the predicted value of Y changes for each one-unit increase in X, not the other way around. The correct statement is: 'b: The slope (regression coefficient) indicating the change in Y for each one-unit change in X.'"
    },
    {
      "id": "PMET-PC-0001",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Restriction of Range",
      "passage_type": "example",
      "source_passage_id": "PMET-0087",
      "sentences": [
        "A company uses a cognitive ability test to select employees, hiring only those who score above the 70th percentile.",
        "When validating the test against job performance, only selected employees (those with high scores) are available.",
        "The restricted range of test scores inflates the observed validity coefficient.",
        "Statistical corrections can estimate what the validity would be in the full applicant population."
      ],
      "target_sentence_index": 2,
      "original_sentence": "The restricted range of test scores reduces the observed validity coefficient.",
      "error_original": "inflates the observed validity coefficient",
      "error_correct": "reduces the observed validity coefficient",
      "explanation": "Restriction of range attenuates (reduces) the observed correlation between predictor and criterion scores, resulting in an underestimate of the true validity coefficient. The error reverses this well-established psychometric principle by stating that restriction of range 'inflates' the validity coefficient."
    },
    {
      "id": "PMET-PC-0002",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Acquisition",
      "passage_type": "example",
      "source_passage_id": "PMET-0004",
      "sentences": [
        "Clinical Example: Fear Acquisition A child is bitten by a dog (US) while at a park.",
        "The pain from the bite naturally produces fear (UR).",
        "The visual appearance of dogs (CS) was present just before and during the bite.",
        "After this single pairing (one-trial learning), the child now experiences fear (CR) when seeing any dog.",
        "The temporal relationship - seeing the dog immediately before and during the painful bite - exemplifies trace conditioning producing rapid fear acquisition."
      ],
      "target_sentence_index": 4,
      "original_sentence": "The temporal relationship - seeing the dog immediately before and during the painful bite - exemplifies delay conditioning producing rapid fear acquisition.",
      "error_original": "trace conditioning",
      "error_correct": "delay conditioning",
      "explanation": "The passage describes the CS (seeing the dog) being present 'immediately before and during' the US (the bite), meaning the CS overlaps with the US. This is the defining feature of delay conditioning, where the CS onset precedes the US and the CS remains present until the US occurs. Trace conditioning, by contrast, involves a temporal gap between the offset of the CS and the onset of the US. The error substitutes 'trace conditioning' for the correct term 'delay conditioning.'"
    },
    {
      "id": "PMET-PC-0003",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Introduction to Inferential Statistics",
      "passage_type": "definition",
      "source_passage_id": "PMET-0111",
      "sentences": [
        "Population: The entire group to which researchers wish to generalize findings.",
        "Sample: A subset of the population that is actually measured.",
        "Parameter: A characteristic of a population (e.g., population mean μ).",
        "Statistic: A characteristic of a population used to estimate parameters (e.g., sample mean M or x̄).",
        "Sampling Distribution: The theoretical distribution of a statistic across all possible samples of a given size."
      ],
      "target_sentence_index": 3,
      "original_sentence": "Statistic: A characteristic of a sample used to estimate parameters (e.g., sample mean M or x̄).",
      "error_original": "A characteristic of a population used to estimate parameters",
      "error_correct": "A characteristic of a sample used to estimate parameters",
      "explanation": "A statistic is a characteristic of a *sample*, not a population. A characteristic of a population is called a parameter. The error swaps 'sample' for 'population' in the definition of a statistic, making it incorrectly identical to the definition of a parameter."
    },
    {
      "id": "PMET-PC-0004",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Standard Error of Estimate",
      "passage_type": "definition",
      "source_passage_id": "PMET-0035",
      "sentences": [
        "Predictor Variable (X): The variable used to make predictions; also called the independent variable in regression.",
        "Criterion Variable (Y): The variable being predicted; also called the dependent variable in regression.",
        "Residual: The difference between the actual Y score and the predicted Y score (Y - Y').",
        "SEE: The standard variance of the residuals; indicates prediction accuracy."
      ],
      "target_sentence_index": 3,
      "original_sentence": "SEE: The standard deviation of the residuals; indicates prediction accuracy.",
      "error_original": "standard variance",
      "error_correct": "standard deviation",
      "explanation": "The Standard Error of Estimate (SEE) is defined as the standard deviation of the residuals, not the standard variance. Variance is the square of the standard deviation, so substituting 'variance' for 'deviation' is a subtle but clearly incorrect term substitution."
    },
    {
      "id": "PMET-PC-0005",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Coefficient of Determination (r²)",
      "passage_type": "example",
      "source_passage_id": "PMET-0039",
      "sentences": [
        "Example: Interpreting r² If the correlation between SAT scores and college GPA is r = .50, then r² = .25.",
        "This means that 25% of the variance in college GPA can be accounted for by SAT scores.",
        "Conversely, 75% of the variance in GPA is due to other factors not captured by SAT scores.",
        "This interpretation helps put correlation coefficients in theoretical perspective."
      ],
      "target_sentence_index": 3,
      "original_sentence": "This interpretation helps put correlation coefficients in practical perspective.",
      "error_original": "theoretical perspective",
      "error_correct": "practical perspective",
      "explanation": "The original passage states that interpreting r² helps put correlation coefficients in 'practical' perspective, emphasizing real-world applicability. The error substitutes 'theoretical' for 'practical,' which reverses the intended meaning. The coefficient of determination (r²) is specifically valued because it gives a concrete, practical understanding of how much variance is shared between two variables, making abstract correlation values more meaningful in applied contexts."
    },
    {
      "id": "PMET-PC-0006",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Incremental Validity",
      "passage_type": "example",
      "source_passage_id": "PMET-0041",
      "sentences": [
        "A researcher examines whether a new anxiety questionnaire adds predictive value for treatment outcomes beyond existing measures.",
        "A regression using only the BDI-II yields R² = .30.",
        "Adding the new anxiety measure increases R² to .38.",
        "The increment of .08 (8% additional variance explained) represents the convergent validity of the new measure.",
        "Statistical tests can determine whether this increment is significant."
      ],
      "target_sentence_index": 3,
      "original_sentence": "The increment of .08 (8% additional variance explained) represents the incremental validity of the new measure.",
      "error_original": "convergent validity",
      "error_correct": "incremental validity",
      "explanation": "The passage describes how a new measure adds predictive value beyond an existing measure, which is the definition of incremental validity — the degree to which a new predictor explains additional variance beyond what is already accounted for. Convergent validity refers to the degree to which two measures of the same construct correlate with each other, which is a different psychometric concept entirely."
    },
    {
      "id": "PMET-PC-0007",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Kurtosis",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0405",
      "sentences": [
        "Kurtosis describes the \"peakedness\" of a distribution and the heaviness of its tails.",
        "Leptokurtic distributions are more peaked with heavier tails than normal (positive kurtosis).",
        "Platykurtic distributions are flatter with lighter tails (negative kurtosis).",
        "Mesokurtic distributions have the same kurtosis as the normal distribution."
      ],
      "target_sentence_index": 2,
      "original_sentence": "Platykurtic distributions are flatter with lighter tails (negative kurtosis).",
      "error_original": "lighter tails",
      "error_correct": "lighter tails",
      "explanation": "This passage is too short to introduce a subtle error without it being immediately revealed by adjacent sentences. Let me re-evaluate."
    },
    {
      "id": "PMET-PC-0008",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Major Qualitative Traditions",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0286",
      "sentences": [
        "The case study approach involves in-depth examination of a single case or a small number of cases.",
        "A \"case\" can be an individual, a program, an organization, or an event.",
        "Case studies use multiple data sources (interviews, documents, observations) and are valuable for exploring complex phenomena in controlled laboratory contexts.",
        "They provide rich detail but have limited generalizability."
      ],
      "target_sentence_index": 2,
      "original_sentence": "Case studies use multiple data sources (interviews, documents, observations) and are valuable for exploring complex phenomena in real-world contexts.",
      "error_original": "controlled laboratory contexts",
      "error_correct": "real-world contexts",
      "explanation": "Case studies are specifically valued for exploring complex phenomena in real-world contexts (naturalistic settings), not controlled laboratory contexts. A hallmark of case study research is its ecological validity and its focus on understanding phenomena as they occur naturally, which is why they trade generalizability for rich, contextually embedded detail."
    },
    {
      "id": "PMET-PC-0009",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Types of Program Evaluation",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0290",
      "sentences": [
        "Process evaluation (also called implementation evaluation) monitors whether the program is being delivered as intended.",
        "It assesses implementation fidelity —the degree to which the program follows its designed protocol.",
        "Process evaluation answers: \"Is the program being carried out as planned?\"",
        "\"Are participants being reached?\"",
        "\"Are services being delivered correctly?\""
      ],
      "target_sentence_index": 0,
      "original_sentence": "Process evaluation (also called implementation evaluation) monitors whether the program is being delivered as intended.",
      "error_original": "also called implementation evaluation",
      "error_correct": "also called formative evaluation",
      "explanation": "Process evaluation is also commonly referred to as formative evaluation (or implementation evaluation). However, in this context the original passage correctly uses 'implementation evaluation' as the alternate name. The error here is actually a trick — let me re-examine. The original passage does say 'implementation evaluation,' which is correct. A subtle error would be to swap this alternate name."
    },
    {
      "id": "PMET-PC-0010",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Major Qualitative Traditions",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0284",
      "sentences": [
        "Phenomenology seeks to describe the essence of lived experience as perceived by participants.",
        "Researchers conduct in-depth interviews to understand how individuals experience a particular phenomenon (e.g., living with chronic pain, experiencing grief).",
        "The analyst identifies themes and structures that capture the core meaning of the experience.",
        "The researcher engages in bracketing (also called epoché)—setting aside personal preconceptions to focus on participants' objective experiences."
      ],
      "target_sentence_index": 3,
      "original_sentence": "The researcher engages in bracketing (also called epoché)—setting aside personal preconceptions to focus on participants' subjective experiences.",
      "error_original": "objective experiences",
      "error_correct": "subjective experiences",
      "explanation": "Phenomenology is fundamentally concerned with subjective experience—how individuals personally perceive and make meaning of phenomena. The passage incorrectly states 'objective experiences,' but bracketing (epoché) is performed precisely so the researcher can set aside their own assumptions and attend faithfully to participants' subjective experiences. Replacing 'subjective' with 'objective' contradicts a core tenet of phenomenological inquiry."
    },
    {
      "id": "PMET-PC-0011",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Incremental Validity",
      "passage_type": "example",
      "source_passage_id": "PMET-0090",
      "sentences": [
        "A clinician wants to know if a new personality measure adds predictive value for therapy outcome beyond established predictors (severity, chronicity, social support).",
        "Existing predictors account for 25% of outcome variance.",
        "Adding the personality measure increases this to 32%.",
        "The 7% increase (ΔR² = .07) represents the convergent validity of the new measure."
      ],
      "target_sentence_index": 3,
      "original_sentence": "The 7% increase (ΔR² = .07) represents the incremental validity of the new measure.",
      "error_original": "convergent validity",
      "error_correct": "incremental validity",
      "explanation": "The passage describes the additional variance accounted for by a new measure beyond existing predictors (ΔR²), which is the definition of incremental validity, not convergent validity. Convergent validity refers to the degree to which two measures that theoretically should be related are in fact related. The concept being illustrated here — whether a new predictor adds predictive value beyond what is already explained — is specifically incremental validity."
    },
    {
      "id": "PMET-PC-0012",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Controlling External Validity Threats",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0299",
      "sentences": [
        "Understanding the Distinction Random assignment controls internal validity threats by ensuring groups are equivalent.",
        "Random selection (from the population to the sample) controls external validity threats by ensuring the sample represents the population.",
        "Many students confuse these concepts on the EPPP.",
        "Random assignment creates representative samples; random selection creates equivalent groups."
      ],
      "target_sentence_index": 3,
      "original_sentence": "Random assignment creates equivalent groups; random selection creates representative samples.",
      "error_original": "Random assignment creates representative samples; random selection creates equivalent groups",
      "error_correct": "Random assignment creates equivalent groups; random selection creates representative samples",
      "explanation": "The final sentence reverses the functions of random assignment and random selection. Random assignment creates equivalent groups (controlling internal validity), while random selection creates representative samples (controlling external validity). The error swaps these two outcomes, which is a concept reversal."
    },
    {
      "id": "PMET-PC-0013",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Type II Error (False Negative)",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0115",
      "sentences": [
        "Clinical Implications In clinical contexts, the consequences of Type I and Type II errors differ.",
        "A Type I error in treatment research means concluding a treatment works when it doesn't (potentially exposing patients to ineffective treatments).",
        "A Type II error means missing a truly effective treatment (denying patients beneficial interventions).",
        "Researchers must consider these trade-offs when designing studies."
      ],
      "target_sentence_index": 1,
      "original_sentence": "A Type I error in treatment research means concluding a treatment works when it doesn't (potentially exposing patients to ineffective treatments).",
      "error_original": "A Type I error in treatment research means concluding a treatment works when it doesn't",
      "error_correct": "A Type I error in treatment research means concluding a treatment works when it doesn't",
      "explanation": "This passage has fewer than 4 meaningfully distinct factual claims to modify without the error being revealed by adjacent sentences. However, re-evaluating: the passage does contain 4 sentences."
    },
    {
      "id": "PMET-PC-0014",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "One-Sample t-Test",
      "passage_type": "example",
      "source_passage_id": "PMET-0119",
      "sentences": [
        "Example: Choosing a t-Test Scenario: A researcher measures anxiety before and after a relaxation intervention in the same 30 participants.",
        "Appropriate test: Paired samples t-test, because the same participants are measured twice (within-subjects design).",
        "Scenario: A researcher compares anxiety scores between 30 participants who received treatment and 30 different participants who received placebo.",
        "Appropriate test: Independent samples t-test, because different participants are in each group (within-subjects design)."
      ],
      "target_sentence_index": 3,
      "original_sentence": "Appropriate test: Independent samples t-test, because different participants are in each group (between-subjects design).",
      "error_original": "within-subjects design",
      "error_correct": "between-subjects design",
      "explanation": "An independent samples t-test is used when different participants are in each group, which constitutes a between-subjects design, not a within-subjects design. A within-subjects design involves the same participants being measured under multiple conditions, which would call for a paired samples t-test instead."
    },
    {
      "id": "PMET-PC-0015",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Types of Program Evaluation",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0291",
      "sentences": [
        "Outcome evaluation measures whether program goals and objectives were achieved.",
        "It examines the indirect, intended effects of the program on participants.",
        "For example, did a smoking cessation program lead to reduced smoking rates among participants?",
        "Outcome evaluations typically use pre-post designs or comparison groups."
      ],
      "target_sentence_index": 1,
      "original_sentence": "It examines the direct, intended effects of the program on participants.",
      "error_original": "indirect, intended effects",
      "error_correct": "direct, intended effects",
      "explanation": "Outcome evaluation specifically examines the direct, intended effects of a program on its participants. The word 'indirect' was substituted for 'direct,' which is a concept reversal error. Indirect effects would be more associated with impact evaluation, which looks at broader, longer-term, or unintended consequences of a program, rather than outcome evaluation which focuses on the direct results tied to program goals and objectives."
    },
    {
      "id": "PMET-PC-0016",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Avoidance Learning",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0158",
      "sentences": [
        "Two-factor theory provides a behavioral account of anxiety disorder maintenance.",
        "Avoidance prevents exposure to feared situations, thereby preventing extinction of conditioned fear.",
        "This explains why exposure therapy, which prevents avoidance and allows sensitization to occur, is effective for anxiety disorders.",
        "The theory also explains why reassurance-seeking and safety behaviors maintain anxiety."
      ],
      "target_sentence_index": 2,
      "original_sentence": "This explains why exposure therapy, which prevents avoidance and allows extinction to occur, is effective for anxiety disorders.",
      "error_original": "allows sensitization to occur",
      "error_correct": "allows extinction to occur",
      "explanation": "The error substitutes 'sensitization' for 'extinction.' Exposure therapy works by preventing avoidance responses so that the conditioned fear response can undergo extinction (i.e., the conditioned stimulus is presented without the unconditioned stimulus, weakening the association). Sensitization is the opposite process—it refers to an increased response to a stimulus with repeated exposure, which is not the therapeutic mechanism of exposure therapy."
    },
    {
      "id": "PMET-PC-0017",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Introduction to Classical Conditioning",
      "passage_type": "definition",
      "source_passage_id": "PMET-0001",
      "sentences": [
        "Unconditioned Stimulus (US): A stimulus that naturally and automatically triggers a response without prior learning (e.g., food causing salivation).",
        "Unconditioned Response (UR): The unlearned, naturally occurring response to the unconditioned stimulus (e.g., salivation to food).",
        "Conditioned Stimulus (CS): A previously neutral stimulus that, after association with the US, comes to trigger a conditioned response (e.g., bell after pairing with food).",
        "Conditioned Response (CR): The learned response to the unconditioned stimulus (e.g., salivation to the bell)."
      ],
      "target_sentence_index": 3,
      "original_sentence": "Conditioned Response (CR): The learned response to the conditioned stimulus (e.g., salivation to the bell).",
      "error_original": "the unconditioned stimulus",
      "error_correct": "the conditioned stimulus",
      "explanation": "The Conditioned Response (CR) is defined as the learned response to the conditioned stimulus (CS), not the unconditioned stimulus (US). The passage incorrectly substitutes 'unconditioned stimulus' for 'conditioned stimulus.' The response to the unconditioned stimulus is the Unconditioned Response (UR), not the CR."
    },
    {
      "id": "PMET-PC-0018",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Introduction to Research Validity",
      "passage_type": "definition",
      "source_passage_id": "PMET-0295",
      "sentences": [
        "Four Types of Research Validity.",
        "Internal Validity: Did the treatment (IV) actually cause the observed effect (DV)?",
        "External Validity: Can the findings be generalized to other people, settings, and times?",
        "Construct Validity: Are we measuring the constructs we think we're measuring?",
        "Statistical Conclusion Validity: Are our statistical assumptions justified?"
      ],
      "target_sentence_index": 4,
      "original_sentence": "Statistical Conclusion Validity: Are our statistical conclusions accurate?",
      "error_original": "statistical assumptions justified",
      "error_correct": "statistical conclusions accurate",
      "explanation": "Statistical Conclusion Validity concerns whether the statistical conclusions drawn from data are accurate (e.g., correct inferences about covariation between variables). The modified sentence incorrectly substitutes 'assumptions justified' for 'conclusions accurate,' which changes the core definition of this validity type. Justified assumptions relate more to meeting test prerequisites, not to the accuracy of statistical inferences."
    },
    {
      "id": "PMET-PC-0019",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Multiple Baseline Design",
      "passage_type": "example",
      "source_passage_id": "PMET-0251",
      "sentences": [
        "A therapist targets three problem behaviors in a child with autism: hand-flapping, echolalia, and tantrums.",
        "After establishing baselines for all three, she implements a token economy first for hand-flapping.",
        "Once reduction is observed, she extends the intervention to echolalia, then to tantrums.",
        "If each behavior decreases only when the intervention is applied to it, this demonstrates internal validity without requiring withdrawal."
      ],
      "target_sentence_index": 3,
      "original_sentence": "If each behavior decreases only when the intervention is applied to it, this demonstrates experimental control without requiring withdrawal.",
      "error_original": "internal validity",
      "error_correct": "experimental control",
      "explanation": "The passage originally states that the multiple baseline design demonstrates 'experimental control' without requiring withdrawal. The error substitutes 'internal validity' for 'experimental control.' While related concepts, the specific strength of the multiple baseline design is that it demonstrates experimental control (i.e., a functional relationship between the independent and dependent variables) without needing to withdraw treatment, which is the hallmark advantage of this design over reversal/withdrawal designs."
    },
    {
      "id": "PMET-PC-0020",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Components of Clinical Utility",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0085",
      "sentences": [
        "Evaluating Clinical Utility Questions to ask about a test's clinical utility:",
        "Does use of this test lead to different clinical decisions than would be made without it?",
        "Do those different decisions result in better patient outcomes?",
        "Is the test feasible to administer in typical research settings?",
        "Is the test acceptable to patients and clinicians?"
      ],
      "target_sentence_index": 3,
      "original_sentence": "Is the test feasible to administer in typical clinical settings?",
      "error_original": "typical research settings",
      "error_correct": "typical clinical settings",
      "explanation": "The original passage specifies 'clinical settings' as the context for evaluating feasibility of test administration. Clinical utility specifically concerns the practical value of a test in real-world clinical practice, not research settings. Substituting 'research' for 'clinical' subtly changes the meaning, as feasibility in research environments (which may have more resources and fewer time constraints) is a different consideration than feasibility in everyday clinical practice."
    },
    {
      "id": "PMET-PC-0021",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Meta-Analysis",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0072",
      "sentences": [
        "A forest plot is the standard graphical display of meta-analytic results.",
        "Each study is represented by a horizontal line (confidence interval) with a square at the point estimate (the square's size reflects the study's weight).",
        "The overall combined estimate is displayed as a diamond at the top.",
        "Forest plots allow readers to visually assess the consistency and direction of effects across studies."
      ],
      "target_sentence_index": 2,
      "original_sentence": "The overall combined estimate is displayed as a diamond at the bottom.",
      "error_original": "at the top",
      "error_correct": "at the bottom",
      "explanation": "In a standard forest plot, the overall combined (summary) estimate is displayed as a diamond at the bottom of the plot, not at the top. Individual study estimates are listed above it, and the diamond representing the pooled effect size appears at the bottom after all individual studies."
    },
    {
      "id": "PMET-PC-0022",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Restriction of Range",
      "passage_type": "example",
      "source_passage_id": "PMET-0040",
      "sentences": [
        "A company uses a cognitive ability test to select employees, hiring only those who score above the 75th percentile.",
        "When later examining the correlation between test scores and job performance among hired employees, they find a modest correlation of r = .20.",
        "However, if they could have studied all applicants (unrestricted range), the correlation might be r = .50.",
        "The selection process restricted the range of test scores, inflating the observed validity coefficient."
      ],
      "target_sentence_index": 3,
      "original_sentence": "The selection process restricted the range of test scores, attenuating the observed validity coefficient.",
      "error_original": "inflating the observed validity coefficient",
      "error_correct": "attenuating the observed validity coefficient",
      "explanation": "Restriction of range attenuates (reduces) the observed correlation, not inflates it. In the example, the unrestricted correlation would be r = .50, but due to range restriction the observed correlation dropped to r = .20. This demonstrates that restriction of range leads to an underestimate of the true relationship between variables."
    },
    {
      "id": "PMET-PC-0023",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Major Qualitative Traditions",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0283",
      "sentences": [
        "Grounded theory aims to generate theory from data rather than testing pre-existing hypotheses.",
        "Researchers collect data (typically through interviews and observations), code it systematically, and develop theoretical concepts that are \"grounded\" in the data.",
        "The process involves open coding (identifying initial categories), axial coding (relating categories), and selective coding (integrating into a coherent theory).",
        "Data collection and analysis occur simultaneously, and theoretical sampling guides recruitment—new participants are selected to refine emerging theory (Glaser & Corbin, 1967)."
      ],
      "target_sentence_index": 3,
      "original_sentence": "Data collection and analysis occur simultaneously, and theoretical sampling guides recruitment—new participants are selected to refine emerging theory (Glaser & Strauss, 1967).",
      "error_original": "Glaser & Corbin, 1967",
      "error_correct": "Glaser & Strauss, 1967",
      "explanation": "The seminal work on grounded theory was authored by Barney Glaser and Anselm Strauss in 1967 ('The Discovery of Grounded Theory'). The error substitutes 'Corbin' for 'Strauss.' Juliet Corbin was a later collaborator of Strauss, but the original 1967 foundational text was by Glaser and Strauss."
    },
    {
      "id": "PMET-PC-0024",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Internal vs. External Validity Trade-offs",
      "passage_type": "definition",
      "source_passage_id": "PMET-0297",
      "sentences": [
        "The Trade-off High Control (Lab): Strong internal validity, weaker external validity.",
        "We know the treatment works in controlled conditions but may not generalize to the real world.",
        "Naturalistic Settings (Field): Stronger external validity, weaker internal validity.",
        "Results generalize better, but we're less certain the treatment caused the effects."
      ],
      "target_sentence_index": 0,
      "original_sentence": "The Trade-off High Control (Lab): Strong internal validity, weaker external validity.",
      "error_original": "weaker external validity",
      "error_correct": "weaker external validity",
      "explanation": "This passage actually contains no error in sentence 0 — let me re-do this properly."
    },
    {
      "id": "PMET-PC-0025",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Threats to Internal Validity",
      "passage_type": "definition",
      "source_passage_id": "PMET-0296",
      "sentences": [
        "Diffusion of Treatment occurs when control group participants learn about or receive aspects of the treatment.",
        "Compensatory Equalization occurs when administrators provide extra services to the control group to compensate for not receiving treatment.",
        "Compensatory Rivalry occurs when control group participants work harder to compete with the treatment group, also known as the Hawthorne effect.",
        "Resentful Demoralization occurs when control group participants become demoralized and perform worse than they otherwise would."
      ],
      "target_sentence_index": 2,
      "original_sentence": "Compensatory Rivalry occurs when control group participants work harder to compete with the treatment group, also known as the John Henry effect.",
      "error_original": "Hawthorne effect",
      "error_correct": "John Henry effect",
      "explanation": "Compensatory Rivalry is also known as the John Henry effect, named after the folk legend of a steel driver who worked harder to compete against a machine. The Hawthorne effect refers to a different phenomenon where participants modify their behavior simply because they know they are being observed, not because they are competing with another group."
    },
    {
      "id": "PMET-PC-0026",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Threats to Internal Validity",
      "passage_type": "example",
      "source_passage_id": "PMET-0300",
      "sentences": [
        "A researcher studies the effect of a new anxiety treatment over 8 weeks.",
        "During the study, a major national crisis occurs, elevating anxiety in the population.",
        "Any observed changes in anxiety might be due to the treatment, the crisis, or both.",
        "The external event (crisis) is a maturation threat."
      ],
      "target_sentence_index": 3,
      "original_sentence": "The external event (crisis) is a history threat.",
      "error_original": "maturation threat",
      "error_correct": "history threat",
      "explanation": "The passage describes an external event (a national crisis) occurring during the study that could affect the dependent variable. This is a 'history threat' to internal validity — an outside event coinciding with the study that provides an alternative explanation for results. A 'maturation threat' refers to internal changes within participants over time (e.g., growing older, becoming fatigued), not external events."
    },
    {
      "id": "PMET-PC-0027",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Applications of IRT",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0208",
      "sentences": [
        "The EPPP itself uses IRT-based scoring.",
        "Items are calibrated using IRT models, and examinee scores are estimated on a theta scale.",
        "This means the EPPP can draw from a large item bank while maintaining score comparability across administrations.",
        "The pass/fail decision is based on a theta cutoff rather than a raw percentage correct, which accounts for differences in item discrimination across test forms."
      ],
      "target_sentence_index": 3,
      "original_sentence": "The pass/fail decision is based on a theta cutoff rather than a raw percentage correct, which accounts for differences in item difficulty across test forms.",
      "error_original": "item discrimination",
      "error_correct": "item difficulty",
      "explanation": "The original passage states that the theta cutoff accounts for differences in 'item difficulty' across test forms. The error substitutes 'item discrimination' for 'item difficulty.' While item discrimination is an important IRT parameter, the primary reason for using a theta cutoff rather than a raw percentage correct across different test forms is to account for variations in item difficulty, ensuring that examinees taking forms with harder or easier items are evaluated fairly."
    },
    {
      "id": "PMET-PC-0028",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Introduction to Correlation",
      "passage_type": "definition",
      "source_passage_id": "PMET-0033",
      "sentences": [
        "A correlation coefficient is a numerical index ranging from -1.00 to +1.00 that indicates the strength and direction of the linear relationship between two variables.",
        "A positive correlation means that as one variable increases, the other tends to increase (e.g., height and weight).",
        "A negative correlation means that as one variable increases, the other tends to increase as well (e.g., stress and immune function).",
        "A zero correlation indicates that no systematic linear relationship exists between the variables."
      ],
      "target_sentence_index": 2,
      "original_sentence": "A negative correlation means that as one variable increases, the other tends to decrease (e.g., stress and immune function).",
      "error_original": "the other tends to increase as well",
      "error_correct": "the other tends to decrease",
      "explanation": "A negative correlation indicates an inverse relationship between two variables: as one variable increases, the other tends to decrease. The error reverses this direction by stating the other variable 'tends to increase as well,' which would describe a positive correlation, not a negative one."
    },
    {
      "id": "PMET-PC-0029",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Introduction to Operant Conditioning",
      "passage_type": "definition",
      "source_passage_id": "PMET-0154",
      "sentences": [
        "Operant Behavior: Voluntary behavior that operates on the environment to produce consequences.",
        "Reinforcement: Any consequence that increases the probability of a behavior occurring again.",
        "Punishment: Any consequence that increases the probability of a behavior occurring again.",
        "Contingency: The relationship between a behavior and its consequence."
      ],
      "target_sentence_index": 2,
      "original_sentence": "Punishment: Any consequence that decreases the probability of a behavior occurring again.",
      "error_original": "increases the probability",
      "error_correct": "decreases the probability",
      "explanation": "Punishment is defined as any consequence that decreases (not increases) the probability of a behavior occurring again. The error swaps 'decreases' with 'increases,' making the definition of punishment identical to that of reinforcement, which is incorrect."
    },
    {
      "id": "PMET-PC-0030",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "The Four Basic Schedules",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0179",
      "sentences": [
        "Reinforcement is delivered after a fixed number of responses.",
        "For example, FR-5 means reinforcement occurs after every 5 responses.",
        "FR schedules produce high, steady response rates with a brief pause before reinforcement (pre-reinforcement pause).",
        "Piecework pay is a real-world example."
      ],
      "target_sentence_index": 2,
      "original_sentence": "FR schedules produce high, steady response rates with a brief pause after reinforcement (post-reinforcement pause).",
      "error_original": "a brief pause before reinforcement (pre-reinforcement pause)",
      "error_correct": "a brief pause after reinforcement (post-reinforcement pause)",
      "explanation": "In fixed-ratio (FR) schedules, the characteristic pause occurs immediately after reinforcement is delivered, not before it. This is known as the post-reinforcement pause (PRP). The organism pauses briefly after receiving the reinforcer before resuming responding at a high rate to meet the next ratio requirement."
    },
    {
      "id": "PMET-PC-0031",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Multivariate Analysis of Variance (MANOVA)",
      "passage_type": "example",
      "source_passage_id": "PMET-0121",
      "sentences": [
        "A researcher compares two therapy groups on three outcome measures simultaneously: depression, anxiety, and quality of life.",
        "Running three separate ANOVAs would inflate the Type II error rate (approximately 1 - .95^3 = .14 rather than .05).",
        "MANOVA tests all three DVs in one analysis, maintaining the overall alpha at .05.",
        "The researcher reports Wilks' Lambda and, if significant, conducts follow-up analyses to determine which DVs contribute to the group difference."
      ],
      "target_sentence_index": 1,
      "original_sentence": "Running three separate ANOVAs would inflate the Type I error rate (approximately 1 - .95^3 = .14 rather than .05).",
      "error_original": "Type II error rate",
      "error_correct": "Type I error rate",
      "explanation": "The error substitutes 'Type II' for 'Type I.' Running multiple separate ANOVAs inflates the Type I error rate (the probability of falsely rejecting a true null hypothesis), not the Type II error rate. This is the primary rationale for using MANOVA—to control the familywise Type I error rate when testing multiple dependent variables."
    },
    {
      "id": "PMET-PC-0032",
      "mode": "passage_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Specificity",
      "passage_type": "example",
      "source_passage_id": "PMET-0089",
      "sentences": [
        "A depression screening test is administered to 1,000 patients.",
        "Of 200 who actually have depression, 180 test positive (sensitivity = 180/200 = 90%).",
        "Of 800 without depression, 720 test negative (specificity = 720/800 = 90%).",
        "The test correctly identifies 90% of depressed patients and 90% of non-depressed patients."
      ],
      "target_sentence_index": 1,
      "original_sentence": "Of 200 who actually have depression, 180 test positive (sensitivity = 180/200 = 90%).",
      "error_original": "180 test positive (sensitivity = 180/200 = 90%)",
      "error_correct": "180 test positive (sensitivity = 180/200 = 90%) — this is correct; however, see the actual error below",
      "explanation": "Placeholder — see corrected version below."
    },
    {
      "id": "PMET-SC-0001",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Internal Consistency Reliability",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0228",
      "modified_sentence": "Because each half is only half as long as the full test, the Kuder-Richardson formula is used to estimate the reliability of the full-length test.",
      "phrases": [
        "Because each half is only half as long as the full test,",
        " the Kuder-Richardson formula is used",
        " to estimate the reliability",
        " of the full-length test."
      ],
      "target_phrase_index": 1,
      "error_original": "the Kuder-Richardson formula is used",
      "error_correct": "the Spearman-Brown formula is used",
      "explanation": "The Spearman-Brown formula (also called the Spearman-Brown prophecy formula) is used to correct the split-half correlation to estimate the reliability of the full-length test. The Kuder-Richardson formulas (KR-20 and KR-21) are different internal consistency measures used specifically for dichotomous items. Confusing these two is a common error, as both relate to internal consistency reliability, but they serve distinct purposes."
    },
    {
      "id": "PMET-SC-0002",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Threats to Construct Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0581",
      "modified_sentence": "Two major threats to construct validity are construct underrepresentation, which occurs when a test is too broad and fails to capture important dimensions of the construct, and construct-irrelevant variance, which occurs when test scores are systematically influenced by factors unrelated to the construct being measured.",
      "phrases": [
        "Two major threats to construct validity are construct underrepresentation,",
        " which occurs when a test is too broad and fails to capture important dimensions of the construct,",
        " and construct-irrelevant variance, which occurs when test scores are systematically influenced",
        " by factors unrelated to the construct being measured."
      ],
      "target_phrase_index": 1,
      "error_original": "too broad",
      "error_correct": "too narrow",
      "explanation": "Construct underrepresentation occurs when a test is too NARROW, meaning it fails to include items that adequately sample the full breadth of the construct. Saying the test is 'too broad' incorrectly describes the opposite problem. A test that is too broad would more likely introduce construct-irrelevant variance. Construct underrepresentation specifically refers to insufficient coverage of the construct's important facets or dimensions."
    },
    {
      "id": "PMET-SC-0003",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0470",
      "modified_sentence": "Statistical power can be increased by using a larger sample size, a larger effect size, a higher alpha level, higher variability in scores, or by using a one-tailed test.",
      "phrases": [
        "Statistical power can be increased by using a larger sample size,",
        " a larger effect size, a higher alpha level,",
        " higher variability in scores,",
        " or by using a one-tailed test."
      ],
      "target_phrase_index": 2,
      "error_original": "higher variability in scores",
      "error_correct": "lower variability in scores",
      "explanation": "Statistical power is increased by lower variability (not higher variability) in scores. When variability is reduced, the standard error decreases, making it easier to detect a true effect. The original passage correctly lists 'lower variability' as one of the factors that increases power."
    },
    {
      "id": "PMET-SC-0004",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Threats to External Validity",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0298",
      "modified_sentence": "If a treatment was validated primarily on white, middle-class college students, its efficacy with diverse clinical populations should be evaluated carefully.",
      "phrases": [
        "If a treatment was validated primarily",
        " on white, middle-class college students,",
        " its efficacy with diverse clinical populations",
        " should be evaluated carefully."
      ],
      "target_phrase_index": 2,
      "error_original": "its efficacy with diverse clinical populations",
      "error_correct": "its effectiveness with diverse clinical populations",
      "explanation": "The original passage uses the term 'effectiveness,' which in evidence-based practice terminology refers to how well a treatment works in real-world clinical settings and diverse populations. 'Efficacy' refers to how well a treatment works under controlled, ideal research conditions (i.e., internal validity). The distinction is important: the passage is discussing external validity and generalizability to real-world clients, which is a question of effectiveness, not efficacy."
    },
    {
      "id": "PMET-SC-0005",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Positive and Negative Predictive Value",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0083",
      "modified_sentence": "When the base rate of a condition is low, the positive predictive value decreases substantially because most positive results are false positives, while the negative predictive value also decreases because most negatives are false negatives.",
      "phrases": [
        "When the base rate of a condition is low,",
        " the positive predictive value decreases substantially because most positive results are false positives,",
        " while the negative predictive value also decreases",
        " because most negatives are false negatives."
      ],
      "target_phrase_index": 2,
      "error_original": "the negative predictive value also decreases",
      "error_correct": "the negative predictive value remains high",
      "explanation": "When base rate is low, PPV is low (most positives are false positives), but NPV is actually high, not low. NPV decreases when the base rate is high, not when it is low. The passage itself states that NPV is low when base rate is high. The error here reverses the relationship between base rate and NPV for low-prevalence conditions."
    },
    {
      "id": "PMET-SC-0006",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Extinction and Spontaneous Recovery",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0412",
      "modified_sentence": "Reinstatement occurs when the conditioned response reappears after the extinguished organism is exposed to unpaired presentations of the conditioned stimulus, and it demonstrates that extinction does not erase the original CS-US association.",
      "phrases": [
        "Reinstatement occurs when the conditioned response reappears",
        " after the extinguished organism is exposed to unpaired presentations of the conditioned stimulus,",
        " and it demonstrates that extinction does not erase",
        " the original CS-US association."
      ],
      "target_phrase_index": 1,
      "error_original": "unpaired presentations of the conditioned stimulus",
      "error_correct": "unpaired presentations of the unconditioned stimulus",
      "explanation": "Reinstatement occurs when the CR returns after the organism receives unpaired presentations of the unconditioned stimulus (US), not the conditioned stimulus (CS), following extinction. Exposure to the US alone can reinstate the previously extinguished conditioned response, demonstrating that extinction does not fully eliminate the learned association."
    },
    {
      "id": "PMET-SC-0007",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Extinction and Spontaneous Recovery",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0411",
      "modified_sentence": "Renewal refers to the return of the conditioned response when the organism is tested in a context different from the extinction context, demonstrating that extinction involves new excitatory associations rather than erasing the original CS-US learning.",
      "phrases": [
        "Renewal refers to the return of the conditioned response",
        " when the organism is tested in a context different from the extinction context,",
        " demonstrating that extinction involves new excitatory associations",
        " rather than erasing the original CS-US learning."
      ],
      "target_phrase_index": 2,
      "error_original": "new excitatory associations",
      "error_correct": "new inhibitory associations",
      "explanation": "Extinction does not erase the original conditioned response but instead involves the formation of new inhibitory associations that suppress the CR. The fact that renewal occurs (the CR returns in a different context) supports this interpretation. Calling them 'excitatory' associations is incorrect; extinction learning is inhibitory in nature, as demonstrated by phenomena like renewal, spontaneous recovery, and reinstatement."
    },
    {
      "id": "PMET-SC-0008",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "The Four Basic Schedules",
      "passage_type": "definition",
      "source_passage_id": "PMET-0155",
      "modified_sentence": "Variable schedules produce more consistent responding and greater resistance to extinction than fixed schedules, and variable interval (VI) produces the highest response rate and greatest resistance to extinction.",
      "phrases": [
        "Variable schedules produce more consistent responding",
        " and greater resistance to extinction than fixed schedules,",
        " and variable interval (VI) produces the highest response rate",
        " and greatest resistance to extinction."
      ],
      "target_phrase_index": 2,
      "error_original": "variable interval (VI) produces the highest response rate",
      "error_correct": "variable ratio (VR) produces the highest response rate",
      "explanation": "The passage states that the variable ratio (VR) schedule produces the highest response rate and greatest resistance to extinction. Variable interval (VI) is a different schedule that, while resistant to extinction, does not produce the highest response rate. VR schedules are well-known for generating the highest and most steady rates of responding among all four basic reinforcement schedules."
    },
    {
      "id": "PMET-SC-0009",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Type I Error (False Positive)",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0130",
      "modified_sentence": "A Type I error occurs when we reject the null hypothesis when it is actually true, and is also called a \"false positive\" or \"beta error,\" with its probability equal to the significance level (α).",
      "phrases": [
        "A Type I error occurs when we reject the null hypothesis when it is actually true,",
        " and is also called a \"false positive\" or \"beta error,\"",
        " with its probability equal to",
        " the significance level (α)."
      ],
      "target_phrase_index": 1,
      "error_original": "\"beta error,\"",
      "error_correct": "\"alpha error,\"",
      "explanation": "A Type I error is also known as an 'alpha error,' not a 'beta error.' The term 'beta error' refers to a Type II error (false negative), where beta (β) represents the probability of failing to reject a false null hypothesis. Since the Type I error rate is set by alpha (α), it is correctly termed an 'alpha error.'"
    },
    {
      "id": "PMET-SC-0010",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0489",
      "modified_sentence": "Negative reinforcement is commonly confused with punishment, but it actually increases the frequency of a behavior by involving the removal of a discriminative stimulus following the desired response.",
      "phrases": [
        "Negative reinforcement is commonly confused with punishment,",
        " but it actually increases the frequency of a behavior",
        " by involving the removal of a discriminative stimulus",
        " following the desired response."
      ],
      "target_phrase_index": 2,
      "error_original": "removal of a discriminative stimulus",
      "error_correct": "removal of an aversive stimulus",
      "explanation": "Negative reinforcement involves the removal of an aversive (unpleasant) stimulus contingent on a behavior, thereby increasing the likelihood of that behavior. A discriminative stimulus (SD) is a stimulus that signals the availability of reinforcement and sets the occasion for a response — it is not what is removed in negative reinforcement. The passage specifically states that negative reinforcement increases behavior through stimulus removal, referring to the removal of something unpleasant (aversive), not a discriminative stimulus."
    },
    {
      "id": "PMET-SC-0011",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0574",
      "modified_sentence": "According to Messick's unified validity framework, construct underrepresentation occurs when a test is too narrow and fails to capture important dimensions of the construct, while construct-irrelevant variance occurs when a test systematically undersamples the content domain that is extraneous to the target construct.",
      "phrases": [
        "According to Messick's unified validity framework,",
        " construct underrepresentation occurs when a test is too narrow and fails to capture important dimensions of the construct,",
        " while construct-irrelevant variance occurs when a test systematically undersamples the content domain",
        " that is extraneous to the target construct."
      ],
      "target_phrase_index": 2,
      "error_original": "systematically undersamples the content domain",
      "error_correct": "systematically measures unintended factors",
      "explanation": "Construct-irrelevant variance occurs when a test measures unintended factors extraneous to the construct, inflating or contaminating scores with irrelevant sources of variance. 'Undersampling the content domain' actually describes construct underrepresentation, the other major threat to construct validity identified in Messick's framework. The two threats are conceptual opposites: underrepresentation means the test is too narrow, while construct-irrelevant variance means the test is too broad, capturing things it shouldn't."
    },
    {
      "id": "PMET-SC-0012",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Threats to Construct Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0328",
      "modified_sentence": "When the operationalization of one construct is confounded with another construct, a treatment that includes both behavioral activation and relaxation training confounds these two components, making it impossible to determine which component is responsible for the observed treatment effects.",
      "phrases": [
        "When the operationalization of one construct is confounded with another construct,",
        " a treatment that includes both behavioral activation and relaxation training confounds these two components,",
        " making it impossible to determine which component",
        " is responsible for the observed treatment effects."
      ],
      "target_phrase_index": 1,
      "error_original": "behavioral activation",
      "error_correct": "cognitive restructuring",
      "explanation": "The original passage specifies that the example of construct confounding involves a treatment that includes both cognitive restructuring and relaxation training. 'Behavioral activation' is a different therapeutic technique (commonly associated with behavioral treatments for depression) and was incorrectly substituted for 'cognitive restructuring' in this example of a threat to construct validity."
    },
    {
      "id": "PMET-SC-0013",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-validity.html",
      "chapter_title": "Threats & Safeguards: Research Validity",
      "section": "Threats to Construct Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0326",
      "modified_sentence": "Demand characteristics are a threat to construct validity that lead participants to behave as they think the researcher expects, and they were first described by Martin Seligman in his research on the social psychology of experiments.",
      "phrases": [
        "Demand characteristics are a threat to construct validity",
        " that lead participants to behave as they think the researcher expects,",
        " and they were first described by Martin Seligman",
        " in his research on the social psychology of experiments."
      ],
      "target_phrase_index": 2,
      "error_original": "Martin Seligman",
      "error_correct": "Martin Orne",
      "explanation": "Demand characteristics were first described by Martin Orne, not Martin Seligman. Orne introduced the concept in his influential work on the social psychology of psychological experiments, highlighting how participants pick up on cues about what the experimenter expects and alter their behavior accordingly. Martin Seligman is known for learned helplessness and positive psychology, not for the concept of demand characteristics."
    },
    {
      "id": "PMET-SC-0014",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Reinforcement",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0168",
      "modified_sentence": "Reinforcement is the process by which consequences increase the likelihood that a behavior will occur again, and understanding the distinction between positive and negative punishment is critical for EPPP preparation, as this is a commonly tested area where confusion often arises.",
      "phrases": [
        "Reinforcement is the process by which consequences increase the likelihood that a behavior will occur again,",
        " and understanding the distinction between positive and negative punishment is critical for EPPP preparation,",
        " as this is a commonly tested area",
        " where confusion often arises."
      ],
      "target_phrase_index": 1,
      "error_original": "positive and negative punishment",
      "error_correct": "positive and negative reinforcement",
      "explanation": "The passage is specifically about reinforcement, not punishment. The distinction being discussed is between positive and negative reinforcement — both of which increase the likelihood of a behavior. Punishment, by contrast, decreases the likelihood of a behavior. Substituting 'punishment' for 'reinforcement' changes the concept entirely and is inconsistent with the topic of the passage."
    },
    {
      "id": "PMET-SC-0015",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0432",
      "modified_sentence": "A correlation coefficient describes the strength and direction of the curvilinear relationship between two variables, but it cannot establish causation because the relationship may be explained by a confounding third variable.",
      "phrases": [
        "A correlation coefficient describes",
        " the strength and direction of the curvilinear relationship between two variables,",
        " but it cannot establish causation",
        " because the relationship may be explained by a confounding third variable."
      ],
      "target_phrase_index": 1,
      "error_original": "curvilinear relationship",
      "error_correct": "linear relationship",
      "explanation": "A standard correlation coefficient (Pearson's r) specifically measures the strength and direction of the linear relationship between two variables, not a curvilinear relationship. In fact, a Pearson's r of zero could still reflect a strong curvilinear association. Special methods such as eta (η) or polynomial regression are needed to capture curvilinear relationships."
    },
    {
      "id": "PMET-SC-0016",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Survey Research",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0272",
      "modified_sentence": "Survey research uses questionnaires or interviews to collect data from a sample, typically to describe characteristics of a population or examine causal effects between variables, and representative sampling is critical for generalizing survey results to the population of interest.",
      "phrases": [
        "Survey research uses questionnaires or interviews to collect data from a sample,",
        " typically to describe characteristics of a population or examine causal effects between variables,",
        " and representative sampling is critical",
        " for generalizing survey results to the population of interest."
      ],
      "target_phrase_index": 1,
      "error_original": "examine causal effects between variables",
      "error_correct": "examine relationships between variables",
      "explanation": "Survey research is a non-experimental (descriptive/correlational) method and is used to examine relationships between variables, not causal effects. Establishing causal effects requires experimental designs with manipulation of independent variables and random assignment. Survey research can identify associations and correlations but cannot determine causation."
    },
    {
      "id": "PMET-SC-0017",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "The Three-Term Contingency",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0189",
      "modified_sentence": "The three-term contingency, also known as the ABC model, was a foundational concept in Edward Thorndike's operant conditioning framework, where A refers to the antecedent discriminative stimulus, B refers to the behavior, and C refers to the consequence that follows.",
      "phrases": [
        "The three-term contingency, also known as the ABC model,",
        " was a foundational concept in Edward Thorndike's operant conditioning framework,",
        " where A refers to the antecedent discriminative stimulus, B refers to the behavior,",
        " and C refers to the consequence that follows."
      ],
      "target_phrase_index": 1,
      "error_original": "Edward Thorndike's operant conditioning framework",
      "error_correct": "B.F. Skinner's operant conditioning framework",
      "explanation": "The three-term contingency (ABC model) is a foundational concept in B.F. Skinner's operant conditioning framework, not Edward Thorndike's. While Thorndike contributed the Law of Effect and instrumental learning concepts, it was Skinner who formalized the three-term contingency as the core analytical unit of operant behavior, describing how antecedent stimuli, behavior, and consequences are functionally related."
    },
    {
      "id": "PMET-SC-0018",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Introduction to Classical Conditioning",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0008",
      "modified_sentence": "Classical conditioning underlies many emotional responses, phobias, and physiological reactions, and understanding these mechanisms is essential for psychologists because they form the theoretical foundation for flooding, systematic desensitization, and other evidence-based interventions for anxiety disorders.",
      "phrases": [
        "Classical conditioning underlies many emotional responses, phobias, and physiological reactions,",
        " and understanding these mechanisms is essential for psychologists",
        " because they form the theoretical foundation for flooding, systematic desensitization,",
        " and other evidence-based interventions for anxiety disorders."
      ],
      "target_phrase_index": 2,
      "error_original": "flooding, systematic desensitization,",
      "error_correct": "exposure-based treatments, systematic desensitization,",
      "explanation": "The original passage states that classical conditioning forms the theoretical foundation for 'exposure-based treatments,' not 'flooding.' While flooding is indeed an exposure-based technique rooted in classical conditioning principles, the passage specifically uses the broader term 'exposure-based treatments' as the category. Replacing it with 'flooding' narrows the claim incorrectly and misrepresents the original text, which intended to reference the full range of exposure-based treatments rather than one specific technique."
    },
    {
      "id": "PMET-SC-0019",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Higher-Order Conditioning",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0017",
      "modified_sentence": "Higher-order conditioning is generally weaker than first-order conditioning and is susceptible to extinction, but it provides a mechanism for explaining how complex associative networks develop and how fears can generalize to stimuli never directly associated with trauma (Gewirtz & Davis, 2000).",
      "phrases": [
        "Higher-order conditioning is generally weaker than first-order conditioning",
        " and is susceptible to extinction, but it provides a mechanism",
        " for explaining how complex associative networks develop and how fears can generalize to stimuli",
        " never directly associated with trauma (Gewirtz & Davis, 2000)."
      ],
      "target_phrase_index": 2,
      "error_original": "how fears can generalize to stimuli",
      "error_correct": "how fears can spread to stimuli",
      "explanation": "The original passage states that higher-order conditioning explains how fears can 'spread' to stimuli never directly associated with trauma. The error replaces 'spread' with 'generalize,' which is a different learning concept. Generalization refers to responding to stimuli similar to the conditioned stimulus, whereas spreading via higher-order conditioning refers to fears extending to stimuli that were associated with the CS but never paired with the US (trauma) itself."
    },
    {
      "id": "PMET-SC-0020",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Coefficient of Alienation",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0052",
      "modified_sentence": "The coefficient of alienation represents the proportion of variance that is NOT shared between two variables, and it is calculated as 1 - r², which indicates the proportion of unexplained variance remaining after the correlation is accounted for.",
      "phrases": [
        "The coefficient of alienation represents the proportion of variance that is NOT shared between two variables,",
        " and it is calculated as 1 - r²,",
        " which indicates the proportion of unexplained variance remaining",
        " after the correlation is accounted for."
      ],
      "target_phrase_index": 1,
      "error_original": "it is calculated as 1 - r²",
      "error_correct": "it is calculated as 1 - r² only when referring to the coefficient of nondetermination; the coefficient of alienation itself is calculated as the square root of 1 - r², i.e., √(1 - r²)",
      "explanation": "The coefficient of alienation is actually calculated as √(1 - r²), not 1 - r². The value 1 - r² is the coefficient of nondetermination (also called the coefficient of non-determination), which represents the proportion of unexplained variance. The coefficient of alienation is the square root of that value. This is a commonly confused distinction in psychometrics."
    },
    {
      "id": "PMET-SC-0021",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Chi-Square Tests",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0464",
      "modified_sentence": "The chi-square test of independence tests whether two categorical variables are related, and it analyzes data organized in a correlation matrix to determine if the observed frequencies differ significantly from expected frequencies.",
      "phrases": [
        "The chi-square test of independence tests whether two categorical variables are related,",
        " and it analyzes data organized in a correlation matrix",
        " to determine if the observed frequencies",
        " differ significantly from expected frequencies."
      ],
      "target_phrase_index": 1,
      "error_original": "a correlation matrix",
      "error_correct": "a contingency table",
      "explanation": "The chi-square test of independence uses a contingency table (also called a cross-tabulation table), not a correlation matrix. A contingency table displays the frequency distribution of categorical variables, while a correlation matrix displays correlation coefficients between continuous variables. The passage explicitly states that the chi-square test of independence uses a contingency table."
    },
    {
      "id": "PMET-SC-0022",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0441",
      "modified_sentence": "Predictive validity is a type of criterion-related validity in which the criterion is measured at the same time as the predictor, and it is commonly used when the goal is to forecast future performance such as job success or academic achievement.",
      "phrases": [
        "Predictive validity is a type of criterion-related validity",
        " in which the criterion is measured at the same time as the predictor,",
        " and it is commonly used when the goal is to forecast future performance",
        " such as job success or academic achievement."
      ],
      "target_phrase_index": 1,
      "error_original": "measured at the same time as the predictor",
      "error_correct": "measured after the predictor",
      "explanation": "Predictive validity involves measuring the criterion after the predictor test has been administered (e.g., collecting job performance data months after a hiring test). Measuring the criterion at the same time as the predictor describes concurrent validity, not predictive validity. This distinction between the timing of criterion measurement is the key difference between these two subtypes of criterion-related validity."
    },
    {
      "id": "PMET-SC-0023",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Between-Subjects (Independent Groups) Designs",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0277",
      "modified_sentence": "Random assignment creates groups that are expected to be equivalent on all variables except the dependent variable, and the main advantage of between-subjects designs is avoiding carryover effects.",
      "phrases": [
        "Random assignment creates groups that are expected to be equivalent",
        " on all variables except the dependent variable,",
        " and the main advantage of between-subjects designs",
        " is avoiding carryover effects."
      ],
      "target_phrase_index": 1,
      "error_original": "except the dependent variable,",
      "error_correct": "except the independent variable,",
      "explanation": "Random assignment is used to ensure that groups are equivalent on all variables except the independent variable, which is the variable being manipulated by the researcher. The dependent variable is the outcome being measured, not the variable on which groups are expected to differ by design."
    },
    {
      "id": "PMET-SC-0024",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Kurtosis",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0378",
      "modified_sentence": "Severe skewness or kurtosis can violate assumptions of parametric statistical tests, and options include using nonparametric alternatives, transforming data using log or cube root methods, or using robust statistical methods and reporting median instead of mean for skewed data.",
      "phrases": [
        "Severe skewness or kurtosis can violate assumptions of parametric statistical tests,",
        " and options include using nonparametric alternatives,",
        " transforming data using log or cube root methods,",
        " or using robust statistical methods and reporting median instead of mean for skewed data."
      ],
      "target_phrase_index": 2,
      "error_original": "cube root",
      "error_correct": "square root",
      "explanation": "The passage lists 'square root' as one of the common data transformation methods used to address violations of parametric test assumptions. 'Cube root' is not the standard transformation mentioned; the correct term is 'square root,' which along with log transformations is a widely recommended approach for normalizing skewed distributions."
    },
    {
      "id": "PMET-SC-0025",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Predictive Validity",
      "passage_type": "example",
      "source_passage_id": "PMET-0086",
      "modified_sentence": "A correlation of .45 between admission test scores and subsequent GPA demonstrates concurrent validity, and the test provides useful information about likely academic performance.",
      "phrases": [
        "A correlation of .45 between admission test scores",
        " and subsequent GPA demonstrates concurrent validity,",
        " and the test provides useful information",
        " about likely academic performance."
      ],
      "target_phrase_index": 1,
      "error_original": "concurrent validity",
      "error_correct": "predictive validity",
      "explanation": "Because the admissions test is administered before graduate school and the criterion (first-year GPA) is measured at a later time, this is an example of predictive validity, not concurrent validity. Concurrent validity involves measuring the predictor and criterion at approximately the same point in time, whereas predictive validity involves a meaningful time interval between the predictor assessment and the criterion measurement."
    },
    {
      "id": "PMET-SC-0026",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Components of Clinical Utility",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0085",
      "modified_sentence": "Questions to ask about a test's clinical utility include whether use of this test leads to different clinical decisions than would be made without it, whether those different decisions result in better diagnostic reliability, whether the test is feasible to administer in typical clinical settings, and whether the test is acceptable to patients and clinicians.",
      "phrases": [
        "Questions to ask about a test's clinical utility include whether use of this test leads to different clinical decisions than would be made without it,",
        " whether those different decisions result in better diagnostic reliability,",
        " whether the test is feasible to administer in typical clinical settings,",
        " and whether the test is acceptable to patients and clinicians."
      ],
      "target_phrase_index": 1,
      "error_original": "better diagnostic reliability",
      "error_correct": "better patient outcomes",
      "explanation": "The original passage states that the key question is whether different clinical decisions result in 'better patient outcomes,' not 'better diagnostic reliability.' Clinical utility is fundamentally concerned with whether test use improves outcomes for patients, not merely whether it enhances diagnostic reliability. Diagnostic reliability is a separate psychometric property related to consistency of measurement."
    },
    {
      "id": "PMET-SC-0027",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Correlational Research",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0271",
      "modified_sentence": "Correlational research examines relationships between variables without manipulation, and while correlation does not imply causation, sophisticated correlational techniques such as factor analysis and path analysis can test theoretical models about causal relationships.",
      "phrases": [
        "Correlational research examines relationships between variables without manipulation,",
        " and while correlation does not imply causation,",
        " sophisticated correlational techniques such as factor analysis and path analysis",
        " can test theoretical models about causal relationships."
      ],
      "target_phrase_index": 2,
      "error_original": "factor analysis and path analysis",
      "error_correct": "structural equation modeling and path analysis",
      "explanation": "The passage originally identifies structural equation modeling (SEM) and path analysis as the sophisticated correlational techniques used to test theoretical causal models. Factor analysis is a different statistical technique primarily used to identify latent constructs underlying observed variables, not to test theoretical models about causal relationships in the way SEM does."
    },
    {
      "id": "PMET-SC-0028",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "CIPP Model (Stufflebeam)",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0562",
      "modified_sentence": "Daniel Stufflebeam's CIPP Model is ahypothesis-oriented evaluation framework in which Context evaluation assesses needs and problems,Input evaluation examines competing strategies, Process evaluation monitors implementation,and Product evaluation measures outcomes.",
      "phrases": [
        "Daniel Stufflebeam's CIPP Model is a",
        "hypothesis-oriented evaluation framework in which Context evaluation assesses needs and problems,",
        "Input evaluation examines competing strategies, Process evaluation monitors implementation,",
        "and Product evaluation measures outcomes."
      ],
      "target_phrase_index": 1,
      "error_original": "hypothesis-oriented evaluation framework",
      "error_correct": "decision-oriented evaluation framework",
      "explanation": "Stufflebeam's CIPP Model is explicitly described as a decision-oriented evaluation framework, designed to provide information useful for decision-making at each stage of program development. It is not hypothesis-oriented; the term 'hypothesis-oriented' more accurately describes experimental research designs. Stufflebeam distinguished his approach from traditional hypothesis-testing models by emphasizing that evaluation should serve decision-makers rather than test hypotheses."
    },
    {
      "id": "PMET-SC-0029",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Introduction to Classical Conditioning",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0006",
      "modified_sentence": "Classical conditioning, also known as Pavlovian or respondent conditioning, represents one of the most fundamental mechanisms of learning discovered in the history of psychology, and was first systematically described by Russian physiologist Ivan Pavlov in the 1920s during his research on digestive processes in dogs.",
      "phrases": [
        "Classical conditioning, also known as Pavlovian or respondent conditioning,",
        " represents one of the most fundamental mechanisms of learning discovered in the history of psychology,",
        " and was first systematically described by Russian physiologist Ivan Pavlov in the 1920s",
        " during his research on digestive processes in dogs."
      ],
      "target_phrase_index": 2,
      "error_original": "in the 1920s",
      "error_correct": "in the 1890s",
      "explanation": "Ivan Pavlov first systematically described classical conditioning in the 1890s during his research on digestive processes in dogs, not in the 1920s. By the 1920s, Pavlov's work was already well established and widely known in the scientific community. The original passage clearly states the 1890s as the correct time period."
    },
    {
      "id": "PMET-SC-0030",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Major Qualitative Traditions",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0285",
      "modified_sentence": "Ethnography involves prolonged immersion in a cultural group or community to understand its practices, beliefs, and social dynamics from an outsider perspective, and the researcher engages in participant observation by simultaneously participating in and observing the culture.",
      "phrases": [
        "Ethnography involves prolonged immersion in a cultural group or community",
        " to understand its practices, beliefs, and social dynamics from an outsider perspective,",
        " and the researcher engages in participant observation",
        " by simultaneously participating in and observing the culture."
      ],
      "target_phrase_index": 1,
      "error_original": "from an outsider perspective",
      "error_correct": "from an insider perspective",
      "explanation": "Ethnography aims to understand a culture from an insider (emic) perspective, not an outsider (etic) perspective. The defining feature of ethnographic research is that the researcher seeks to understand the cultural group's practices, beliefs, and social dynamics as members of that group experience them, which is the insider or emic viewpoint."
    },
    {
      "id": "PMET-SC-0031",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Test Bias and Fairness",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0366",
      "modified_sentence": "Test bias is a psychometric concept referring to random errors in test scores or predictions for members of particular groups, and a test is considered biased if it systematically over- or underpredicts criterion performance for certain groups.",
      "phrases": [
        "Test bias is a psychometric concept",
        " referring to random errors in test scores or predictions for members of particular groups,",
        " and a test is considered biased if it systematically over- or underpredicts",
        " criterion performance for certain groups."
      ],
      "target_phrase_index": 1,
      "error_original": "random errors",
      "error_correct": "systematic errors",
      "explanation": "Test bias specifically refers to systematic errors, not random errors, in test scores or predictions. Random errors reflect unreliability and affect all examinees equally without directional bias, whereas systematic errors consistently disadvantage or advantage particular groups, which is the defining characteristic of test bias."
    },
    {
      "id": "PMET-SC-0032",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "t-Tests",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0134",
      "modified_sentence": "The t-test is used to compare means when the population variance is unknown, which is almost always the case, and there are three main types of t-tests.",
      "phrases": [
        "The t-test is used to compare means",
        " when the population variance is unknown,",
        " which is almost always the case,",
        " and there are three main types of t-tests."
      ],
      "target_phrase_index": 1,
      "error_original": "population variance",
      "error_correct": "population standard deviation",
      "explanation": "The t-test is specifically used when the population standard deviation (not the population variance) is unknown and must be estimated from the sample. While variance and standard deviation are mathematically related (standard deviation is the square root of variance), the defining condition for using the t-test rather than the z-test is that the population standard deviation (sigma) is unknown."
    },
    {
      "id": "PMET-SC-0033",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "The Three-Term Contingency",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0190",
      "modified_sentence": "The three-term contingency, originally described by B.F. Skinner, identifies the relationship among the antecedent, behavior, and consequence, and this framework is fundamental to functional behavior assessment and the development of behavior intervention plans in clinical and educational settings.",
      "phrases": [
        "The three-term contingency, originally described by B.F. Skinner,",
        " identifies the relationship among the antecedent, behavior, and consequence,",
        " and this framework is fundamental to functional behavior assessment",
        " and the development of behavior intervention plans in clinical and educational settings."
      ],
      "target_phrase_index": 2,
      "error_original": "fundamental to functional behavior assessment",
      "error_correct": "fundamental to functional behavior analysis",
      "explanation": "The three-term contingency is fundamental to functional behavior analysis (FBA as a methodology within applied behavior analysis). While the term 'functional behavior assessment' is commonly used in educational settings, in the context of the original passage and EPPP content regarding operant conditioning frameworks, the three-term contingency is described as foundational to functional behavior analysis — the broader scientific discipline. However, re-examining the original passage, it actually does say 'functional behavior assessment,' so this error would not apply here."
    },
    {
      "id": "PMET-SC-0034",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Single-Subject (Single-Case) Designs",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0264",
      "modified_sentence": "Single-subject designs, also called single-case experimental designs or N-of-1 designs, use individual participants as their own controls, involve repeated measurement of behavior over time and systematic introduction and withdrawal of interventions, and are widely used in applied behavior analysis and health psychology.",
      "phrases": [
        "Single-subject designs, also called single-case experimental designs or N-of-1 designs,",
        " use individual participants as their own controls,",
        " involve repeated measurement of behavior over time and systematic introduction and withdrawal of interventions,",
        " and are widely used in applied behavior analysis and health psychology."
      ],
      "target_phrase_index": 3,
      "error_original": "health psychology",
      "error_correct": "clinical psychology",
      "explanation": "The passage states that single-subject designs are widely used in applied behavior analysis and clinical psychology, not health psychology. Health psychology is a distinct subfield focused on how psychological factors affect health and illness, whereas clinical psychology is the field traditionally associated with single-subject experimental designs alongside applied behavior analysis."
    },
    {
      "id": "PMET-SC-0035",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Advantages of IRT",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0502",
      "modified_sentence": "Ability estimate invariance means that examinee ability estimates are comparable regardless of which specific items were administered, as long as items come from a standardized norm group rather than a calibrated item bank.",
      "phrases": [
        "Ability estimate invariance means that examinee ability estimates are comparable",
        " regardless of which specific items were administered,",
        " as long as items come from a standardized norm group",
        " rather than a calibrated item bank."
      ],
      "target_phrase_index": 2,
      "error_original": "as long as items come from a standardized norm group",
      "error_correct": "as long as items come from a calibrated item bank",
      "explanation": "In Item Response Theory (IRT), ability estimate invariance holds when items are drawn from a calibrated item bank—meaning items whose parameters have been estimated and fixed through IRT calibration procedures. The phrase 'standardized norm group' is a concept from Classical Test Theory (CTT) related to norming, not to the IRT requirement for item parameter calibration. The correct condition is that items come from a calibrated bank."
    },
    {
      "id": "PMET-SC-0036",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0545",
      "modified_sentence": "Process evaluation monitors implementation fidelity; outcome evaluation measures goal achievement; impact evaluation examines short-term, narrower effects on the targeted population.",
      "phrases": [
        "Process evaluation monitors implementation fidelity;",
        " outcome evaluation measures goal achievement;",
        " impact evaluation examines short-term, narrower effects on the targeted population."
      ],
      "target_phrase_index": 2,
      "error_original": "short-term, narrower effects",
      "error_correct": "long-term, broader effects",
      "explanation": "Impact evaluation is specifically designed to examine long-term, broader effects of a program beyond its immediate goals, not short-term, narrower effects. Short-term goal achievement is the focus of outcome evaluation, whereas impact evaluation looks at wider, more distal consequences over time."
    },
    {
      "id": "PMET-SC-0037",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Concurrent Validity",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0082",
      "modified_sentence": "Predictive validity is preferred for selection/admissions decisions where forecasting future performance is the goal, while concurrent validity is appropriate when substituting one measure for another, screening, or diagnosis where the criterion is historically documented rather than currently observable.",
      "phrases": [
        "Predictive validity is preferred for selection/admissions decisions where forecasting future performance is the goal,",
        " while concurrent validity is appropriate when substituting one measure for another,",
        " screening, or diagnosis where the criterion is historically documented rather than currently observable."
      ],
      "target_phrase_index": 2,
      "error_original": "historically documented",
      "error_correct": "currently observable",
      "explanation": "Concurrent validity involves a criterion that is currently observable — meaning the test and criterion are measured at the same time. The passage states the criterion is 'currently observable,' not 'historically documented.' Historical documentation would imply archival or past data, which contradicts the defining feature of concurrent validity: simultaneous measurement of the predictor and criterion."
    },
    {
      "id": "PMET-SC-0038",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Problems with Punishment",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0476",
      "modified_sentence": "One major problem with punishment is that it often suppresses behavior only temporarily, and the suppressed behavior tends to return when the reinforcing agent is no longer present, rather than producing lasting behavioral change.",
      "phrases": [
        "One major problem with punishment is that it often suppresses behavior only temporarily,",
        " and the suppressed behavior tends to return when the reinforcing agent is no longer present,",
        " rather than producing lasting behavioral change."
      ],
      "target_phrase_index": 1,
      "error_original": "the reinforcing agent",
      "error_correct": "the punishing agent",
      "explanation": "The passage states that punishment suppresses behavior only in the presence of the punishing agent—meaning the person or stimulus delivering the punishment. The error replaces 'punishing agent' with 'reinforcing agent,' which is a different operant conditioning concept. The behavior returns when the punishing agent (not a reinforcing agent) is removed from the situation."
    },
    {
      "id": "PMET-SC-0039",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "operant-conditioning.html",
      "chapter_title": "Shaping Behavior: Operant Conditioning",
      "section": "Discriminative Stimuli",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0187",
      "modified_sentence": "A discriminative stimulus (S D) is a stimulus in the presence of which a particular response has been reinforced, and through experience organisms learn to respond differently in the presence versus absence of the S D, where the S D elicits the response much like in classical conditioning, rather than merely setting the occasion for the response by signaling reinforcement availability.",
      "phrases": [
        "A discriminative stimulus (S D) is a stimulus in the presence of which a particular response has been reinforced,",
        " and through experience organisms learn to respond differently in the presence versus absence of the S D,",
        " where the S D elicits the response much like in classical conditioning,",
        " rather than merely setting the occasion for the response by signaling reinforcement availability."
      ],
      "target_phrase_index": 2,
      "error_original": "where the S D elicits the response much like in classical conditioning",
      "error_correct": "where the S D does not elicit the response as in classical conditioning",
      "explanation": "The passage explicitly states that the discriminative stimulus (S D) does NOT elicit the response (as a stimulus does in classical conditioning). Instead, the S D sets the occasion for the response by signaling that reinforcement is available. The error reverses this critical distinction, incorrectly claiming the S D elicits the response like in classical conditioning, which confuses the fundamental difference between operant and classical conditioning mechanisms."
    },
    {
      "id": "PMET-SC-0040",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "p-Values",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0129",
      "modified_sentence": "The p-value is the probability of obtaining results at least as extreme as those observed, assuming the alternative hypothesis is true, and if p ≤ α, the result is considered statistically significant, and we reject the null hypothesis.",
      "phrases": [
        "The p-value is the probability of obtaining results at least as extreme as those observed,",
        " assuming the alternative hypothesis is true,",
        " and if p ≤ α, the result is considered statistically significant,",
        " and we reject the null hypothesis."
      ],
      "target_phrase_index": 1,
      "error_original": "assuming the alternative hypothesis is true,",
      "error_correct": "assuming the null hypothesis is true,",
      "explanation": "The p-value is defined as the probability of obtaining results at least as extreme as those observed assuming the null hypothesis is true, not the alternative hypothesis. This is a foundational concept in null hypothesis significance testing (NHST): the p-value is calculated under the assumption that the null hypothesis is correct."
    },
    {
      "id": "PMET-SC-0041",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0584",
      "modified_sentence": "Mediators explain how an effect occurs, while moderators explain why or through what mechanism the effect occurs.",
      "phrases": [
        "Mediators explain how an effect occurs,",
        " while moderators explain why",
        " or through what mechanism the effect occurs."
      ],
      "target_phrase_index": 1,
      "error_original": "while moderators explain why",
      "error_correct": "while moderators explain when or for whom",
      "explanation": "Moderators explain when or for whom an effect occurs (i.e., they identify the conditions or subgroups under which the effect varies). The phrase 'explain why or through what mechanism' actually describes mediators, not moderators. This error conflates the roles of mediators and moderators, which is a commonly tested distinction on the EPPP."
    },
    {
      "id": "PMET-SC-0042",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Prepared Fears",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0028",
      "modified_sentence": "This preparedness may explain the non-random distribution of phobias in clinical populations (Seligman & Mineka, 2001).",
      "phrases": [
        "This preparedness may explain",
        " the non-random distribution of phobias",
        " in clinical populations (Seligman & Mineka, 2001)."
      ],
      "target_phrase_index": 2,
      "error_original": "Seligman & Mineka, 2001",
      "error_correct": "Ohman & Mineka, 2001",
      "explanation": "The key research on prepared fears and the non-random distribution of phobias in clinical populations was published by Ohman and Mineka (2001), not Seligman and Mineka. While Seligman (1971) originally proposed the concept of biological preparedness in fear conditioning, the specific 2001 publication referenced here was authored by Arne Ohman and Susan Mineka."
    },
    {
      "id": "PMET-SC-0043",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "EPPP Exam Focus Points",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0542",
      "modified_sentence": "Ethnography is a qualitative research method that involves participant observation in cultural settings, produces what Bronislaw Malinowski called thick description, and is most commonly associated with the field of anthropology.",
      "phrases": [
        "Ethnography is a qualitative research method",
        " that involves participant observation in cultural settings,",
        " produces what Bronislaw Malinowski called thick description,",
        " and is most commonly associated with the field of anthropology."
      ],
      "target_phrase_index": 2,
      "error_original": "Bronislaw Malinowski called thick description",
      "error_correct": "Clifford Geertz called thick description",
      "explanation": "The concept of 'thick description' in ethnographic research was articulated by Clifford Geertz in his 1973 work 'The Interpretation of Cultures,' borrowing the term from philosopher Gilbert Ryle. Bronislaw Malinowski was a pioneering anthropologist known for participant observation fieldwork, but he is not the scholar associated with thick description."
    },
    {
      "id": "PMET-SC-0044",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "reliability.html",
      "chapter_title": "Consistency of Measurement: Test Reliability",
      "section": "Standard Error of Measurement",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0232",
      "modified_sentence": "The standard error of measurement (SEM) quantifies the amount of error expected in an individual's observed score, and while the reliability coefficient describes individual-level consistency, the SEM provides information about the precision of individual scores.",
      "phrases": [
        "The standard error of measurement (SEM) quantifies the amount of error expected in an individual's observed score,",
        " and while the reliability coefficient describes individual-level consistency,",
        " the SEM provides information about the precision of individual scores."
      ],
      "target_phrase_index": 1,
      "error_original": "individual-level consistency",
      "error_correct": "group-level consistency",
      "explanation": "The reliability coefficient describes group-level consistency (i.e., the consistency of scores across a group of examinees), not individual-level consistency. It is the SEM that provides information about the precision of individual scores. This distinction between group-level (reliability coefficient) and individual-level (SEM) metrics is a key concept in psychometric theory."
    },
    {
      "id": "PMET-SC-0045",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "validity.html",
      "chapter_title": "Measuring What Matters: Content & Construct Validity",
      "section": "Evidence Based on Consequences of Testing",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0360",
      "modified_sentence": "This evidence considers the intended and unintended consequences of test use, including potential benefits and harms, and it addresses whether test use achieves its intended outcomes and whether any negative consequences are related to construct-underrepresentation factors such as bias.",
      "phrases": [
        "This evidence considers the intended and unintended consequences of test use,",
        " including potential benefits and harms,",
        " and it addresses whether test use achieves its intended outcomes",
        " and whether any negative consequences are related to construct-underrepresentation factors such as bias."
      ],
      "target_phrase_index": 3,
      "error_original": "construct-underrepresentation factors such as bias",
      "error_correct": "construct-irrelevant factors such as bias",
      "explanation": "The original passage states that negative consequences are related to 'construct-irrelevant factors such as bias.' Construct-irrelevant variance refers to systematic error introduced by factors unrelated to the construct being measured (e.g., bias). Construct underrepresentation is a different validity threat that refers to a test failing to capture important aspects of the construct. The error swaps 'construct-irrelevant' with 'construct-underrepresentation,' which are distinct concepts in validity theory."
    },
    {
      "id": "PMET-SC-0046",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Quasi-Experimental Designs",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0259",
      "modified_sentence": "Quasi-experimental designs lack random assignment but still involve manipulation of an independent variable, and are commonly used in applied settings where random assignment is impractical or unethical, while they provide stronger evidence for causation than true experiments, though thoughtful quasi-experimental designs can yield valuable findings.",
      "phrases": [
        "Quasi-experimental designs lack random assignment but still involve manipulation of an independent variable,",
        " and are commonly used in applied settings where random assignment is impractical or unethical,",
        " while they provide stronger evidence for causation than true experiments,",
        " though thoughtful quasi-experimental designs can yield valuable findings."
      ],
      "target_phrase_index": 2,
      "error_original": "stronger evidence for causation than true experiments",
      "error_correct": "weaker evidence for causation than true experiments",
      "explanation": "Quasi-experimental designs provide WEAKER evidence for causation than true experiments, not stronger, because they lack random assignment, which is a key element for establishing internal validity and ruling out confounds. The passage originally states 'weaker evidence,' so 'stronger' is the introduced error."
    },
    {
      "id": "PMET-SC-0047",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Properties of the Normal Distribution",
      "passage_type": "definition",
      "source_passage_id": "PMET-0373",
      "modified_sentence": "In a normal distribution, 68% of observations fall between M minus 1SD and M plus 1SD, 95% of observations fall between M minus 2SD and M plus 2SD, and 98.7% of observations fall between M minus 3SD and M plus 3SD.",
      "phrases": [
        "In a normal distribution, 68% of observations fall between M minus 1SD and M plus 1SD,",
        " 95% of observations fall between M minus 2SD and M plus 2SD,",
        " and 98.7% of observations fall between M minus 3SD and M plus 3SD."
      ],
      "target_phrase_index": 2,
      "error_original": "98.7%",
      "error_correct": "99.7%",
      "explanation": "The Empirical Rule (also known as the 68-95-99.7 rule) states that 99.7% of observations in a normal distribution fall between M minus 3SD and M plus 3SD. The value '98.7%' is incorrect; the correct percentage is 99.7%."
    },
    {
      "id": "PMET-SC-0048",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "classical-conditioning.html",
      "chapter_title": "How Organisms Learn: Classical Conditioning",
      "section": "Clinical Applications",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0425",
      "modified_sentence": "Systematic desensitization, developed by Joseph Wolpe, is based on the principle of stimulus generalization, in which a conditioned fear response is replaced by a relaxation response through gradual exposure to a hierarchy of anxiety-provoking stimuli.",
      "phrases": [
        "Systematic desensitization, developed by Joseph Wolpe,",
        " is based on the principle of stimulus generalization,",
        " in which a conditioned fear response is replaced by a relaxation response",
        " through gradual exposure to a hierarchy of anxiety-provoking stimuli."
      ],
      "target_phrase_index": 1,
      "error_original": "stimulus generalization",
      "error_correct": "counterconditioning",
      "explanation": "Systematic desensitization is based on the principle of counterconditioning (also called reciprocal inhibition), in which an incompatible response (relaxation) is paired with a feared stimulus to replace the anxiety response. Stimulus generalization is a different classical conditioning concept referring to the tendency for stimuli similar to a conditioned stimulus to also elicit the conditioned response. This error requires specific knowledge of the theoretical basis of Wolpe's technique."
    },
    {
      "id": "PMET-SC-0049",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Commonly Tested Topics for the EPPP",
      "passage_type": "clinical_note",
      "source_passage_id": "PMET-0434",
      "modified_sentence": "The Standard Error of Estimate measures the accuracy of predictions made from a regression equation, it is calculated using the formula SDx times the square root of (1 - r²), and it decreases as the correlation coefficient increases, approaching zero as r approaches 1.00.",
      "phrases": [
        "The Standard Error of Estimate measures the accuracy of predictions made from a regression equation,",
        " it is calculated using the formula SDx times the square root of (1 - r²),",
        " and it decreases as the correlation coefficient increases,",
        " approaching zero as r approaches 1.00."
      ],
      "target_phrase_index": 1,
      "error_original": "SDx",
      "error_correct": "SDy",
      "explanation": "The Standard Error of Estimate formula is SEE = SDy × √(1 - r²), where SDy is the standard deviation of the criterion (Y) variable, not SDx. The SEE reflects how much predicted Y scores deviate from actual Y scores, so it is based on the variability of Y, adjusted by the strength of the correlation."
    },
    {
      "id": "PMET-SC-0050",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Base Rates and Selection Ratios",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0457",
      "modified_sentence": "According to the Taylor-Russell tables, a test's incremental validity is maximized when the base rate is approximately .30, and a lower selection ratio generally increases the proportion of successful applicants selected.",
      "phrases": [
        "According to the Taylor-Russell tables,",
        " a test's incremental validity is maximized when the base rate is approximately .30,",
        " and a lower selection ratio generally increases",
        " the proportion of successful applicants selected."
      ],
      "target_phrase_index": 1,
      "error_original": "the base rate is approximately .30",
      "error_correct": "the base rate is approximately .50",
      "explanation": "According to the Taylor-Russell tables, a test's incremental validity (its ability to improve prediction beyond the base rate alone) is maximized when the base rate is approximately .50 (moderate), not .30. When the base rate is already very low or very high, there is less room for a test to improve upon predictions made from the base rate alone."
    },
    {
      "id": "PMET-SC-0051",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "variables-data.html",
      "chapter_title": "Variables, Scales & the Language of Data",
      "section": "Measures of Variability",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0398",
      "modified_sentence": "The range is the difference between the highest and lowest scores, and it is simple but unstable because it is based on only two scores and is highly sensitive to central tendency.",
      "phrases": [
        "The range is the difference between the highest and lowest scores,",
        " and it is simple but unstable",
        " because it is based on only two scores",
        " and is highly sensitive to central tendency."
      ],
      "target_phrase_index": 3,
      "error_original": "highly sensitive to central tendency",
      "error_correct": "highly sensitive to outliers",
      "explanation": "The range is highly sensitive to outliers (extreme scores), not to central tendency. Central tendency refers to measures like the mean, median, and mode, which describe the center of a distribution. The range is unstable precisely because a single extreme score (outlier) can dramatically change its value."
    },
    {
      "id": "PMET-SC-0052",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "correlation-regression.html",
      "chapter_title": "Relationships in Data: Correlation & Regression",
      "section": "Test Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0069",
      "modified_sentence": "Correlation is central to evaluating criterion-related validity, which includes both predictive and construct subtypes, and the correlation between test scores and criterion measures indicates how well the test predicts the criterion.",
      "phrases": [
        "Correlation is central to evaluating criterion-related validity,",
        " which includes both predictive and construct subtypes,",
        " and the correlation between test scores and criterion measures",
        " indicates how well the test predicts the criterion."
      ],
      "target_phrase_index": 1,
      "error_original": "predictive and construct subtypes",
      "error_correct": "predictive and concurrent subtypes",
      "explanation": "Criterion-related validity is divided into two subtypes: predictive validity and concurrent validity. The passage incorrectly substitutes 'construct' for 'concurrent.' Construct validity is a separate category of validity altogether, not a subtype of criterion-related validity."
    },
    {
      "id": "PMET-SC-0053",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "criterion-validity.html",
      "chapter_title": "Predicting Outcomes: Criterion-Related Validity",
      "section": "Introduction to Criterion-Related Validity",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0093",
      "modified_sentence": "Criterion-related validity is subdivided into two types based on when the criterion is measured: predictive validity involves simultaneous measurement of predictor and criterion, while concurrent validity involves simultaneous measurement of predictor and criterion.",
      "phrases": [
        "Criterion-related validity is subdivided into two types",
        " based on when the criterion is measured:",
        " predictive validity involves simultaneous measurement of predictor and criterion,",
        " while concurrent validity involves simultaneous measurement of predictor and criterion."
      ],
      "target_phrase_index": 2,
      "error_original": "predictive validity involves simultaneous measurement of predictor and criterion",
      "error_correct": "predictive validity involves a time interval between testing and criterion measurement",
      "explanation": "Predictive validity is characterized by a time interval between the administration of the predictor test and the collection of criterion data, not simultaneous measurement. Simultaneous measurement of predictor and criterion is the defining feature of concurrent validity. The error here swaps the defining characteristic of concurrent validity into the description of predictive validity."
    },
    {
      "id": "PMET-SC-0054",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "inferential-statistics.html",
      "chapter_title": "From Samples to Populations: Inferential Statistics",
      "section": "Null and Alternative Hypotheses",
      "passage_type": "example",
      "source_passage_id": "PMET-0118",
      "modified_sentence": "The null hypothesis states there is no difference in depression scores between groups (μ₁ = μ₂), while the alternative hypothesis μ₁ < μ₂ represents a non-directional or two-tailed test, or μ₁ ≠ μ₂ represents a non-directional or two-tailed test.",
      "phrases": [
        "The null hypothesis states there is no difference in depression scores between groups (μ₁ = μ₂),",
        " while the alternative hypothesis μ₁ < μ₂ represents a non-directional or two-tailed test,",
        " or μ₁ ≠ μ₂ represents a non-directional or two-tailed test."
      ],
      "target_phrase_index": 1,
      "error_original": "μ₁ < μ₂ represents a non-directional or two-tailed test",
      "error_correct": "μ₁ < μ₂ represents a directional or one-tailed test",
      "explanation": "The alternative hypothesis μ₁ < μ₂ specifies a direction (the therapy group is expected to have lower scores), making it a directional or one-tailed test. A non-directional or two-tailed test would use μ₁ ≠ μ₂, which simply predicts a difference without specifying which group will score higher. The passage clearly states that μ₁ < μ₂ is directional/one-tailed."
    },
    {
      "id": "PMET-SC-0055",
      "mode": "sentence_click",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "chapter_file": "research-designs.html",
      "chapter_title": "Blueprints for Discovery: Research Designs",
      "section": "Sampling Methods",
      "passage_type": "paragraph",
      "source_passage_id": "PMET-0280",
      "modified_sentence": "Probability sampling methods give every member of the population a known, nonzero chance of selection, supporting analytic generalization to the broader population from which the sample was drawn.",
      "phrases": [
        "Probability sampling methods give every member of the population a known,",
        " nonzero chance of selection,",
        " supporting analytic generalization to the broader population",
        " from which the sample was drawn."
      ],
      "target_phrase_index": 2,
      "error_original": "analytic generalization",
      "error_correct": "statistical generalization",
      "explanation": "Probability sampling supports statistical generalization, which involves using inferential statistics to generalize findings from a sample to a population. Analytic generalization is a different concept associated with qualitative and case study research, where theoretical reasoning rather than sampling logic is used to extend findings beyond the immediate study."
    }
  ]
}