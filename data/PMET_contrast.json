{
  "domain_code": "PMET",
  "domain_name": "Psychometrics & Research Methods",
  "question_type": "contrast",
  "total": 30,
  "questions": [
    {
      "id": "LEA_CONT_001",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Classical Conditioning",
      "item_x": "Conditioned stimulus (CS)",
      "item_y": "Unconditioned stimulus (UCS)",
      "question": "What is the difference between a conditioned stimulus and an unconditioned stimulus?",
      "answer": "An unconditioned stimulus (UCS) is a stimulus that naturally and automatically elicits a response without prior learning — it is 'unlearned.' (e.g., food naturally elicits salivation; a loud noise naturally elicits fear). A conditioned stimulus (CS) was originally a neutral stimulus that, after repeated pairing with the UCS, acquires the ability to elicit a response on its own. It is 'created' through learning. In Watson's Little Albert study: the loud noise was the UCS; the white rat began as a neutral stimulus and became the CS after pairing.",
      "key_distinction": "UCS = elicits response automatically (unlearned); CS = acquired response trigger through repeated pairing (learned).",
      "commonly_confused_because": "Students confuse which stimulus comes before training (UCS/neutral stimulus) vs. after training (CS), especially in exam vignettes.",
      "legacy_domain_code": "LEA",
      "legacy_domain_name": "Learning"
    },
    {
      "id": "LEA_CONT_002",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Classical Conditioning",
      "item_x": "Extinction (classical conditioning)",
      "item_y": "Forgetting",
      "question": "What is the difference between extinction and forgetting in classical conditioning?",
      "answer": "Extinction in classical conditioning occurs when the CS is repeatedly presented without the UCS, causing the conditioned response (CR) to gradually weaken and disappear. It is an active inhibitory learning process, not simply the passive fading of the memory. Evidence: spontaneous recovery — after rest, the CR returns temporarily, demonstrating that the original CS-UCS association was not erased but was inhibited. Forgetting is passive decay of a memory trace over time due to disuse. Forgetting does not produce spontaneous recovery.",
      "key_distinction": "Extinction = active inhibition of learned response through repeated non-reinforcement (reversible by spontaneous recovery); Forgetting = passive decay.",
      "commonly_confused_because": "Both result in the conditioned response no longer appearing, but extinction is an active learned process while forgetting is passive.",
      "legacy_domain_code": "LEA",
      "legacy_domain_name": "Learning"
    },
    {
      "id": "LEA_CONT_003",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Classical Conditioning",
      "item_x": "Stimulus generalization",
      "item_y": "Stimulus discrimination",
      "question": "What is the difference between stimulus generalization and stimulus discrimination in conditioning?",
      "answer": "Stimulus generalization occurs when stimuli similar to the original CS also elicit the conditioned response, even though they were never directly paired with the UCS. The more similar a stimulus is to the CS, the stronger the response (generalization gradient). Stimulus discrimination occurs when the organism learns to respond only to the specific CS and not to similar stimuli — often because only the CS was paired with the UCS while similar stimuli were not, producing the ability to distinguish between them.",
      "key_distinction": "Generalization = similar stimuli also elicit CR; Discrimination = responds only to the original CS, not to similar stimuli.",
      "commonly_confused_because": "Both involve how the organism responds to stimuli beyond the original CS; they represent opposite outcomes of stimulus similarity testing.",
      "legacy_domain_code": "LEA",
      "legacy_domain_name": "Learning"
    },
    {
      "id": "LEA_CONT_004",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Operant Conditioning",
      "item_x": "Positive reinforcement",
      "item_y": "Negative reinforcement",
      "question": "What is the difference between positive reinforcement and negative reinforcement?",
      "answer": "Both positive and negative reinforcement INCREASE the frequency or probability of a behavior. Positive reinforcement involves adding a desirable/pleasant stimulus contingent on the behavior, increasing the likelihood the behavior will recur (e.g., giving a child candy for cleaning their room). Negative reinforcement involves removing an aversive/unpleasant stimulus contingent on the behavior, which also increases the behavior's likelihood (e.g., taking pain medication removes headache, increasing future medication-taking; buckling a seatbelt removes the annoying alarm).",
      "key_distinction": "Both increase behavior; Positive = add something pleasant; Negative = remove something unpleasant.",
      "commonly_confused_because": "Students assume 'negative' means punishment (decreasing behavior), when negative reinforcement INCREASES behavior by removing something bad.",
      "legacy_domain_code": "LEA",
      "legacy_domain_name": "Learning"
    },
    {
      "id": "LEA_CONT_005",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Operant Conditioning",
      "item_x": "Positive punishment",
      "item_y": "Negative punishment",
      "question": "What is the difference between positive punishment and negative punishment?",
      "answer": "Both positive and negative punishment DECREASE the frequency of a behavior. Positive punishment involves adding an aversive stimulus following the behavior, making it less likely (e.g., spanking a child after misbehaving; overcorrection). Negative punishment involves removing a desirable/pleasant stimulus following the behavior, making it less likely (e.g., taking away TV privileges after misbehaving; response cost). Both reduce behavior, but through opposite mechanisms — adding something bad vs. removing something good.",
      "key_distinction": "Both decrease behavior; Positive punishment = add aversive stimulus; Negative punishment = remove pleasant stimulus.",
      "commonly_confused_because": "The positive/negative labels refer to stimulus addition/removal, not to the valence of the outcome — a concept students frequently misread.",
      "legacy_domain_code": "LEA",
      "legacy_domain_name": "Learning"
    },
    {
      "id": "LEA_CONT_006",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Operant Conditioning",
      "item_x": "Fixed ratio schedule",
      "item_y": "Variable ratio schedule",
      "question": "What is the difference between fixed ratio and variable ratio schedules of reinforcement?",
      "answer": "In a fixed ratio (FR) schedule, reinforcement is delivered after a fixed number of responses (e.g., FR 5 = every 5th response). This produces a high rate of responding with a characteristic post-reinforcement pause (brief cessation after each reward). FR schedules produce relatively rapid extinction. In a variable ratio (VR) schedule, reinforcement is delivered after an unpredictable, variable number of responses (e.g., slot machines). VR schedules produce the highest and most consistent rate of responding and are the most resistant to extinction. The unpredictability prevents the post-reinforcement pause.",
      "key_distinction": "FR = high rate, post-reinforcement pause, faster extinction; VR = highest rate, no pause, most resistant to extinction.",
      "commonly_confused_because": "Both produce high rates of responding; students confuse which produces the faster extinction and which is the gambling model.",
      "legacy_domain_code": "LEA",
      "legacy_domain_name": "Learning"
    },
    {
      "id": "LEA_CONT_007",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Operant Conditioning",
      "item_x": "Fixed interval schedule",
      "item_y": "Variable interval schedule",
      "question": "What is the difference between fixed interval and variable interval schedules of reinforcement?",
      "answer": "In a fixed interval (FI) schedule, the first response after a fixed period of time is reinforced (e.g., FI 60 = first response after 60 seconds is reinforced). This produces a scalloped pattern — very low responding right after reinforcement, then gradually increasing as the next interval approaches. In a variable interval (VI) schedule, reinforcement is delivered for the first response after a variable, unpredictable time interval. This produces a slow, steady, consistent rate of responding with good resistance to extinction. Example: checking email (you never know when a new message will arrive).",
      "key_distinction": "FI = scalloped pattern, low right after reward; VI = slow, steady rate, more resistant to extinction.",
      "commonly_confused_because": "Both interval schedules are based on time rather than responses, but the predictability vs. unpredictability of the interval produces different response patterns.",
      "legacy_domain_code": "LEA",
      "legacy_domain_name": "Learning"
    },
    {
      "id": "RMS_CONT_001",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Types of Variables and Data",
      "item_x": "Interval level of measurement",
      "item_y": "Ratio level of measurement",
      "question": "What is the difference between interval and ratio levels of measurement?",
      "answer": "Interval data have equal intervals between values but lack a true zero point — zero does not mean the complete absence of the characteristic (e.g., IQ, temperature in Fahrenheit). You can add and subtract but multiplication and ratios are meaningless ('80°F is not twice as hot as 40°F'). Ratio data have equal intervals AND a true, meaningful zero point representing complete absence of the characteristic (e.g., height, weight, reaction time, income). Ratios are meaningful ('100 kg is twice as heavy as 50 kg'). Psychological test scores are typically treated as interval data.",
      "key_distinction": "Interval = equal intervals, no true zero; Ratio = equal intervals + true zero (ratios meaningful).",
      "commonly_confused_because": "Both allow mean and standard deviation calculation; the presence or absence of a meaningful zero is easily overlooked.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_002",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Types of Variables and Data",
      "item_x": "Moderator variable",
      "item_y": "Mediator variable",
      "question": "What is the difference between a moderator variable and a mediator variable?",
      "answer": "A moderator variable changes the strength or direction of the relationship between an independent variable (IV) and a dependent variable (DV) — it specifies when or for whom the relationship holds. For example, the relationship between stress (IV) and depression (DV) may be stronger for women than men — gender is a moderator. A mediator variable explains the mechanism by which an IV affects a DV — it is the process through which the IV exerts its effect. For example, stress (IV) causes depression (DV) because stress increases cortisol levels (mediator). Moderators answer 'for whom?' and 'when?'; mediators answer 'how?' and 'why?'",
      "key_distinction": "Moderator = changes the strength/direction of the IV-DV relationship; Mediator = explains the mechanism/process linking IV to DV.",
      "commonly_confused_because": "Both are third variables that relate to the IV-DV relationship; students conflate variables that affect the effect with variables that carry the effect.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_003",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Overview of Inferential Statistics",
      "item_x": "Type I error",
      "item_y": "Type II error",
      "question": "What is the difference between a Type I error and a Type II error in hypothesis testing?",
      "answer": "A Type I error (false positive, α) occurs when the null hypothesis is true but the researcher incorrectly rejects it — concluding there IS an effect when there is none. The probability of a Type I error is the alpha level (typically .05). A Type II error (false negative, β) occurs when the null hypothesis is false but the researcher fails to reject it — concluding there is NO effect when one actually exists. The probability of correctly detecting a real effect is power (1 − β). Decreasing alpha from .05 to .01 reduces Type I risk but increases Type II risk (reduces power).",
      "key_distinction": "Type I = false alarm, reject true null; Type II = missed signal, fail to reject false null.",
      "commonly_confused_because": "Both are statistical errors; the α/β notation and the double-negatives in the definitions ('failing to reject') make this concept particularly confusing.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_004",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Overview of Inferential Statistics",
      "item_x": "Statistical significance",
      "item_y": "Effect size",
      "question": "What is the difference between statistical significance and effect size?",
      "answer": "Statistical significance (p-value) tells us the probability of obtaining results at least as extreme as observed, assuming the null hypothesis is true. When p < .05 (the conventional alpha level), we reject the null. Statistical significance is heavily influenced by sample size — with a very large sample, even a trivially small difference can reach significance. Effect size measures the magnitude of the effect, independent of sample size. Common effect size measures include Cohen's d (mean differences), r (correlation), and η² (ANOVA). A statistically significant result can have a negligible effect size; a non-significant result may reflect inadequate power rather than no effect.",
      "key_distinction": "Statistical significance = probability of data given null (affected by N); Effect size = magnitude of the effect (independent of N).",
      "commonly_confused_because": "Students treat statistical significance as synonymous with practical importance; large samples can make trivial effects statistically significant.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_005",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Research - Internal/External Validity",
      "item_x": "Internal validity",
      "item_y": "External validity",
      "question": "What is the difference between internal and external validity?",
      "answer": "Internal validity refers to the degree to which a study's results can be attributed to the independent variable rather than to confounds or extraneous variables. It addresses: 'Did the IV actually cause the change in the DV?' Threats include history, maturation, selection bias, regression to the mean, and testing effects. External validity refers to the degree to which study results can be generalized to other people, settings, and times — beyond the specific study sample and conditions. Threats include non-representative samples and artificial laboratory conditions. There is often a trade-off: tightly controlled experiments maximize internal validity but may sacrifice external validity.",
      "key_distinction": "Internal validity = causal interpretation (did IV cause DV?); External validity = generalizability (to whom and where do findings apply?).",
      "commonly_confused_because": "Both are forms of research validity; students confuse whether the question is about the causal interpretation vs. the scope of generalization.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_006",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Research - Internal/External Validity",
      "item_x": "History threat (internal validity)",
      "item_y": "Maturation threat (internal validity)",
      "question": "What is the difference between history and maturation as threats to internal validity?",
      "answer": "A history threat occurs when some external event (other than the independent variable) that occurs between the pretest and posttest could explain the observed change in the dependent variable. For example, a study evaluating an anti-bullying program might be confounded by a school-wide anti-bullying assembly that occurred during the study. A maturation threat occurs when natural biological or psychological changes within participants over time (growing, getting tired, getting better due to normal healing) produce the observed change — unrelated to the treatment. Both are internal validity threats because they provide alternative explanations for observed changes.",
      "key_distinction": "History = external events during the study; Maturation = internal developmental/biological changes within participants over time.",
      "commonly_confused_because": "Both occur over time and can produce changes that mimic treatment effects; the source (external event vs. internal biological change) is the distinction.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_007",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Research - Single-Subject and Group Designs",
      "item_x": "A-B-A-B (reversal) single-subject design",
      "item_y": "Multiple baseline single-subject design",
      "question": "What is the difference between the A-B-A-B reversal and multiple baseline single-subject designs?",
      "answer": "The A-B-A-B (reversal) design alternates between baseline (A) and treatment (B) phases. Replication of the treatment effect across phases provides strong evidence of a causal relationship (good internal validity). It is the most internally valid single-subject design. However, it cannot be used when: (a) the behavior is irreversible (e.g., academic skills), (b) reverting to baseline is unethical (e.g., self-harm). The multiple baseline design introduces the treatment sequentially across multiple behaviors, settings, or subjects while keeping others in baseline. It is used when reversal is impossible or unethical and demonstrates the causal effect by showing change only when treatment is introduced for each baseline.",
      "key_distinction": "A-B-A-B = reversal/withdrawal phases, strongest causal evidence; Multiple baseline = staggered treatment introduction, used when reversal is unethical/impossible.",
      "commonly_confused_because": "Students may not recognize when a reversal design is contraindicated or how a multiple baseline establishes causation without reversal.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_008",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Inferential Statistical Tests",
      "item_x": "One-way ANOVA",
      "item_y": "Analysis of covariance (ANCOVA)",
      "question": "What is the difference between one-way ANOVA and ANCOVA?",
      "answer": "A one-way ANOVA tests whether there are significant differences in a continuous dependent variable across three or more groups defined by one independent variable. It does not control for extraneous variables. ANCOVA (analysis of covariance) extends ANOVA by statistically removing the effects of one or more continuous extraneous variables (covariates) from the dependent variable before testing group differences. This increases statistical power (by reducing error variance) and controls for pre-existing group differences. ANCOVA is used when groups are not fully equivalent at baseline.",
      "key_distinction": "ANOVA = compares groups on DV; ANCOVA = compares groups on DV after statistically controlling for a covariate.",
      "commonly_confused_because": "Both compare group means; ANCOVA's covariate-control function is a nuanced addition that students often overlook.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_009",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Correlation and Regression",
      "item_x": "Pearson r",
      "item_y": "Spearman rho (ρ)",
      "question": "What is the difference between Pearson r and Spearman rho as correlation coefficients?",
      "answer": "Pearson r is a parametric correlation coefficient used when both variables are measured at the interval or ratio level and are approximately normally distributed. It measures the linear relationship between two continuous variables. Spearman rho (ρ) is a nonparametric correlation coefficient used when one or both variables are ranked/ordinal data, or when the assumptions for Pearson r are violated (non-normal distribution, outliers). Spearman rho ranks the data and computes a Pearson correlation on the ranks. It is less powerful than Pearson r when assumptions are met but more appropriate for ordinal data.",
      "key_distinction": "Pearson r = parametric, interval/ratio data, linear; Spearman rho = nonparametric, ranked/ordinal data.",
      "commonly_confused_because": "Both range from −1 to +1 and measure relationship strength; students confuse when each is appropriate based on measurement level.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_010",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Types of Variables and Data",
      "item_x": "Between-subjects design",
      "item_y": "Within-subjects (repeated measures) design",
      "question": "What is the difference between a between-subjects and a within-subjects (repeated measures) design?",
      "answer": "In a between-subjects design, different participants are assigned to each condition of the independent variable. Each participant experiences only one level of the IV. Random assignment controls for individual differences. This design requires more participants and is susceptible to differences between groups. In a within-subjects (repeated measures) design, the same participants experience all conditions of the IV. Each participant serves as their own control, eliminating between-person variability and increasing statistical power. However, within-subjects designs can suffer from order effects (carryover, fatigue, practice) that require counterbalancing (e.g., Latin square) to control.",
      "key_distinction": "Between-subjects = different people in different conditions; Within-subjects = same people in all conditions.",
      "commonly_confused_because": "Students may not recognize the advantages of within-subjects designs for power or the unique threats (order effects) they introduce.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "TES_CONT_001",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Item Analysis and Test Reliability",
      "item_x": "Test-retest reliability",
      "item_y": "Alternate forms reliability",
      "question": "What is the difference between test-retest and alternate forms reliability?",
      "answer": "Test-retest reliability assesses the stability of a test over time by administering the SAME test to the same individuals on two separate occasions. The resulting coefficient reflects temporal stability (consistency across time). A limitation is that scores may be influenced by memory of previous responses (carry-over effect). Alternate forms (parallel forms) reliability assesses consistency between two equivalent versions of a test administered to the same individuals. It controls for memory effects but requires developing two equivalent forms. Both provide coefficients that reflect how much of score variance is true score variance vs. error.",
      "key_distinction": "Test-retest = same test, different times (stability); Alternate forms = different equivalent versions, same time (form equivalence).",
      "commonly_confused_because": "Both assess consistency of scores; the source of error each controls and fails to control differs in important ways.",
      "legacy_domain_code": "TES",
      "legacy_domain_name": "Testing and Measurement"
    },
    {
      "id": "TES_CONT_002",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Item Analysis and Test Reliability",
      "item_x": "Item difficulty index (p)",
      "item_y": "Item discrimination index (D)",
      "question": "What is the difference between item difficulty (p) and item discrimination (D) in item analysis?",
      "answer": "The item difficulty index (p) is the proportion of examinees who answer an item correctly. It ranges from 0.0 (no one correct) to 1.0 (everyone correct). An optimal item difficulty for maximizing discrimination is approximately p = .50. Items with p > .90 (too easy) or p < .10 (too hard) contribute little to test differentiation. The item discrimination index (D) measures how well a given item distinguishes between high-scoring and low-scoring examinees — typically calculated by comparing the proportion correct in the high-scoring group vs. low-scoring group. A high D means the item reliably separates those who know the content from those who don't.",
      "key_distinction": "p = how easy an item is (proportion correct); D = how well the item discriminates between high and low scorers.",
      "commonly_confused_because": "Both are item analysis statistics and both are proportions; students confuse what each measures.",
      "legacy_domain_code": "TES",
      "legacy_domain_name": "Testing and Measurement"
    },
    {
      "id": "TES_CONT_003",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Test Validity - Content and Construct Validity",
      "item_x": "Content validity",
      "item_y": "Face validity",
      "question": "What is the difference between content validity and face validity?",
      "answer": "Content validity is the degree to which a test's items adequately and representatively sample the full domain of content the test is intended to measure. It is assessed by expert judgment and systematic content analysis — not by a statistical coefficient. A test used for licensure has content validity if its items represent the full range of skills practitioners need. Face validity refers to whether a test APPEARS to measure what it's supposed to measure from the surface — i.e., whether items look relevant and appropriate to test-takers. Face validity is not a true form of validity in the technical sense; it has no statistical basis and can be misleading. A test can have face validity without content validity, and vice versa.",
      "key_distinction": "Content validity = systematically representative of the domain (expert evaluation); Face validity = superficial appearance of measuring the construct (not technical validity).",
      "commonly_confused_because": "Students assume that if a test looks valid (face), it must be valid (content); the distinction between appearance and systematic domain coverage is crucial.",
      "legacy_domain_code": "TES",
      "legacy_domain_name": "Testing and Measurement"
    },
    {
      "id": "TES_CONT_004",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Test Validity - Criterion-Related Validity",
      "item_x": "Predictive validity",
      "item_y": "Concurrent validity",
      "question": "What is the difference between predictive and concurrent criterion-related validity?",
      "answer": "Predictive validity involves correlating test scores obtained NOW with a criterion measure collected in the FUTURE. The time gap is essential — the test predicts future performance (e.g., SAT scores predict first-year college GPA). This is the most relevant form for selection testing. Concurrent validity involves correlating test scores with a criterion measure collected at roughly the SAME TIME. Both the test and criterion are administered together (e.g., a new intelligence test correlated with an existing validated IQ test administered simultaneously). Concurrent validity is easier to establish but less directly relevant for selection purposes.",
      "key_distinction": "Predictive = test now → criterion in future; Concurrent = test and criterion measured at the same time.",
      "commonly_confused_because": "Both are criterion-related validity types and both produce a validity coefficient; the time relationship between predictor and criterion is the sole distinction.",
      "legacy_domain_code": "TES",
      "legacy_domain_name": "Testing and Measurement"
    },
    {
      "id": "TES_CONT_005",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Test Validity - Content and Construct Validity",
      "item_x": "Convergent validity",
      "item_y": "Discriminant validity",
      "question": "What is the difference between convergent and discriminant validity as components of construct validity?",
      "answer": "Convergent validity is demonstrated when a test correlates highly with other measures that assess the SAME or theoretically related constructs (different methods, same trait). High convergent validity supports the claim that the test measures what it intends to. Discriminant (divergent) validity is demonstrated when a test does NOT correlate highly with measures of DIFFERENT, theoretically unrelated constructs (same method, different trait). Together they are assessed using Campbell and Fiske's multitrait-multimethod (MTMM) matrix. Both are necessary for construct validity: the test must measure its intended construct (convergent) and not the wrong construct (discriminant).",
      "key_distinction": "Convergent = should correlate high with same trait, different method; Discriminant = should correlate low with different traits.",
      "commonly_confused_because": "Students confuse which direction (high or low correlation) validates each type, and which types of comparisons (same trait vs. different trait) are relevant.",
      "legacy_domain_code": "TES",
      "legacy_domain_name": "Testing and Measurement"
    },
    {
      "id": "TES_CONT_007",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Test Validity - Criterion-Related Validity",
      "item_x": "Sensitivity",
      "item_y": "Specificity",
      "question": "What is the difference between sensitivity and specificity in criterion-related test validation?",
      "answer": "Sensitivity is the proportion of individuals who truly have the condition (true positives) that the test correctly identifies — i.e., the true positive rate. A highly sensitive test rarely misses cases (few false negatives) and is most useful for screening purposes. Specificity is the proportion of individuals who truly do not have the condition (true negatives) that the test correctly classifies as negative — i.e., the true negative rate. A highly specific test rarely generates false positives and is most useful for confirming a diagnosis. There is an inherent trade-off: raising the cut score increases specificity but decreases sensitivity, and vice versa.",
      "key_distinction": "Sensitivity = correctly identifies those WITH the condition (true positive rate); Specificity = correctly identifies those WITHOUT the condition (true negative rate).",
      "commonly_confused_because": "Both are derived from the same 2×2 contingency table and both involve proportions of correctly classified individuals; students confuse which group (those with vs. without the condition) serves as the denominator for each.",
      "legacy_domain_code": "TES",
      "legacy_domain_name": "Testing and Measurement"
    },
    {
      "id": "TES_CONT_009",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Test Validity - Criterion-Related Validity",
      "item_x": "Shrinkage",
      "item_y": "Restriction of range",
      "question": "What is the difference between shrinkage and restriction of range as threats to criterion-related validity?",
      "answer": "Shrinkage refers to the decrease in a validity (or multiple correlation) coefficient when the regression equation derived from one sample is applied to a new, independent sample. It occurs because regression capitalizes on chance relationships specific to the derivation sample that do not replicate. Shrinkage is addressed by cross-validation — applying the equation to a holdout sample and comparing the obtained R to the original. Restriction of range occurs when the variability of scores on the predictor or criterion is artificially limited in the validation sample — typically because selection has already occurred (e.g., only hired applicants are followed up). Range restriction attenuates (underestimates) the true validity coefficient in the full population, and statistical corrections exist to adjust for it.",
      "key_distinction": "Shrinkage = validity coefficient inflated by chance in the derivation sample, shrinks on cross-validation; Restriction of range = validity coefficient deflated because score variability is truncated by selection.",
      "commonly_confused_because": "Both produce a discrepancy between the observed and true validity coefficient, but they push the coefficient in opposite directions (inflated vs. deflated) and arise from different methodological sources.",
      "legacy_domain_code": "TES",
      "legacy_domain_name": "Testing and Measurement"
    },
    {
      "id": "RMS_CONT_011",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Research - Single-Subject and Group Designs",
      "item_x": "Case study",
      "item_y": "Single-subject experimental design",
      "question": "What is the difference between a case study and a single-subject experimental design?",
      "answer": "A case study is a qualitative, descriptive method involving intensive study of one individual, group, or event. It produces rich detail but lacks experimental control — there is no manipulation of an independent variable, no baseline phase, and no systematic replication. Causal inferences cannot be drawn. A single-subject experimental design (e.g., A-B-A-B reversal, multiple baseline) involves systematic manipulation of an independent variable with one or a few participants. Alternating or staggered baseline (A) and treatment (B) phases provide experimental control and allow the researcher to establish a causal relationship between the treatment and the target behavior. Unlike case studies, single-subject designs meet the criteria for internal validity.",
      "key_distinction": "Case study = descriptive, no experimental control, cannot establish causation; Single-subject experimental design = manipulates IV, compares baseline to treatment, allows causal inference.",
      "commonly_confused_because": "Both focus on one or very few individuals; students assume any in-depth study of an individual is experimental, but experimental control (manipulation + baseline comparison) is what distinguishes the two.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_012",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Research - Single-Subject and Group Designs",
      "item_x": "Cross-sectional research design",
      "item_y": "Longitudinal research design",
      "question": "What is the difference between a cross-sectional and a longitudinal research design?",
      "answer": "A cross-sectional design collects data from different groups of participants at a single point in time and compares across groups (e.g., comparing 20-, 40-, and 60-year-olds on cognitive ability in one session). It is efficient but susceptible to cohort effects — differences between age groups may reflect generational experiences rather than true developmental change. A longitudinal design follows the same participants over an extended period, measuring them at multiple time points. It directly tracks change within individuals, providing higher internal validity for developmental questions. However, it is expensive, time-consuming, and susceptible to attrition (dropout) and practice/testing effects from repeated measurement.",
      "key_distinction": "Cross-sectional = different people at one time, quick but subject to cohort effects; Longitudinal = same people over time, tracks real within-person change but subject to attrition and practice effects.",
      "commonly_confused_because": "Both are used to study developmental change; students confuse which design measures actual within-person change vs. cross-group differences that may reflect cohort rather than developmental effects.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_013",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Inferential Statistical Tests",
      "item_x": "Parametric statistical tests",
      "item_y": "Nonparametric statistical tests",
      "question": "What is the difference between parametric and nonparametric statistical tests?",
      "answer": "Parametric tests make assumptions about population parameters — most importantly that data are normally distributed and measured at the interval or ratio level, and often that group variances are equal (homogeneity of variance). Examples include the t-test, ANOVA, and Pearson r. They are more statistically powerful when assumptions are satisfied. Nonparametric (distribution-free) tests do not assume a specific population distribution and are appropriate when data are nominal or ordinal, sample sizes are very small, or parametric assumptions are clearly violated. Examples: Mann-Whitney U (analog to independent-samples t-test), Wilcoxon signed-rank (analog to correlated t-test), Kruskal-Wallis (analog to one-way ANOVA), chi-square. Nonparametric tests are less powerful than parametric counterparts when parametric assumptions hold.",
      "key_distinction": "Parametric = assumes normal distribution and interval/ratio data, more powerful when assumptions met; Nonparametric = no distribution assumptions, appropriate for ordinal/nominal data or violated assumptions.",
      "commonly_confused_because": "Students may not know the nonparametric analog for each parametric test, or when it is appropriate to switch — particularly for small samples or ordinal data.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_014",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Inferential Statistical Tests",
      "item_x": "One-tailed (directional) hypothesis test",
      "item_y": "Two-tailed (nondirectional) hypothesis test",
      "question": "What is the difference between a one-tailed and a two-tailed hypothesis test?",
      "answer": "A one-tailed (directional) test places the entire rejection region in one tail of the sampling distribution. It requires the researcher to predict the direction of the effect in advance (e.g., the treatment will increase — not just change — scores). It is more powerful for detecting an effect in the predicted direction because the critical value needed for significance is smaller. However, an effect in the opposite direction cannot be detected. A two-tailed (nondirectional) test splits the rejection region equally between both tails, testing whether there is any significant difference in either direction. It requires a larger effect to reach significance (less powerful per direction) but detects effects in either direction without a prior directional prediction. Two-tailed tests are the default in most psychological research.",
      "key_distinction": "One-tailed = directional prediction, full alpha in one tail, more powerful for that direction only; Two-tailed = nondirectional, alpha split across both tails, detects effects in either direction.",
      "commonly_confused_because": "Students may not realize that inappropriately choosing a one-tailed test after viewing data inflates the Type I error rate, or may confuse which is more powerful under which conditions.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_015",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Correlation and Regression",
      "item_x": "Simple linear regression",
      "item_y": "Multiple regression",
      "question": "What is the difference between simple linear regression and multiple regression?",
      "answer": "Simple linear regression uses a single predictor variable (X) to predict a criterion variable (Y), yielding the equation Y' = a + bX, where b is the regression coefficient (slope) and a is the y-intercept. It describes the linear relationship between one predictor and the outcome. Multiple regression uses two or more predictor variables to predict a single criterion variable (Y). Each predictor receives a partial regression coefficient reflecting its unique contribution to predicting Y after controlling for the other predictors. Multiple regression yields a multiple correlation coefficient (R) and coefficient of multiple determination (R²). It increases predictive accuracy but requires larger samples, assumes predictors are not highly intercorrelated (multicollinearity), and requires careful interpretation of partial coefficients.",
      "key_distinction": "Simple regression = one predictor; Multiple regression = two or more predictors, each with a partial coefficient reflecting unique variance contribution controlling for other predictors.",
      "commonly_confused_because": "Students may not recognize that in multiple regression each partial coefficient reflects variance unique to that predictor after removing shared variance with other predictors — not just its simple bivariate correlation with the criterion.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    },
    {
      "id": "RMS_CONT_016",
      "domain_code": "PMET",
      "domain_name": "Psychometrics & Research Methods",
      "subdomain": "Correlation and Regression",
      "item_x": "Correlation",
      "item_y": "Causation",
      "question": "What is the difference between correlation and causation in research?",
      "answer": "A correlation is a statistical association between two variables — as one changes, the other tends to change in a predictable direction. A correlation coefficient quantifies the strength and direction of this relationship. Correlation alone does not establish that one variable caused the other. Three criteria must be met to infer causation: (1) covariation — the variables must be correlated; (2) temporal precedence — the cause must precede the effect; (3) elimination of alternative explanations (confounds and third variables). Only a true experiment with random assignment and manipulation of an independent variable can satisfy all three criteria. Correlational studies face the directionality problem (which variable caused which) and the third-variable problem (an unmeasured variable may cause both), making causal inference inappropriate without experimental control.",
      "key_distinction": "Correlation = statistical association, does not imply direction or cause; Causation = one variable produces change in another, requires experimental manipulation with random assignment.",
      "commonly_confused_because": "Media reports and everyday reasoning routinely interpret correlational findings causally; students must recognize that meeting only the covariation criterion is insufficient for causal claims.",
      "legacy_domain_code": "RMS",
      "legacy_domain_name": "Research Methods and Statistics"
    }
  ]
}